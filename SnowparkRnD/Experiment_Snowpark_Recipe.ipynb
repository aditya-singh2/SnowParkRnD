{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24313b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, os\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.registry.registry import Registry\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "exp_data = os.getenv(\"EXPERIMENT_DETAILS\")\n",
    "\n",
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure\n",
    "def train_ml_models(session: Session, exp_data: str) -> list:   \n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "    import importlib, os, json\n",
    "    import logging\n",
    "    \n",
    "     # variable for holding logs\n",
    "    logs = []\n",
    "    \n",
    "    # function for accumulating logs\n",
    "    def log_message(level: str, message: str):\n",
    "        logs.append(f\"{level}: {message}\")\n",
    "    \n",
    "    log_message(\"INFO\",\"Starting Experiment Recipe Execution\")\n",
    "    \n",
    "    # Experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    # Read dataset, Random split\n",
    "    df_train, df_test = session.table(exp_details.get(\"dataset\")).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    features = df_train.columns\n",
    "    features.remove(exp_details.get(\"target_column\"))\n",
    "    \n",
    "    # get features\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=exp_details.get(\"target_column\"):\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    categorical_features_oe = list(map(lambda a: a+'_OE', categorical_features))\n",
    "    print(\"numerical_features: \", numerical_features)\n",
    "    print(\"categorical_features_oe: \", categorical_features_oe)\n",
    "    \n",
    "    \n",
    "    #pipeline steps \n",
    "    categorical_pp = {\n",
    "        'ord': OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe) \n",
    "    }\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_features!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "    \n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically import selected algorithms\n",
    "    for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        logger.info(algorithm[1])\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        \n",
    "        pipe = Pipeline(steps=steps+[(\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "                                              , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        model = pipe.fit(df_train)\n",
    "         \n",
    "        # Test the model\n",
    "        df_test_pred = model.predict(df_test)\n",
    "        \n",
    "        # metrices\n",
    "        mse = mean_squared_error(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        mae = mean_absolute_error(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        r2 = r2_score(df=df_test_pred, y_true_col_name=exp_details.get(\"target_column\"), y_pred_col_name=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        print(\"Execution Completed\")\n",
    "        print(f'{algorithm[1]} MSE: {mse}')\n",
    "        print(f'{algorithm[1]} MAE: {mae}')\n",
    "        print(f'{algorithm[1]} R2: {r2}')\n",
    "        \n",
    "\n",
    "        # LOG MODEL INTO SNOWFLAKE REGISTRY\n",
    "        from snowflake.ml.registry.registry import Registry\n",
    "        reg = Registry(session=session)\n",
    "        # Log the model\n",
    "#         model_name = f\"expname_{algorithm}\"\n",
    "        try:\n",
    "            logger.info(\"logging model\")\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=exp_details.get(\"name\", \"sample_experiment\")+\"_\"+algorithm[1],\n",
    "                               comment=\"test\",\n",
    "                               version_name=\"run1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "                               metrics=[{\"model_metrics\": {\"MSE\": mse, \"MAE\": mae, \"r2\": r2}, \"project_id\": \"0001\", \"type\": \"EXP\"}])\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                pass\n",
    "            else:\n",
    "                return str(ex).split('?')\n",
    "    return [{\"EXP_NAME\":exp_details.get(\"name\", \"sample_experiment\"),\n",
    "             \"Version\":\"Run1\",\n",
    "             \"matrices\":{\"model_metrics\": {\"MSE\": mse, \"MAE\": mae, \"r2\": r2}, \"project_id\": \"0001\", \"type\": \"EXP\"},\n",
    "             \"Alogirthm_Type\":\"Regression\",\n",
    "             \"Alogithms\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_exp_name\":\"\"}]\n",
    "\n",
    "\n",
    "# Initilization\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=train_ml_models,\n",
    "                       name=\"train_ml_models\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "print(\"Executing Stored Procedure\")\n",
    "procedure_response = session.call(\"train_ml_models\", exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
