{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9b83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install fosforml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9345492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927947\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# project_id = str(uuid.uuid4())\n",
    "run_id = random.randint(100000, 999999)\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699f9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"fd0cf79c-8118-43a7-8f0b-059e8f78227a\".upper().replace('-','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1495d8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FD0CF79C_8118_43A7_8F0B_059E8F78227A'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"FD0CF79C_8118_43A7_8F0B_059E8F78227A_exp_001_run_0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c66b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_exp_data = {\n",
    "    \"algorithm_category\": \"Snowparkml\",\n",
    "    \"algorithm_type\": \"Classification\",\n",
    "    \"algorithms\": [\n",
    "      {\n",
    "        \"algorithm_name\": \"snowflake.ml.modeling.xgboost.XGBClassifier\"\n",
    "      }\n",
    "    ],\n",
    "    \"dataset_name\": \"EMPLOYEE\",\n",
    "    \"experiment_id\": \"600b9f90-f431-4590-83c7-f38fe138dedc\",\n",
    "    \"experiment_name\": \"New_Experiment_05\",\n",
    "    \"monitor_run_id\": \"000000\",\n",
    "    \"project_id\": \"68bce134-6d7a-4e24-9591-86266438acf9\",\n",
    "    \"stored_procedure\": \"run_experiment\",\n",
    "    \"target_column\": \"LEAVEORNOT\"\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c487d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_exp_data = '''{\n",
    "            \"monitor_run_id\": \"16e3f179-bb70-4632-9a39-9a6fac4a5581\",\n",
    "            \"project_id\": \"test12345\",\n",
    "            \"experiment_id\" : \"exp6789\", \n",
    "            \"experiment_name\":\"My_run_listing_exp\", \n",
    "            \"stored_procedure\":\"run_experiment\",\n",
    "            \"algorithm_category\":\"Snowparkml\",\n",
    "            \"algorithm_type\":\"Classification\",\n",
    "            \"dataset_name\":\"EMPLOYEE_10L\",\n",
    "            \"target_column\":\"LEAVEORNOT\",\n",
    "            \"algorithms\":[{\"algorithm_name\": \"snowflake.ml.modeling.tree.DecisionTreeClassifier\"}]\n",
    "        }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d621e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-1 (classification Airline Delay dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"classification\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.xgboost.XGBClassifier\": null}}, \n",
    "\"dataset\": \"AIRLINE_DEP_DELAY_10K\", \n",
    "\"target_column\": \"DEP_DEL15\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df37eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-2 (Regression Alcohol dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null}}, \n",
    "\"dataset\": \"ALCOHOL_DATA_10L\", \n",
    "\"target_column\": \"QUALITY\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-3 (classification Employee dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"classification\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.linear_model.LogisticRegression\": null}}, \n",
    "\"dataset\": \"EMPLOYEE_10L\", \n",
    "\"target_column\": \"LEAVEORNOT\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-4 (Regression Diamonds dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.xgboost.XGBRegressor\": null}}, \n",
    "\"dataset\": \"DIAMONDS\", \n",
    "\"target_column\": \"PRICE\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fc1b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm_category': 'Snowparkml',\n",
       " 'algorithm_type': 'Classification',\n",
       " 'algorithms': [{'algorithm_name': 'snowflake.ml.modeling.xgboost.XGBClassifier'}],\n",
       " 'dataset_name': 'EMPLOYEE',\n",
       " 'experiment_id': '600b9f90-f431-4590-83c7-f38fe138dedc',\n",
       " 'experiment_name': 'New_Experiment_05',\n",
       " 'monitor_run_id': '000000',\n",
       " 'project_id': '68bce134-6d7a-4e24-9591-86266438acf9',\n",
       " 'stored_procedure': 'run_experiment',\n",
       " 'target_column': 'LEAVEORNOT'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_exp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf3ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "\n",
    "session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fosforio.manager import get_conn_details_from_ds_name\n",
    "from snowflake.snowpark.session import Session\n",
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e7bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"insight_exp\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "        \n",
    "# def get_session(dataset, project_id):\n",
    "#     \"\"\"\n",
    "#     Method creates snowflake session object.\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         conn = get_conn_details_from_ds_name(dataset, project_id)\n",
    "#         region=conn[\"params\"][\"READER\"][\"region\"] if conn[\"params\"][\"READER\"][\"cloudPlatform\"] is None \\\n",
    "#                     else conn[\"params\"][\"READER\"][\"region\"]+\".\"+conn[\"params\"][\"READER\"][\"cloudPlatform\"]\n",
    "#         account = conn['params']['READER']['accountId'] if region is None \\\n",
    "#                     else conn['params']['READER']['accountId']+\".\"+region\n",
    "#         CONNECTION_PARAMETERS = {\n",
    "#             \"account\": account,\n",
    "#             \"user\":conn['params']['READER']['user'],\n",
    "#             \"password\": conn['params']['READER']['password'],\n",
    "#             \"role\": conn['params']['READER']['role'],\n",
    "#             \"database\": conn['params']['READER']['database'],\n",
    "#             \"warehouse\": conn['params']['READER']['wareHouse'],\n",
    "#             \"schema\": conn['params']['READER']['schema']\n",
    "#         }\n",
    "#         return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "#     except Exception as ex:\n",
    "#         print(\"Error while creating snowflake session\", ex)\n",
    "#         raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec151ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(session: Session, exp_data: dict) -> list:\n",
    "    # Imports\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "    from snowflake.ml.modeling.metrics import r2_score, accuracy_score, precision_score, roc_auc_score, \\\n",
    "        f1_score, recall_score, log_loss, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "    from snowflake.snowpark.functions import col, is_null, regexp_replace, when, lit\n",
    "    from snowflake.snowpark.types import StringType\n",
    "    from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "    import importlib, sys, json, os, logging\n",
    "    from snowflake.ml.registry.registry import Registry\n",
    "    from fosforml import register_model\n",
    "    import os\n",
    "    \n",
    "    os.environ['RUN_ID'] = '927947'\n",
    "\n",
    "\n",
    "    # variable for holding logs\n",
    "    logs = []\n",
    "    \n",
    "    # function for accumulating logs\n",
    "    def log_message(level: str, message: str):\n",
    "        logs.append(f\"{level}: {message}\")\n",
    "    \n",
    "    \n",
    "    # Functions used in stored proc\n",
    "    def apply_data_cleansing(df):\n",
    "        \"\"\"\n",
    "        Method handles null values in snowpark dataframe.\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        df_cleaned: dataframe after null handling\n",
    "        \"\"\"\n",
    "        # fillna - Unknown and 0\n",
    "        schema_fields = df.schema.fields\n",
    "        fill_values = {field.name: \"UNKNOWN\" if isinstance(field.datatype, StringType) else 0 for field in schema_fields}\n",
    "        df_cleaned = df.fillna(fill_values)\n",
    "        return df_cleaned\n",
    "\n",
    "\n",
    "    def get_feature_columns(df):\n",
    "        \"\"\"\n",
    "        Identifies the numerical and categorical features in dataset.\n",
    "        Identifies features for label encoding and one hot encoding\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        \"\"\"\n",
    "        schema_fields = df.schema.fields\n",
    "        features = df.columns\n",
    "        features.remove(exp_details.get(\"target_column\"))\n",
    "        df_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset_name')}\").collect()\n",
    "        categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "        categorical_features = []  \n",
    "        for row in df_schema:\n",
    "            for typ in categorical_types:\n",
    "                if typ in row['type']:\n",
    "                    categorical_features.append(row['name'])\n",
    "                    break\n",
    "        numerical_features = list(set(features) - set(categorical_features))\n",
    "        print(f\"numerical_features:  {numerical_features}\")\n",
    "        print(f\"categorical_features: {categorical_features}\")\n",
    "        log_message(\"INFO\",f\"numerical_features:  {numerical_features}\")\n",
    "        log_message(\"INFO\",f\"categorical_features: {categorical_features}\")\n",
    "        \n",
    "        \n",
    "        #identify columns for labelencoding and onehotencoding   \n",
    "        le_column_features = categorical_features\n",
    "        oh_column_features = []\n",
    "        if len(categorical_features) >= 1:\n",
    "            log_message(\"INFO\",f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for column in categorical_features:\n",
    "                if df.select(df[column]).distinct().count() < 10:\n",
    "                    oh_column_features.append(column)\n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_features}\")\n",
    "            print(f\"Columns identified to be encoded with one hot encoder: {oh_column_features}\")\n",
    "            log_message(\"INFO\",f\"Columns identified to be encoded with label encoder: {le_column_features}\")\n",
    "            log_message(\"INFO\",f\"Columns identified to be encoded with one hot encoder: {oh_column_features}\")\n",
    "        return categorical_features, numerical_features, le_column_features, oh_column_features\n",
    "\n",
    "\n",
    "    def create_and_run_preprocessing(df, categorical_features, numerical_features, le_column_features, oh_column_features):\n",
    "        \"\"\"\n",
    "        Based on different features column input creates preprocessing steps and run it on input dataframe\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        :returns:\n",
    "        df_train: preprocessed train dataset\n",
    "        df_test: preprocessed test dataset\n",
    "        \"\"\"\n",
    "        #pipeline steps \n",
    "        log_message(\"INFO\",\"Setting up preprocessing pipeline based on dataset\")\n",
    "        categorical_pp = {f'le_{column}':LabelEncoder(input_cols=column, output_cols=column) for column in le_column_features}\n",
    "        if len(oh_column_features)>0:\n",
    "            categorical_pp['oh_enc'] = OneHotEncoder(input_cols=oh_column_features, output_cols=oh_column_features, handle_unknown='ignore')\n",
    "        numerical_pp = {\n",
    "            'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "        }\n",
    "        steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_pp[key]!=[]] + \\\n",
    "        [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "        print(f\"Selected preprocesing steps: \\n{steps}\")\n",
    "        log_message(\"INFO\",f\"Selected preprocesing steps: \\n{steps}\")   \n",
    "            \n",
    "        # Run preprocessing pipeline steps\n",
    "        print(\"Running data preprocessing pipeline\")\n",
    "        log_message(\"INFO\",\"Running data preprocessing pipeline\") \n",
    "        df = Pipeline(steps=steps).fit(df).transform(df)\n",
    "        print(f\"Transformed dataset: \\n {df.show()}\")\n",
    "        log_message(\"INFO\",f\"Transformed dataset: \\n {df.show()}\")\n",
    "        df_train, df_test = df.random_split(weights=[0.8, 0.2], seed=0)\n",
    "        for col_name in df_train.schema.names:\n",
    "            new_col = col_name.replace('.','_')\n",
    "            df_train = df_train.withColumnRenamed(col_name, new_col)\n",
    "        for col_name in df_test.schema.names:\n",
    "            new_col = col_name.replace('.','_')\n",
    "            df_test = df_test.withColumnRenamed(col_name, new_col)\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def run_estimator(df_train, df_test, input_cols):\n",
    "        \"\"\"\n",
    "        trains on df_train and creates model object for given algorithm/estimator.\n",
    "        runs prediction function of model object on test dataset\n",
    "        :param:\n",
    "        df_train: input training dataframe\n",
    "        df_test: input test dataframe\n",
    "        input_cols: list of input feature names\n",
    "        :returns:\n",
    "        model: trained model object\n",
    "        df_pred: output predict dataframe\n",
    "        \"\"\"\n",
    "        for algorithm in exp_details.get(\"algorithms\"):\n",
    "            algorithm = algorithm[\"algorithm_name\"].rsplit('.', 1)\n",
    "            module = importlib.import_module(algorithm[0])\n",
    "            print(f\"----Running Algorithm {algorithm[1]}----\")\n",
    "            log_message(\"INFO\",f\"----Running Algorithm {algorithm[1]}----\")\n",
    "            attr = getattr(module, algorithm[1])\n",
    "            pipe = Pipeline(steps=[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                                  , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                                  , output_cols=['PREDICTIONS']))]\n",
    "                   )\n",
    "    \n",
    "            # Fit the pipeline\n",
    "            print(f\"Running model pipeline {algorithm[1]}\")\n",
    "            log_message(\"INFO\",f\"Running model pipeline {algorithm[1]}\")\n",
    "            model = pipe.fit(df_train)\n",
    "            print(dir(model))\n",
    "            # Test the model\n",
    "            print(\"Running prediction on model with test dataset\")\n",
    "            log_message(\"INFO\",\"Running prediction on model with test dataset\")\n",
    "            df_pred = model.predict(df_test)\n",
    "            return model, df_pred, algorithm[1]\n",
    "\n",
    "    \n",
    "    def try_or(fn):\n",
    "        try:\n",
    "            out = fn()\n",
    "            return out\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "        \n",
    "    def eval_metrics(df_pred):\n",
    "        log_message(\"INFO\",\"Generating Metrices\")\n",
    "        if exp_details.get(\"algorithm_type\") == 'Classification':\n",
    "            return {\n",
    "            'accuracy_score': try_or(lambda: accuracy_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'f1_score': try_or(lambda: f1_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'recall_score': try_or(lambda: recall_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'precision_score': try_or(lambda: precision_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'roc_auc': try_or(lambda: roc_auc_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS')),\n",
    "            'log_loss': try_or(lambda: log_loss(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "            'mean_absolute_percentage_error': try_or(lambda: mean_absolute_percentage_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'r2_score': try_or(lambda: r2_score(df=df_pred, y_true_col_name=exp_details.get(\"target_column\"), y_pred_col_name='PREDICTIONS')),\n",
    "            'mean_absolute_error': try_or(lambda: mean_absolute_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'mean_squared_error': try_or(lambda: mean_squared_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "            }\n",
    "\n",
    "\n",
    "#     def register_model(model, metrics_info, estimator):\n",
    "#         log_message(\"INFO\",\"Started: Registering model on snowflake\")\n",
    "#         reg = Registry(session=session)\n",
    "        \n",
    "#         clean = lambda x : x.replace(\"-\",\"_\")\n",
    "#         project_id = clean(exp_details.get(\"project_id\"))\n",
    "#         exp_name = clean(exp_details.get(\"experiment_name\"))\n",
    "#         run_id = clean(exp_details.get(\"monitor_run_id\"))\n",
    "#         model_name = \"Experiment_\"+project_id+\"_FDC_\"+exp_name\n",
    "#         mv = reg.log_model(model=model,\n",
    "#                            model_name=model_name,\n",
    "#                            comment=exp_details.get(\"description\"),\n",
    "#                            version_name='V_'+exp_details.get(\"monitor_run_id\"),\n",
    "#                            python_version=\"3.9.19\",\n",
    "#                            conda_dependencies=[\"xgboost\",\"scikit-learn\"],\n",
    "#                            metrics={\"model_metrics\": metrics_info,\n",
    "#                                     \"dataset_details\": {\n",
    "#                                         \"dataset_name\": exp_details.get(\"dataset_name\"),\n",
    "#                                         \"target_column\": exp_details.get(\"target_column\"),\n",
    "#                                     },\n",
    "#                                     \"hyper_parameters\": {'criterion': 'entropy', 'max_depth': None, 'max_features': 8, 'min_samples_leaf': 7},\n",
    "#                                      \"algorithm_type\": exp_details.get(\"algorithm_type\"),\n",
    "#                                      \"algorithm\": estimator,                                   \n",
    "#                                      \"experiment_name\": exp_details.get(\"experiment_name\"),\n",
    "#                                      \"source\": \"Experiment\",\n",
    "#                                      \"status\": \"Trained\",\n",
    "#                                      \"run_id\": exp_details.get(\"monitor_run_id\"),\n",
    "#                                      \"experiment_id\": exp_details.get(\"experiment_id\")})\n",
    "#         log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "#         return model_name\n",
    "            \n",
    "            \n",
    "    def create_tags(session, exp_details):\n",
    "        for key in exp_details.keys():\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {key}\")\n",
    "            tag.show()\n",
    "        if exp_details.get('algorithm_type')=='Classification':\n",
    "            metric_names=[\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\"]\n",
    "        else:\n",
    "            metric_names=[\"r2_score\",\"mean_absolute_error\",\"mean_squared_error\",\"mean_absolute_percentage_error\"]\n",
    "        for name in metric_names:\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {name}\")\n",
    "            tag.show()\n",
    "\n",
    "        \n",
    "    def set_tags(session, m_name, exp_details, metric_info):\n",
    "        for key, value in exp_details.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "        for key, value in metric_info.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "\n",
    "    try:\n",
    "        # loading experiment details\n",
    "        exp_details=exp_data\n",
    "\n",
    "        # creating user tags if not exist\n",
    "        create_tags(session, exp_details)\n",
    "\n",
    "        # Reading dataset\n",
    "        log_message(\"INFO\",\"Reading dataset features\")\n",
    "        data = session.table(exp_details.get(\"dataset_name\"))\n",
    "\n",
    "        # fillna\n",
    "        data = apply_data_cleansing(data)\n",
    "\n",
    "        # Identify feature columns\n",
    "        categorical_features, numerical_features, le_column_features, oh_column_features = get_feature_columns(data)\n",
    "\n",
    "        # Based on feature, do preprocessing\n",
    "        data_train, data_test = create_and_run_preprocessing(data, categorical_features, numerical_features, le_column_features, oh_column_features)\n",
    "        \n",
    "        # Save Test and Train Dataset\n",
    "        data_train.write.mode(\"overwrite\").save_as_table(\"EMPLOYEE_TRAIN_CLEANED\")\n",
    "        data_train.write.mode(\"overwrite\").save_as_table(\"EMPLOYEE_TEST_CLEANED\")\n",
    "        \n",
    "        # Run model training and prediction\n",
    "        input_cols = data_train.columns\n",
    "        input_cols.remove(exp_details.get(\"target_column\"))\n",
    "        model, data_pred, estimator = run_estimator(data_train, data_test, input_cols)\n",
    "        \n",
    "        print(str(type(model)))\n",
    "\n",
    "        # Register model on snowflake registry\n",
    "        response = register_model(\n",
    "            model_obj=model,\n",
    "            session=session,\n",
    "            name=\"HR_CHURN_01\",\n",
    "            snowflake_df=data_pred,\n",
    "            dataset_name=exp_details.get(\"dataset_name\"),\n",
    "            dataset_source=\"SnowflakeDataset\",\n",
    "            description=\"This is a test model\",\n",
    "            flavour=\"snowflake\",\n",
    "            model_type=\"classification\",\n",
    "            conda_dependencies=[\"xgboost\",\"scikit-learn\"],\n",
    "            source=\"Experiment\"\n",
    "        )\n",
    "        print(response)\n",
    "        log_message(\"INFO\", f\"{response}\")\n",
    "        return model, data_pred\n",
    "    except Exception as ex:\n",
    "        log_message(\"ERROR\", f\"{repr(ex)}\")\n",
    "        raise ex(\"Execution Logs: \"+\"\\n\".join(logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "914d9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "Stored procedure has been created successfully!\n",
      "Setting tag to session object: tag=  110003\n",
      "Executing Procedure\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_CATEGORY already exists, statement su...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_TYPE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|ALGORITHMS already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|DATASET_NAME already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|EXPERIMENT_ID already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|EXPERIMENT_NAME already exists, statement succe...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|MONITOR_RUN_ID already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|PROJECT_ID already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|STORED_PROCEDURE already exists, statement succ...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|TARGET_COLUMN already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ACCURACY_SCORE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|PRECISION_SCORE already exists, statement succe...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|RECALL_SCORE already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|F1_SCORE already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|ROC_AUC already exists, statement succeeded.  |\n",
      "------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|LOG_LOSS already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "numerical_features:  ['JOININGYEAR', 'AGE', 'PAYMENTTIER', 'EXPERIENCEINCURRENTDOMAIN']\n",
      "categorical_features: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "Columns identified to be encoded with label encoder: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "Columns identified to be encoded with one hot encoder: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "Selected preprocesing steps: \n",
      "[('le_EDUCATION', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7a60343992e0>), ('le_CITY', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7a60343997f0>), ('le_GENDER', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7a6034399d60>), ('le_EVERBENCHED', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7a60343990a0>), ('oh_enc', <snowflake.ml.modeling.preprocessing.one_hot_encoder.OneHotEncoder object at 0x7a6034399d30>), ('scaler', <snowflake.ml.modeling.preprocessing.min_max_scaler.MinMaxScaler object at 0x7a6034399700>)]\n",
      "Running data preprocessing pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"JOININGYEAR\"        |\"AGE\"                |\"PAYMENTTIER\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"EDUCATION_0.0\"  |\"EDUCATION_1.0\"  |\"EDUCATION_2.0\"  |\"CITY_0.0\"  |\"CITY_1.0\"  |\"CITY_2.0\"  |\"GENDER_0.0\"  |\"GENDER_1.0\"  |\"EVERBENCHED_0.0\"  |\"EVERBENCHED_1.0\"  |\"EVERBENCHED\"  |\"GENDER\"  |\"CITY\"  |\"EDUCATION\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.8333333333333144   |0.6315789473684208   |1.0            |0.0                          |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.16666666666668561  |0.3157894736842104   |0.0            |0.42857142857142855          |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |2.0     |0.0          |1             |\n",
      "|0.3333333333333144   |0.8421052631578947   |1.0            |0.2857142857142857           |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |1.0     |0.0          |0             |\n",
      "|0.6666666666666856   |0.26315789473684204  |1.0            |0.7142857142857142           |0.0              |1.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |1.0          |1             |\n",
      "|0.8333333333333144   |0.10526315789473673  |1.0            |0.2857142857142857           |0.0              |1.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |0.0                |1.0                |1.0            |1.0       |2.0     |1.0          |1             |\n",
      "|0.6666666666666856   |0.0                  |1.0            |0.0                          |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.5                  |0.8421052631578947   |1.0            |0.0                          |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |0.0          |0             |\n",
      "|0.6666666666666856   |0.6315789473684208   |1.0            |0.2857142857142857           |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |0.0     |0.0          |1             |\n",
      "|0.6666666666666856   |0.05263157894736836  |1.0            |0.14285714285714285          |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |2.0     |0.0          |0             |\n",
      "|0.8333333333333144   |0.7894736842105261   |0.5            |0.2857142857142857           |0.0              |1.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |1.0          |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Transformed dataset: \n",
      " None\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"JOININGYEAR\"        |\"AGE\"                |\"PAYMENTTIER\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"EDUCATION_0.0\"  |\"EDUCATION_1.0\"  |\"EDUCATION_2.0\"  |\"CITY_0.0\"  |\"CITY_1.0\"  |\"CITY_2.0\"  |\"GENDER_0.0\"  |\"GENDER_1.0\"  |\"EVERBENCHED_0.0\"  |\"EVERBENCHED_1.0\"  |\"EVERBENCHED\"  |\"GENDER\"  |\"CITY\"  |\"EDUCATION\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.8333333333333144   |0.6315789473684208   |1.0            |0.0                          |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.16666666666668561  |0.3157894736842104   |0.0            |0.42857142857142855          |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |2.0     |0.0          |1             |\n",
      "|0.3333333333333144   |0.8421052631578947   |1.0            |0.2857142857142857           |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |1.0     |0.0          |0             |\n",
      "|0.6666666666666856   |0.26315789473684204  |1.0            |0.7142857142857142           |0.0              |1.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |1.0          |1             |\n",
      "|0.8333333333333144   |0.10526315789473673  |1.0            |0.2857142857142857           |0.0              |1.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |0.0                |1.0                |1.0            |1.0       |2.0     |1.0          |1             |\n",
      "|0.6666666666666856   |0.0                  |1.0            |0.0                          |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.5                  |0.8421052631578947   |1.0            |0.0                          |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |0.0          |0             |\n",
      "|0.6666666666666856   |0.6315789473684208   |1.0            |0.2857142857142857           |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |0.0     |0.0          |1             |\n",
      "|0.6666666666666856   |0.05263157894736836  |1.0            |0.14285714285714285          |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |2.0     |0.0          |0             |\n",
      "|0.8333333333333144   |0.7894736842105261   |0.5            |0.2857142857142857           |0.0              |1.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |1.0          |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Running Algorithm XGBClassifier----\n",
      "Running model pipeline XGBClassifier\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_append_step_feature_consumption_info', '_can_be_trained_in_ml_runtime', '_check_dataset_type', '_check_input_cols', '_check_output_cols', '_compute', '_construct_fitted_column_transformer_object', '_convert_attribute_dict_to_ndarray', '_create_sklearn_object', '_create_unfitted_sklearn_object', '_data_sources', '_deps', '_drop_input_cols', '_drop_input_columns', '_enforce_fit', '_feature_names_in', '_final_step_can_fit_predict', '_final_step_can_fit_transform', '_fit', '_fit_ml_runtime', '_fit_snowpark_dataframe_within_one_sproc', '_fit_transform_dataset', '_generate_model_signatures', '_get_data_sources', '_get_dependencies', '_get_estimator', '_get_label_cols', '_get_native_object', '_get_output_column_names', '_get_param_names', '_get_sanitized_list_of_columns', '_get_transformers', '_infer_input_cols', '_infer_input_output_cols', '_infer_output_cols', '_invoke_estimator_func', '_is_convertible_to_sklearn', '_is_convertible_to_sklearn_object', '_is_estimator', '_is_final_step_estimator', '_is_fitted', '_is_pipeline_modifying_label_or_sample_weight', '_is_transformer', '_model_signature_dict', '_n_features_in', '_reset', '_sklearn_object', '_transform_dataset', '_transform_sklearn', '_transformers_to_input_indices', '_upload_model_to_stage', '_use_input_cols_only', '_validate_data_has_no_nulls', '_validate_steps', '_wrap_transformer_in_column_transformer', 'custom_states', 'file_names', 'fit', 'fit_predict', 'fit_transform', 'get_input_cols', 'get_label_cols', 'get_output_cols', 'get_params', 'get_passthrough_cols', 'get_sample_weight_col', 'get_sklearn_args', 'input_cols', 'label_cols', 'model_signatures', 'output_cols', 'passthrough_cols', 'predict', 'predict_log_proba', 'predict_proba', 'sample_weight_col', 'score', 'score_samples', 'set_drop_input_cols', 'set_input_cols', 'set_label_cols', 'set_output_cols', 'set_params', 'set_passthrough_cols', 'set_sample_weight_col', 'start_time', 'steps', 'to_lightgbm', 'to_sklearn', 'to_xgboost', 'transform']\n",
      "Running prediction on model with test dataset\n",
      "<class 'snowflake.ml.modeling.pipeline.pipeline.Pipeline'>\n",
      "Failed to get snowflake dataset details. list index out of range\n",
      "Stored Procedure Executed Successfully !\n",
      "<snowflake.ml.modeling.pipeline.pipeline.Pipeline object at 0x7a6009974880>\n",
      "Logging in mlflow completed !\n",
      "CPU times: user 4.45 s, sys: 89.3 ms, total: 4.54 s\n",
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initilization\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "# exp_details=json.loads(_exp_data)\n",
    "# session = get_session(_exp_data.get(\"dataset_name\"),\"fd0cf79c-8118-43a7-8f0b-059e8f78227a\")\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.custom_package_usage_config['enabled'] = True\n",
    "session.custom_package_usage_config['force_push'] = True\n",
    "# session.custom_package_usage_config[\"cache_path\"] = stage\n",
    "# session.sproc.register(func=run_experiment,\n",
    "#                        name=\"run_experiment\",\n",
    "#                        packages=[\"fosforml==1.0.8\"],\n",
    "#                        is_permanent=True,\n",
    "#                        stage_location=stage,\n",
    "#                        replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "# tagging session\n",
    "print(\"Setting tag to session object: tag= \", \"110003\")\n",
    "session.query_tag=\"110003\"\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# procedure_response = session.call(\"run_experiment\", _exp_data)\n",
    "procedure_response = run_experiment(session, _exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b0d6c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_CATEGORY already exists, statement su...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_TYPE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|ALGORITHMS already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|DATASET_NAME already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|EXPERIMENT_ID already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|EXPERIMENT_NAME already exists, statement succe...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|MONITOR_RUN_ID already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|PROJECT_ID already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|STORED_PROCEDURE already exists, statement succ...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|TARGET_COLUMN already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ACCURACY_SCORE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|PRECISION_SCORE already exists, statement succe...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|RECALL_SCORE already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|F1_SCORE already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|ROC_AUC already exists, statement succeeded.  |\n",
      "------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|LOG_LOSS already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "numerical_features:  ['AGE', 'JOININGYEAR', 'EXPERIENCEINCURRENTDOMAIN', 'PAYMENTTIER']\n",
      "categorical_features: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "Columns identified to be encoded with label encoder: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "Columns identified to be encoded with one hot encoder: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "Selected preprocesing steps: \n",
      "[('le_EDUCATION', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7e00bfde1fd0>), ('le_CITY', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7e00bfdd00a0>), ('le_GENDER', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7e00bfd84a00>), ('le_EVERBENCHED', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7e00bfd84d00>), ('oh_enc', <snowflake.ml.modeling.preprocessing.one_hot_encoder.OneHotEncoder object at 0x7e00bfde1b50>), ('scaler', <snowflake.ml.modeling.preprocessing.min_max_scaler.MinMaxScaler object at 0x7e00bfd84d30>)]\n",
      "Running data preprocessing pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/tmp/pip_packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"AGE\"                |\"JOININGYEAR\"        |\"EXPERIENCEINCURRENTDOMAIN\"  |\"PAYMENTTIER\"  |\"EDUCATION_0.0\"  |\"EDUCATION_1.0\"  |\"EDUCATION_2.0\"  |\"CITY_0.0\"  |\"CITY_1.0\"  |\"CITY_2.0\"  |\"GENDER_0.0\"  |\"GENDER_1.0\"  |\"EVERBENCHED_0.0\"  |\"EVERBENCHED_1.0\"  |\"EVERBENCHED\"  |\"GENDER\"  |\"CITY\"  |\"EDUCATION\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.6315789473684208   |0.8333333333333144   |0.0                          |1.0            |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.3157894736842104   |0.16666666666668561  |0.42857142857142855          |0.0            |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |2.0     |0.0          |1             |\n",
      "|0.8421052631578947   |0.3333333333333144   |0.2857142857142857           |1.0            |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |1.0     |0.0          |0             |\n",
      "|0.26315789473684204  |0.6666666666666856   |0.7142857142857142           |1.0            |0.0              |1.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |1.0          |1             |\n",
      "|0.10526315789473673  |0.8333333333333144   |0.2857142857142857           |1.0            |0.0              |1.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |0.0                |1.0                |1.0            |1.0       |2.0     |1.0          |1             |\n",
      "|0.0                  |0.6666666666666856   |0.0                          |1.0            |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.8421052631578947   |0.5                  |0.0                          |1.0            |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |0.0          |0             |\n",
      "|0.6315789473684208   |0.6666666666666856   |0.2857142857142857           |1.0            |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |0.0     |0.0          |1             |\n",
      "|0.05263157894736836  |0.6666666666666856   |0.14285714285714285          |1.0            |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |2.0     |0.0          |0             |\n",
      "|0.7894736842105261   |0.8333333333333144   |0.2857142857142857           |0.5            |0.0              |1.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |1.0          |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Transformed dataset: \n",
      " None\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"AGE\"                |\"JOININGYEAR\"        |\"EXPERIENCEINCURRENTDOMAIN\"  |\"PAYMENTTIER\"  |\"EDUCATION_0.0\"  |\"EDUCATION_1.0\"  |\"EDUCATION_2.0\"  |\"CITY_0.0\"  |\"CITY_1.0\"  |\"CITY_2.0\"  |\"GENDER_0.0\"  |\"GENDER_1.0\"  |\"EVERBENCHED_0.0\"  |\"EVERBENCHED_1.0\"  |\"EVERBENCHED\"  |\"GENDER\"  |\"CITY\"  |\"EDUCATION\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.6315789473684208   |0.8333333333333144   |0.0                          |1.0            |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.3157894736842104   |0.16666666666668561  |0.42857142857142855          |0.0            |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |2.0     |0.0          |1             |\n",
      "|0.8421052631578947   |0.3333333333333144   |0.2857142857142857           |1.0            |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |1.0     |0.0          |0             |\n",
      "|0.26315789473684204  |0.6666666666666856   |0.7142857142857142           |1.0            |0.0              |1.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |1.0          |1             |\n",
      "|0.10526315789473673  |0.8333333333333144   |0.2857142857142857           |1.0            |0.0              |1.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |0.0                |1.0                |1.0            |1.0       |2.0     |1.0          |1             |\n",
      "|0.0                  |0.6666666666666856   |0.0                          |1.0            |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |0.0     |0.0          |0             |\n",
      "|0.8421052631578947   |0.5                  |0.0                          |1.0            |1.0              |0.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |0.0          |0             |\n",
      "|0.6315789473684208   |0.6666666666666856   |0.2857142857142857           |1.0            |1.0              |0.0              |0.0              |1.0         |0.0         |0.0         |1.0           |0.0           |1.0                |0.0                |0.0            |0.0       |0.0     |0.0          |1             |\n",
      "|0.05263157894736836  |0.6666666666666856   |0.14285714285714285          |1.0            |1.0              |0.0              |0.0              |0.0         |0.0         |1.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |2.0     |0.0          |0             |\n",
      "|0.7894736842105261   |0.8333333333333144   |0.2857142857142857           |0.5            |0.0              |1.0              |0.0              |0.0         |1.0         |0.0         |0.0           |1.0           |1.0                |0.0                |0.0            |1.0       |1.0     |1.0          |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Running Algorithm XGBClassifier----\n",
      "Running model pipeline XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.19.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_append_step_feature_consumption_info', '_can_be_trained_in_ml_runtime', '_check_dataset_type', '_check_input_cols', '_check_output_cols', '_compute', '_construct_fitted_column_transformer_object', '_convert_attribute_dict_to_ndarray', '_create_sklearn_object', '_create_unfitted_sklearn_object', '_data_sources', '_deps', '_drop_input_cols', '_drop_input_columns', '_enforce_fit', '_feature_names_in', '_final_step_can_fit_predict', '_final_step_can_fit_transform', '_fit', '_fit_ml_runtime', '_fit_snowpark_dataframe_within_one_sproc', '_fit_transform_dataset', '_generate_model_signatures', '_get_data_sources', '_get_dependencies', '_get_estimator', '_get_label_cols', '_get_native_object', '_get_output_column_names', '_get_param_names', '_get_sanitized_list_of_columns', '_get_transformers', '_infer_input_cols', '_infer_input_output_cols', '_infer_output_cols', '_invoke_estimator_func', '_is_convertible_to_sklearn', '_is_convertible_to_sklearn_object', '_is_estimator', '_is_final_step_estimator', '_is_fitted', '_is_pipeline_modifying_label_or_sample_weight', '_is_transformer', '_model_signature_dict', '_n_features_in', '_reset', '_sklearn_object', '_transform_dataset', '_transform_sklearn', '_transformers_to_input_indices', '_upload_model_to_stage', '_use_input_cols_only', '_validate_data_has_no_nulls', '_validate_steps', '_wrap_transformer_in_column_transformer', 'custom_states', 'file_names', 'fit', 'fit_predict', 'fit_transform', 'get_input_cols', 'get_label_cols', 'get_output_cols', 'get_params', 'get_passthrough_cols', 'get_sample_weight_col', 'get_sklearn_args', 'input_cols', 'label_cols', 'model_signatures', 'output_cols', 'passthrough_cols', 'predict', 'predict_log_proba', 'predict_proba', 'sample_weight_col', 'score', 'score_samples', 'set_drop_input_cols', 'set_input_cols', 'set_label_cols', 'set_output_cols', 'set_params', 'set_passthrough_cols', 'set_sample_weight_col', 'start_time', 'steps', 'to_lightgbm', 'to_sklearn', 'to_xgboost', 'transform']\n",
      "Running prediction on model with test dataset\n",
      "<class 'snowflake.ml.modeling.pipeline.pipeline.Pipeline'>\n",
      "Failed to get snowflake dataset details. list index out of range\n"
     ]
    }
   ],
   "source": [
    "model, df_pred = run_experiment(session, _exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bc68c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obej = model.output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f94ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(obej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ad28e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "121260cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_model\n\u001b[1;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m register_model(\n\u001b[1;32m      3\u001b[0m             model_obj\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m             session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m      5\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHR_CHURN_01\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 6\u001b[0m             snowflake_df\u001b[38;5;241m=\u001b[39m\u001b[43mdata_pred\u001b[49m,\n\u001b[1;32m      7\u001b[0m             dataset_name\u001b[38;5;241m=\u001b[39mexp_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m             dataset_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSnowflakeDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m             flavour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnowflake\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m             model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m             conda_dependencies\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m             source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from fosforml import register_model\n",
    "response = register_model(\n",
    "            model_obj=model,\n",
    "            session=session,\n",
    "            name=\"HR_CHURN_01\",\n",
    "            snowflake_df=data_pred,\n",
    "            dataset_name=exp_details.get(\"dataset_name\"),\n",
    "            dataset_source=\"SnowflakeDataset\",\n",
    "            description=\"This is a test model\",\n",
    "            flavour=\"snowflake\",\n",
    "            model_type=\"classification\",\n",
    "            conda_dependencies=[\"xgboost\",\"scikit-learn\"],\n",
    "            source=\"Experiment\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b06a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc91bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'account': 'ug94937.us-east4.gcp',\n",
       " 'user': 'ADITYASINGH',\n",
       " 'password': 'Enlightme#2024',\n",
       " 'database': 'FIRST_DB',\n",
       " 'schema': 'PUBLIC',\n",
       " 'warehouse': 'FOSFOR_INSIGHT_WH',\n",
       " 'role': 'ADITYASINGH'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fosforml.model_manager import snowflakesession\n",
    "obj = snowflakesession()\n",
    "obj.connection_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5d3a1d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mmodel\u001b[49m))\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(str(type(model)).find(\"sklearn\") > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c60f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
