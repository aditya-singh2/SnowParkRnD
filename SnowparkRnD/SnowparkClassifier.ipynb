{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9345492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52dfff45-6981-40e0-9f91-d0e6a7a791b7\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# project_id = str(uuid.uuid4())\n",
    "run_id = str(uuid.uuid4())\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e19e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-1 (classification Airline Delay dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"classification\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.xgboost.XGBClassifier\": null}}, \n",
    "\"dataset\": \"AIRLINE_DEP_DELAY_10K\", \n",
    "\"target_column\": \"DEP_DEL15\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f94f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-2 (Regression Alcohol dataset)\n",
    "exp_data = f'''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null}}, \n",
    "\"dataset\": \"ALCOHOL_DATA_10L\", \n",
    "\"target_column\": \"QUALITY\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-3 (classification Employee dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"classification\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.linear_model.LogisticRegression\": null}}, \n",
    "\"dataset\": \"EMPLOYEE_10L\", \n",
    "\"target_column\": \"LEAVEORNOT\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ded366d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-4 (Regression Diamonds dataset)\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":\"{0}\", \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null}}, \n",
    "\"dataset\": \"DIAMONDS\", \n",
    "\"target_column\": \"PRICE\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b7aec7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"source\":\"EXP\", \\n\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \\n\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \\n\"run_id\":\"52dfff45-6981-40e0-9f91-d0e6a7a791b7\", \\n\"exp_name\": \"Final_recipe\", \\n\"algorithm_type\":\"regression\", \\n\"algo_details\": {\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null}, \\n\"dataset\": \"DIAMONDS\", \\n\"target_column\": \"PRICE\"}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec151ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "        \n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure \n",
    "def run_experiment(session: Session, exp_data: str) -> list:\n",
    "    # Imports\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "    from snowflake.ml.modeling.metrics import r2_score, accuracy_score, precision_score, roc_auc_score, \\\n",
    "        f1_score, recall_score, log_loss, mean_absolute_error, mean_squared_error\n",
    "    from snowflake.snowpark.functions import col, is_null, regexp_replace, when, lit\n",
    "    from snowflake.snowpark.types import StringType\n",
    "    from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "    import importlib, sys, json, os, logging\n",
    "    from snowflake.ml.registry.registry import Registry\n",
    "    \n",
    "    \n",
    "    # Functions used in stored proc\n",
    "    def apply_data_cleansing(df):\n",
    "        \"\"\"\n",
    "        Method handles null values in snowpark dataframe.\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        df_cleaned: dataframe after null handling\n",
    "        \"\"\"\n",
    "        # fillna - Unknown and 0\n",
    "        schema_fields = df.schema.fields\n",
    "        fill_values = {field.name: \"UNKNOWN\" if isinstance(field.datatype, StringType) else 0 for field in schema_fields}\n",
    "        df_cleaned = df.fillna(fill_values)\n",
    "        return df_cleaned\n",
    "\n",
    "\n",
    "    def get_feature_columns(df):\n",
    "        \"\"\"\n",
    "        Identifies the numerical and categorical features in dataset.\n",
    "        Identifies features for label encoding and one hot encoding\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        \"\"\"\n",
    "        schema_fields = df.schema.fields\n",
    "        features = df.columns\n",
    "        features.remove(exp_details.get(\"target_column\"))\n",
    "        df_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "        categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "        categorical_features = []  \n",
    "        for row in df_schema:\n",
    "            for typ in categorical_types:\n",
    "                if typ in row['type']:\n",
    "                    categorical_features.append(row['name'])\n",
    "                    break\n",
    "        numerical_features = list(set(features) - set(categorical_features))\n",
    "        print(f\"numerical_features:  {numerical_features}\")\n",
    "        print(f\"categorical_features: {categorical_features}\")\n",
    "        \n",
    "        #identify columns for labelencoding and onehotencoding   \n",
    "        le_column_features = []\n",
    "        oh_column_features = []\n",
    "        if len(categorical_features) >= 1:\n",
    "            print(f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for column in categorical_features:\n",
    "                if df.select(df[column]).distinct().count() >= 10:\n",
    "                    le_column_features.append(column)\n",
    "                elif column == exp_details.get(\"target_column\"):\n",
    "                    le_column_feature.append(column)\n",
    "                else:\n",
    "                    oh_column_features.append(column)\n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_features}\")\n",
    "            print(f\"Columns identified to be encoded with one hot encoder: {oh_column_features}\")\n",
    "        return categorical_features, numerical_features, le_column_features, oh_column_features\n",
    "\n",
    "\n",
    "    def create_and_run_preprocessing(df, categorical_features, numerical_features, le_column_features, oh_column_features):\n",
    "        \"\"\"\n",
    "        Based on different features column input creates preprocessing steps and run it on input dataframe\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        :returns:\n",
    "        df_train: preprocessed train dataset\n",
    "        df_test: preprocessed test dataset\n",
    "        \"\"\"\n",
    "        #pipeline steps \n",
    "        print(\"Setting up preprocessing pipeline based on dataset\")\n",
    "        categorical_pp = {f'le_{column}':LabelEncoder(input_cols=column, output_cols=column) for column in le_column_features}\n",
    "        if len(oh_column_features)>0:\n",
    "            categorical_pp['oh_enc'] = OneHotEncoder(input_cols=oh_column_features, output_cols=oh_column_features, handle_unknown='ignore')\n",
    "        numerical_pp = {\n",
    "            'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "        }\n",
    "        steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_pp[key]!=[]] + \\\n",
    "        [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "        print(f\"Selected preprocesing steps: \\n{steps}\")    \n",
    "            \n",
    "        # Run preprocessing pipeline steps \n",
    "        print(\"Running data preprocessing pipeline\")\n",
    "        df = Pipeline(steps=steps).fit(df).transform(df)\n",
    "        print(f\"Transformed dataset: \\n {df.show()}\")\n",
    "        df_train, df_test = df.random_split(weights=[0.8, 0.2], seed=0)\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def run_estimator(df_train, df_test, input_cols):\n",
    "        \"\"\"\n",
    "        trains on df_train and creates model object for given algorithm/estimator.\n",
    "        runs prediction function of model object on test dataset\n",
    "        :param:\n",
    "        df_train: input training dataframe\n",
    "        df_test: input test dataframe\n",
    "        input_cols: list of input feature names\n",
    "        :returns:\n",
    "        df_pred: output predict dataframe\n",
    "        \"\"\"\n",
    "        for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "            algorithm = algorithm.rsplit('.', 1)\n",
    "            module = importlib.import_module(algorithm[0])\n",
    "            print(f\"----Running Algorithm {algorithm[1]}----\")\n",
    "            attr = getattr(module, algorithm[1])\n",
    "            pipe = Pipeline(steps=[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                                  , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                                  , output_cols=['PREDICTIONS']))]\n",
    "                   )\n",
    "    \n",
    "            # Fit the pipeline\n",
    "            print(f\"Running model pipeline {algorithm[1]}\")\n",
    "            model = pipe.fit(df_train)\n",
    "     \n",
    "            # Test the model\n",
    "            print(\"Running prediction on model with test dataset\")\n",
    "            df_pred = model.predict(df_test)\n",
    "            return model, df_pred\n",
    "\n",
    "    \n",
    "    def try_or(fn):\n",
    "        try:\n",
    "            out = fn()\n",
    "            return out\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "        \n",
    "    def eval_metrics(df_pred):\n",
    "        print(\"Generating Metrices\")\n",
    "        if exp_details.get(\"algorithm_type\") == 'classification':\n",
    "            return {\n",
    "            'accuracy_score': try_or(lambda: accuracy_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'f1_score': try_or(lambda: f1_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'recall_score': try_or(lambda: recall_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'precision_score': try_or(lambda: precision_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'roc_auc': try_or(lambda: roc_auc_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS')),\n",
    "            'log_loss': try_or(lambda: log_loss(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "            'r2_score': try_or(lambda: r2_score(df=df_pred, y_true_col_name=exp_details.get(\"target_column\"), y_pred_col_name='PREDICTIONS')),\n",
    "            'mean_absolute_error': try_or(lambda: mean_absolute_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'mean_squared_error': try_or(lambda: mean_squared_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "            }\n",
    "\n",
    "\n",
    "    def register_model(model, metrics_info):\n",
    "        print(\"Started: Registering model on snowflake\")\n",
    "        reg = Registry(session=session)\n",
    "        try:\n",
    "            clean = lambda x : x.replace(\"-\",\"_\")\n",
    "            project_id = clean(exp_details.get(\"project_id\"))\n",
    "            exp_id = clean(exp_details.get(\"id\"))\n",
    "            run_id = clean(exp_details.get(\"run_id\"))\n",
    "            model_name = exp_details.get(\"exp_name\")+\"_\"+project_id+\"_\"+exp_id+\"_\"+run_id\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=model_name,\n",
    "                               comment=exp_details.get(\"description\"),\n",
    "                               version_name=\"V1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"xgboost\",\"scikit-learn==1.2.2\"],\n",
    "                               metrics=[{\"model_metrics\": metrics_info, \n",
    "                                         \"project_id\": exp_details.get(\"project_id\"),\n",
    "                                         \"id\": exp_details.get(\"id\"),\n",
    "                                         \"run_id\": exp_details.get(\"run_id\"),\n",
    "                                         \"algorithm_type\": exp_details.get(\"algorithm_type\"),\n",
    "                                         \"algo_details\": exp_details.get(\"algo_details\"),\n",
    "                                         \"dataset\": exp_details.get(\"dataset\"),\n",
    "                                         \"target_column\": exp_details.get(\"target_column\"),\n",
    "                                         \"exp_name\": exp_details.get(\"exp_name\"),\n",
    "                                         \"source\": \"EXP\"}])\n",
    "            print(\"Registeration of model completed!!!\")\n",
    "            return model_name\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                print(\"Registeration of model completed!!!\")\n",
    "                return model_name\n",
    "            else:\n",
    "                print(\"Exception Occured while registering model\")\n",
    "                return str(ex).split('?')\n",
    "            \n",
    "            \n",
    "    def create_tags(session, exp_details):\n",
    "        for key in exp_details.keys():\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {key}\")\n",
    "            tag.show()\n",
    "        if exp_details.get('algorithm_type')=='classification':\n",
    "            metric_names=[\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\"]\n",
    "        else:\n",
    "            metric_names=[\"r2_score\",\"mean_absolute_error\",\"mean_squared_error\"]\n",
    "        for name in metric_names:\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {name}\")\n",
    "            tag.show()\n",
    "\n",
    "        \n",
    "    def set_tags(session, m_name, exp_details, metric_info):\n",
    "        for key, value in exp_details.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "        for key, value in metric_info.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "    \n",
    "    # loading experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    metric_names=[\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\",\"\"]\n",
    "    \n",
    "    # creating user tags if not exist\n",
    "    create_tags(session, exp_details)\n",
    "    \n",
    "    # Reading dataset\n",
    "    print(\"Reading dataset features\")\n",
    "    data = session.table(exp_details.get(\"dataset\"))\n",
    "    \n",
    "    # fillna\n",
    "    data = apply_data_cleansing(data)\n",
    "    \n",
    "    # Identify feature columns\n",
    "    categorical_features, numerical_features, le_column_features, oh_column_features = get_feature_columns(data)\n",
    "    \n",
    "    # Based on feature, do preprocessing\n",
    "    data_train, data_test = create_and_run_preprocessing(data, categorical_features, numerical_features, le_column_features, oh_column_features)\n",
    "    \n",
    "    # Run model training and prediction\n",
    "    input_cols = data_train.columns\n",
    "    input_cols.remove(exp_details.get(\"target_column\"))    \n",
    "#     input_cols = categorical_features+numerical_features\n",
    "#     if exp_details.get(\"target_column\") in categorical_features:\n",
    "#         input_cols.remove(exp_details.get(\"target_column\"))\n",
    "    model, data_pred = run_estimator(data_train, data_test, input_cols)\n",
    "    \n",
    "    # Evaluate model metrices\n",
    "    metrics_info = eval_metrics(data_pred)\n",
    "    print(metrics_info)\n",
    "    \n",
    "    # Register model on snowflake registry\n",
    "    model_name = register_model(model, metrics_info)\n",
    "    print(model_name)\n",
    "    \n",
    "    # Set relevant tags to model object\n",
    "    set_tags(session, model_name, exp_details, metrics_info)\n",
    "    \n",
    "    return [{\"exp_name\":exp_details.get(\"exp_name\", \"sample_experiment\"),\n",
    "             \"version\":\"V1\",\n",
    "             \"matrices\":{\"model_metrics\": metrics_info, \"project_id\": \"0001\", \"source\": \"EXP\"},\n",
    "             \"algorithm_type\":exp_details.get(\"algorithm_type\"),\n",
    "             \"algorithm\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_model_name\":exp_details.get(\"exp_name\")+\"_\"+exp_details.get(\"project_id\")+\"_\"+exp_details.get(\"id\")+\"_\"+exp_details.get(\"run_id\")}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "914d9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "Stored procedure has been created successfully!\n",
      "Setting tag to session object: tag=  52dfff45-6981-40e0-9f91-d0e6a7a791b7\n",
      "Executing Procedure\n",
      "-----------------------------------------------\n",
      "|\"status\"                                     |\n",
      "-----------------------------------------------\n",
      "|SOURCE already exists, statement succeeded.  |\n",
      "-----------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|PROJECT_ID already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "|\"status\"                                 |\n",
      "-------------------------------------------\n",
      "|ID already exists, statement succeeded.  |\n",
      "-------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "|\"status\"                                     |\n",
      "-----------------------------------------------\n",
      "|RUN_ID already exists, statement succeeded.  |\n",
      "-----------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|EXP_NAME already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_TYPE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|ALGO_DETAILS already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|DATASET already exists, statement succeeded.  |\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|TARGET_COLUMN already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|R2_SCORE already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|MEAN_ABSOLUTE_ERROR already exists, statement s...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|MEAN_SQUARED_ERROR already exists, statement su...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "Reading dataset features\n",
      "numerical_features:  ['Y', 'DEPTH', 'Z', 'X', 'TABLE_PCT', 'CARAT']\n",
      "categorical_features: ['CUT', 'COLOR', 'CLARITY']\n",
      "['CUT', 'COLOR', 'CLARITY'] columns are non numeric in feature dataset, encoding required.\n",
      "Columns identified to be encoded with label encoder: []\n",
      "Columns identified to be encoded with one hot encoder: ['CUT', 'COLOR', 'CLARITY']\n",
      "Setting up preprocessing pipeline based on dataset\n",
      "Selected preprocesing steps: \n",
      "[('oh_enc', <snowflake.ml.modeling.preprocessing.one_hot_encoder.OneHotEncoder object at 0x7fa8fcf6d5e0>), ('scaler', <snowflake.ml.modeling.preprocessing.min_max_scaler.MinMaxScaler object at 0x7fa8fcf6d4f0>)]\n",
      "Running data preprocessing pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"Y\"                  |\"DEPTH\"              |\"Z\"                  |\"X\"                  |\"TABLE_PCT\"          |\"CARAT\"               |\"CUT_Fair\"  |\"CUT_Good\"  |\"CUT_Ideal\"  |\"CUT_Premium\"  |\"CUT_Very Good\"  |\"COLOR_D\"  |\"COLOR_E\"  |\"COLOR_F\"  |\"COLOR_G\"  |\"COLOR_H\"  |\"COLOR_I\"  |\"COLOR_J\"  |\"CLARITY_I1\"  |\"CLARITY_IF\"  |\"CLARITY_SI1\"  |\"CLARITY_SI2\"  |\"CLARITY_VS1\"  |\"CLARITY_VS2\"  |\"CLARITY_VVS1\"  |\"CLARITY_VVS2\"  |\"CUT\"      |\"COLOR\"  |\"CLARITY\"  |\"PRICE\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.06757215619694397  |0.5138888888888888   |0.07641509433962265  |0.3677839851024209   |0.23076923076923073  |0.006237006237006237  |0.0         |0.0         |1.0          |0.0            |0.0              |0.0        |1.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0           |0.0           |0.0            |1.0            |0.0            |0.0            |0.0             |0.0             |Ideal      |E        |SI2        |326      |\n",
      "|0.06519524617996604  |0.46666666666666656  |0.07264150943396226  |0.36219739292364994  |0.34615384615384615  |0.002079002079002079  |0.0         |0.0         |0.0          |1.0            |0.0              |0.0        |1.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0           |0.0           |1.0            |0.0            |0.0            |0.0            |0.0             |0.0             |Premium    |E        |SI1        |326      |\n",
      "|0.06910016977928693  |0.38611111111111107  |0.07264150943396226  |0.37709497206703907  |0.423076923076923    |0.006237006237006237  |0.0         |1.0         |0.0          |0.0            |0.0              |0.0        |1.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0           |0.0           |0.0            |0.0            |1.0            |0.0            |0.0             |0.0             |Good       |E        |VS1        |327      |\n",
      "|0.07181663837011885  |0.5388888888888888   |0.08270440251572327  |0.3910614525139665   |0.28846153846153844  |0.018711018711018705  |0.0         |0.0         |0.0          |1.0            |0.0              |0.0        |0.0        |0.0        |0.0        |0.0        |1.0        |0.0        |0.0           |0.0           |0.0            |0.0            |0.0            |1.0            |0.0             |0.0             |Premium    |I        |VS2        |334      |\n",
      "|0.07385398981324279  |0.5638888888888887   |0.08647798742138364  |0.404096834264432    |0.28846153846153844  |0.02286902286902287   |0.0         |1.0         |0.0          |0.0            |0.0              |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |1.0        |0.0           |0.0           |0.0            |1.0            |0.0            |0.0            |0.0             |0.0             |Good       |J        |SI2        |335      |\n",
      "|0.06723259762308999  |0.5499999999999998   |0.0779874213836478   |0.36685288640595903  |0.2692307692307693   |0.008316008316008316  |0.0         |0.0         |0.0          |0.0            |1.0              |0.0        |0.0        |0.0        |0.0        |0.0        |0.0        |1.0        |0.0           |0.0           |0.0            |0.0            |0.0            |0.0            |0.0             |1.0             |Very Good  |J        |VVS2       |336      |\n",
      "|0.06757215619694397  |0.536111111111111    |0.07767295597484278  |0.3677839851024209   |0.2692307692307693   |0.008316008316008316  |0.0         |0.0         |0.0          |0.0            |1.0              |0.0        |0.0        |0.0        |0.0        |0.0        |1.0        |0.0        |0.0           |0.0           |0.0            |0.0            |0.0            |0.0            |1.0             |0.0             |Very Good  |I        |VVS1       |336      |\n",
      "|0.06977928692699492  |0.5249999999999999   |0.07955974842767295  |0.3789571694599628   |0.23076923076923073  |0.012474012474012475  |0.0         |0.0         |0.0          |0.0            |1.0              |0.0        |0.0        |0.0        |0.0        |1.0        |0.0        |0.0        |0.0           |0.0           |1.0            |0.0            |0.0            |0.0            |0.0             |0.0             |Very Good  |H        |SI1        |337      |\n",
      "|0.06417657045840407  |0.6138888888888887   |0.07830188679245284  |0.36033519553072624  |0.34615384615384615  |0.004158004158004158  |1.0         |0.0         |0.0          |0.0            |0.0              |0.0        |1.0        |0.0        |0.0        |0.0        |0.0        |0.0        |0.0           |0.0           |0.0            |0.0            |0.0            |1.0            |0.0             |0.0             |Fair       |E        |VS2        |337      |\n",
      "|0.06876061120543293  |0.4555555555555555   |0.07515723270440251  |0.37243947858473     |0.34615384615384615  |0.006237006237006237  |0.0         |0.0         |0.0          |0.0            |1.0              |0.0        |0.0        |0.0        |0.0        |1.0        |0.0        |0.0        |0.0           |0.0           |0.0            |0.0            |1.0            |0.0            |0.0             |0.0             |Very Good  |H        |VS1        |338      |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Transformed dataset: \n",
      " None\n",
      "----Running Algorithm RandomForestRegressor----\n",
      "Running model pipeline RandomForestRegressor\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1300) (1304): 01b54967-0000-6d46-0000-576d0715fcee: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 77, in compute\n  File \"/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py\", line 234, in fit_wrapper_function\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/pandas/core/generic.py\", line 2150, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Ideal'\n in function SNOWPARK_TEMP_PROCEDURE_NSXYP942NX with handler compute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:368\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/framework/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(ds, data_source\u001b[38;5;241m.\u001b[39mDataSource) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_sources)\n\u001b[0;32m--> 436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/ensemble/random_forest_regressor.py:403\u001b[0m, in \u001b[0;36mRandomForestRegressor._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    392\u001b[0m model_trainer \u001b[38;5;241m=\u001b[39m ModelTrainerBuilder\u001b[38;5;241m.\u001b[39mbuild(\n\u001b[1;32m    393\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sklearn_object,\n\u001b[1;32m    394\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size,\n\u001b[1;32m    402\u001b[0m )\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sklearn_object \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:702\u001b[0m, in \u001b[0;36mSnowparkModelTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException(\n\u001b[1;32m    699\u001b[0m             error_code\u001b[38;5;241m=\u001b[39merror_codes\u001b[38;5;241m.\u001b[39mNOT_FOUND,\n\u001b[1;32m    700\u001b[0m             original_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mRuntimeError\u001b[39;00m(modeling_error_messages\u001b[38;5;241m.\u001b[39mATTRIBUTE_NOT_SET\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_cols\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    701\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sproc_export_file_name:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py:686\u001b[0m, in \u001b[0;36mSnowparkModelTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m     sproc_export_file_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mfit_wrapper_sproc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstage_transform_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstage_result_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_weight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m snowpark_exceptions\u001b[38;5;241m.\u001b[39mSnowparkClientException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/stored_procedure.py:131\u001b[0m, in \u001b[0;36mStoredProcedure.__call__\u001b[0;34m(self, session, statement_params, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_return_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_return_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/session.py:3120\u001b[0m, in \u001b[0;36mSession._call\u001b[0;34m(self, sproc_name, statement_params, is_return_table, log_on_exception, *args)\u001b[0m\n\u001b[1;32m   3119\u001b[0m set_api_call_source(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession.call\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/telemetry.py:145\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 145\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/dataframe.py:597\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params, block, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m open_telemetry_context_manager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect, \u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_collect_with_tag_no_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/dataframe.py:645\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;66;03m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mSKIP_LEVELS_THREE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:510\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m     )\n\u001b[0;32m--> 510\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:191\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    189\u001b[0m     e\n\u001b[1;32m    190\u001b[0m )\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:122\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:612\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 612\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    626\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    627\u001b[0m )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:123\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:117\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:417\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:402\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 402\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_notify_query_listener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/snowpark/_internal/server_connection.py:354\u001b[0m, in \u001b[0;36mServerConnection.execute_and_notify_query_listener\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_and_notify_query_listener\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SnowflakeCursor:\n\u001b[0;32m--> 354\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    356\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/connector/cursor.py:1080\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1080\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    344\u001b[0m cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b54967-0000-6d46-0000-576d0715fcee: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 77, in compute\n  File \"/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py\", line 234, in fit_wrapper_function\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/pandas/core/generic.py\", line 2150, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Ideal'\n in function SNOWPARK_TEMP_PROCEDURE_NSXYP942NX with handler compute",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:23\u001b[0m\n",
      "Cell \u001b[0;32mIn[35], line 274\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(session, exp_data)\u001b[0m\n\u001b[1;32m    270\u001b[0m     input_cols\u001b[38;5;241m.\u001b[39mremove(exp_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_column\u001b[39m\u001b[38;5;124m\"\u001b[39m))    \n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m#     input_cols = categorical_features+numerical_features\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m#     if exp_details.get(\"target_column\") in categorical_features:\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m#         input_cols.remove(exp_details.get(\"target_column\"))\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     model, data_pred \u001b[38;5;241m=\u001b[39m \u001b[43mrun_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Evaluate model metrices\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     metrics_info \u001b[38;5;241m=\u001b[39m eval_metrics(data_pred)\n",
      "Cell \u001b[0;32mIn[35], line 152\u001b[0m, in \u001b[0;36mrun_experiment.<locals>.run_estimator\u001b[0;34m(df_train, df_test, input_cols)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Fit the pipeline\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgorithm[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning prediction on model with test dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:373\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# already handled via a nested decorated function\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_snowflake_ml_handled\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m_snowflake_ml_handled:\n\u001b[0;32m--> 373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowpark_exceptions\u001b[38;5;241m.\u001b[39mSnowparkClientException):\n\u001b[1;32m    375\u001b[0m         me \u001b[38;5;241m=\u001b[39m snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException(\n\u001b[1;32m    376\u001b[0m             error_code\u001b[38;5;241m=\u001b[39merror_codes\u001b[38;5;241m.\u001b[39mINTERNAL_SNOWPARK_ERROR, original_exception\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m    377\u001b[0m         )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:368\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m telemetry_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    360\u001b[0m     func_name\u001b[38;5;241m=\u001b[39m_get_full_func_name(func),\n\u001b[1;32m    361\u001b[0m     function_category\u001b[38;5;241m=\u001b[39mTelemetryField\u001b[38;5;241m.\u001b[39mFUNC_CAT_USAGE\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m     custom_tags\u001b[38;5;241m=\u001b[39mcustom_tags,\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException):\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;66;03m# already handled via a nested decorated function\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/pipeline/pipeline.py:446\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, dataset, squash)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator:\n\u001b[1;32m    445\u001b[0m     all_cols \u001b[38;5;241m=\u001b[39m transformed_dataset\u001b[38;5;241m.\u001b[39mcolumns[:]\n\u001b[0;32m--> 446\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_step_feature_consumption_info(\n\u001b[1;32m    449\u001b[0m         step_name\u001b[38;5;241m=\u001b[39mestimator[\u001b[38;5;241m0\u001b[39m], all_cols\u001b[38;5;241m=\u001b[39mall_cols, input_cols\u001b[38;5;241m=\u001b[39mestimator[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget_input_cols()\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_model_signatures(dataset\u001b[38;5;241m=\u001b[39mdataset)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:390\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m update_stmt_params_if_snowpark_df(res, statement_params)\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1300) (1304): 01b54967-0000-6d46-0000-576d0715fcee: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 77, in compute\n  File \"/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/_internal/snowpark_implementations/snowpark_trainer.py\", line 234, in fit_wrapper_function\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/usr/lib/python_udf/b49e96e6278f69312fc460688053a1eeb615fb489add9ace89457c0501d89752/lib/python3.9/site-packages/pandas/core/generic.py\", line 2150, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Ideal'\n in function SNOWPARK_TEMP_PROCEDURE_NSXYP942NX with handler compute"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initilization\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=run_experiment,\n",
    "                       name=\"run_experiment\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "# tagging session\n",
    "print(\"Setting tag to session object: tag= \", run_id)\n",
    "session.query_tag=run_id\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# procedure_response = session.call(\"run_experiment\", exp_data)\n",
    "procedure_response = run_experiment(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2686dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
