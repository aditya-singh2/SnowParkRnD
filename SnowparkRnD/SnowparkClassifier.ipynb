{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9345492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68f5db93-1d4c-4b68-8098-fe02dc6bfca1\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# project_id = str(uuid.uuid4())\n",
    "run_id = str(uuid.uuid4())\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f61695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-1\n",
    "exp_data = '''{{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":{0}, \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"classification\", \n",
    "\"algo_details\": {{\"snowflake.ml.modeling.xgboost.XGBClassifier\": null}}, \n",
    "\"dataset\": \"AIRLINE_DEP_DELAY_10K\", \n",
    "\"target_column\": \"DEP_DEL15\"}}'''.format(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63281bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-2\n",
    "exp_data = f'''\\{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":{run_id}, \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": \\{\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null\\}, \n",
    "\"dataset\": \"ALCOHOL_DATA_10L\", \n",
    "\"target_column\": \"QUALITY\"\\}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-3\n",
    "exp_data = f'''\\{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":{run_id}, \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": \\{\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null\\}, \n",
    "\"dataset\": \"ALCOHOL_DATA_10L\", \n",
    "\"target_column\": \"QUALITY\"\\}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload-4\n",
    "exp_data = f'''\\{\n",
    "\"source\":\"EXP\", \n",
    "\"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \n",
    "\"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \n",
    "\"run_id\":{run_id}, \n",
    "\"exp_name\": \"Final_recipe\", \n",
    "\"algorithm_type\":\"regression\", \n",
    "\"algo_details\": \\{\"snowflake.ml.modeling.ensemble.RandomForestRegressor\": null\\}, \n",
    "\"dataset\": \"ALCOHOL_DATA_10L\", \n",
    "\"target_column\": \"QUALITY\"\\}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec151ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "        \n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure \n",
    "def run_experiment(session: Session, exp_data: str) -> list:\n",
    "    # Imports\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "    from snowflake.ml.modeling.metrics import r2_score, accuracy_score, precision_score, roc_auc_score, \\\n",
    "        f1_score, recall_score, log_loss, mean_absolute_error, mean_squared_error\n",
    "    from snowflake.snowpark.functions import col, is_null, regexp_replace, when, lit\n",
    "    from snowflake.snowpark.types import StringType\n",
    "    from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "    import importlib, sys, json, os, logging\n",
    "    from snowflake.ml.registry.registry import Registry\n",
    "    \n",
    "    \n",
    "    # Functions used in stored proc\n",
    "    def apply_data_cleansing(df):\n",
    "        \"\"\"\n",
    "        Method handles null values in snowpark dataframe.\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        df_cleaned: dataframe after null handling\n",
    "        \"\"\"\n",
    "        # fillna - Unknown and 0\n",
    "        schema_fields = df.schema.fields\n",
    "        fill_values = {field.name: \"UNKNOWN\" if isinstance(field.datatype, StringType) else 0 for field in schema_fields}\n",
    "        df_cleaned = df.fillna(fill_values)\n",
    "        return df_cleaned\n",
    "\n",
    "\n",
    "    def get_feature_columns(df):\n",
    "        \"\"\"\n",
    "        Identifies the numerical and categorical features in dataset.\n",
    "        Identifies features for label encoding and one hot encoding\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        \"\"\"\n",
    "        schema_fields = df.schema.fields\n",
    "        features = df.columns\n",
    "        features.remove(exp_details.get(\"target_column\"))\n",
    "        df_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "        categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "        categorical_features = []  \n",
    "        for row in df_schema:\n",
    "            for typ in categorical_types:\n",
    "                if typ in row['type']:\n",
    "                    categorical_features.append(row['name'])\n",
    "                    break\n",
    "        numerical_features = list(set(features) - set(categorical_features))\n",
    "        print(f\"numerical_features:  {numerical_features}\")\n",
    "        print(f\"categorical_features: {categorical_features}\")\n",
    "        \n",
    "        #identify columns for labelencoding and onehotencoding   \n",
    "        le_column_features = []\n",
    "        oh_column_features = []\n",
    "        if len(categorical_features) >= 1:\n",
    "            print(f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for column in categorical_features:\n",
    "                if df.select(df[column]).distinct().count() >= 10:\n",
    "                    le_column_features.append(column)\n",
    "                elif column == exp_details.get(\"target_column\"):\n",
    "                    le_column_feature.append(column)\n",
    "                else:\n",
    "                    oh_column_features.append(column)\n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_features}\")\n",
    "            print(f\"Columns identified to be encoded with one hot encoder: {oh_column_features}\")\n",
    "        return categorical_features, numerical_features, le_column_features, oh_column_features\n",
    "\n",
    "\n",
    "    def create_and_run_preprocessing(df, categorical_features, numerical_features, le_column_features, oh_column_features):\n",
    "        \"\"\"\n",
    "        Based on different features column input creates preprocessing steps and run it on input dataframe\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        :returns:\n",
    "        df_train: preprocessed train dataset\n",
    "        df_test: preprocessed test dataset\n",
    "        \"\"\"\n",
    "        #pipeline steps \n",
    "        print(\"Setting up preprocessing pipeline based on dataset\")\n",
    "        categorical_pp = {f'le_{column}':LabelEncoder(input_cols=column, output_cols=column) for column in le_column_features}\n",
    "        if len(oh_column_features)>0:\n",
    "            categorical_pp['oh_enc'] = OneHotEncoder(input_cols=oh_column_features, output_cols=oh_column_features, handle_unknown='ignore')\n",
    "        numerical_pp = {\n",
    "            'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "        }\n",
    "        steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_pp[key]!=[]] + \\\n",
    "        [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "        print(f\"Selected preprocesing steps: \\n{steps}\")    \n",
    "            \n",
    "        # Run preprocessing pipeline steps \n",
    "        print(\"Running data preprocessing pipeline\")\n",
    "        df = Pipeline(steps=steps).fit(df).transform(df)\n",
    "        print(f\"Transformed dataset: \\n {df.show()}\")\n",
    "        df_train, df_test = df.random_split(weights=[0.8, 0.2], seed=0)\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def run_estimator(df_train, df_test, input_cols):\n",
    "        \"\"\"\n",
    "        trains on df_train and creates model object for given algorithm/estimator.\n",
    "        runs prediction function of model object on test dataset\n",
    "        :param:\n",
    "        df_train: input training dataframe\n",
    "        df_test: input test dataframe\n",
    "        input_cols: list of input feature names\n",
    "        :returns:\n",
    "        df_pred: output predict dataframe\n",
    "        \"\"\"\n",
    "        for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "            algorithm = algorithm.rsplit('.', 1)\n",
    "            module = importlib.import_module(algorithm[0])\n",
    "            print(f\"----Running Algorithm {algorithm[1]}----\")\n",
    "            attr = getattr(module, algorithm[1])\n",
    "            pipe = Pipeline(steps=[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                                  , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                                  , output_cols=['PREDICTIONS']))]\n",
    "                   )\n",
    "    \n",
    "            # Fit the pipeline\n",
    "            print(f\"Running model pipeline {algorithm[1]}\")\n",
    "            model = pipe.fit(df_train)\n",
    "     \n",
    "            # Test the model\n",
    "            print(\"Running prediction on model with test dataset\")\n",
    "            df_pred = model.predict(df_test)\n",
    "            return model, df_pred\n",
    "\n",
    "    \n",
    "    def try_or(fn):\n",
    "        try:\n",
    "            out = fn()\n",
    "            return out\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "        \n",
    "    def eval_metrics(df_pred):\n",
    "        print(\"Generating Metrices\")\n",
    "        if exp_details.get(\"algorithm_type\") == 'classification':\n",
    "            return {\n",
    "            'accuracy_score': try_or(lambda: accuracy_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'f1_score': try_or(lambda: f1_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'recall_score': try_or(lambda: recall_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'precision_score': try_or(lambda: precision_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'roc_auc': try_or(lambda: roc_auc_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS')),\n",
    "            'log_loss': try_or(lambda: log_loss(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "            'r2_score': try_or(lambda: r2_score(df=df_pred, y_true_col_name=exp_details.get(\"target_column\"), y_pred_col_name='PREDICTIONS')),\n",
    "            'mean_absolute_error': try_or(lambda: mean_absolute_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'mean_squared_error': try_or(lambda: mean_squared_error(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "            }\n",
    "\n",
    "\n",
    "    def register_model(model, metrics_info):\n",
    "        print(\"Started: Registering model on snowflake\")\n",
    "        reg = Registry(session=session)\n",
    "        try:\n",
    "            clean = lambda x : x.replace(\"-\",\"_\")\n",
    "            project_id = clean(exp_details.get(\"project_id\"))\n",
    "            exp_id = clean(exp_details.get(\"id\"))\n",
    "            run_id = clean(exp_details.get(\"run_id\"))\n",
    "            model_name = exp_details.get(\"exp_name\")+\"_\"+project_id+\"_\"+exp_id+\"_\"+run_id\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=model_name,\n",
    "                               comment=exp_details.get(\"description\"),\n",
    "                               version_name=\"V1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"xgboost\",\"scikit-learn==1.2.2\"],\n",
    "                               metrics=[{\"model_metrics\": metrics_info, \n",
    "                                         \"project_id\": exp_details.get(\"project_id\"),\n",
    "                                         \"id\": exp_details.get(\"id\"),\n",
    "                                         \"run_id\": exp_details.get(\"run_id\"),\n",
    "                                         \"algorithm_type\": exp_details.get(\"algorithm_type\"),\n",
    "                                         \"algo_details\": exp_details.get(\"algo_details\"),\n",
    "                                         \"dataset\": exp_details.get(\"dataset\"),\n",
    "                                         \"target_column\": exp_details.get(\"target_column\"),\n",
    "                                         \"exp_name\": exp_details.get(\"exp_name\"),\n",
    "                                         \"source\": \"EXP\"}])\n",
    "            print(\"Registeration of model completed!!!\")\n",
    "            return model_name\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                print(\"Registeration of model completed!!!\")\n",
    "                return model_name\n",
    "            else:\n",
    "                print(\"Exception Occured while registering model\")\n",
    "                return str(ex).split('?')\n",
    "            \n",
    "            \n",
    "    def create_tags(session, exp_details):\n",
    "        for key in exp_details.keys():\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {key}\")\n",
    "            tag.show()\n",
    "        if exp_details.get('algorithm_type')=='classification':\n",
    "            metric_names=[\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\"]\n",
    "        else:\n",
    "            metric_names=[\"r2_score\",\"mean_absolute_error\",\"mean_squared_error\"]\n",
    "        for name in metric_names:\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {name}\")\n",
    "            tag.show()\n",
    "\n",
    "        \n",
    "    def set_tags(session, m_name, exp_details, metric_info):\n",
    "        for key, value in exp_details.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "        for key, value in metric_info.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "    \n",
    "    # loading experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    metric_names=[\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\",\"\"]\n",
    "    \n",
    "    # creating user tags if not exist\n",
    "    create_tags(session, exp_details)\n",
    "    \n",
    "    # Reading dataset\n",
    "    print(\"Reading dataset features\")\n",
    "    data = session.table(exp_details.get(\"dataset\"))\n",
    "    \n",
    "    # fillna\n",
    "    data = apply_data_cleansing(data)\n",
    "    \n",
    "    # Identify feature columns\n",
    "    categorical_features, numerical_features, le_column_features, oh_column_features = get_feature_columns(data)\n",
    "    \n",
    "    # Based on feature, do preprocessing\n",
    "    data_train, data_test = create_and_run_preprocessing(data, categorical_features, numerical_features, le_column_features, oh_column_features)\n",
    "    \n",
    "    # Run model training and prediction\n",
    "    input_cols = categorical_features+numerical_features\n",
    "    if exp_details.get(\"target_column\") in categorical_features:\n",
    "        input_cols.remove(exp_details.get(\"target_column\"))\n",
    "    model, data_pred = run_estimator(data_train, data_test, input_cols)\n",
    "    \n",
    "    # Evaluate model metrices\n",
    "    metrics_info = eval_metrics(data_pred)\n",
    "    print(metrics_info)\n",
    "    \n",
    "    # Register model on snowflake registry\n",
    "    model_name = register_model(model, metrics_info)\n",
    "    print(model_name)\n",
    "    \n",
    "    # Set relevant tags to model object\n",
    "    set_tags(session, model_name, exp_details, metrics_info)\n",
    "    \n",
    "    return [{\"exp_name\":exp_details.get(\"exp_name\", \"sample_experiment\"),\n",
    "             \"version\":\"V1\",\n",
    "             \"matrices\":{\"model_metrics\": metrics_info, \"project_id\": \"0001\", \"source\": \"EXP\"},\n",
    "             \"algorithm_type\":exp_details.get(\"algorithm_type\"),\n",
    "             \"algorithm\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_model_name\":exp_details.get(\"exp_name\")+\"_\"+exp_details.get(\"project_id\")+\"_\"+exp_details.get(\"id\")+\"_\"+exp_details.get(\"run_id\")}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "914d9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "Stored procedure has been created successfully!\n",
      "Setting tag to session object: tag=  bd215cc2-d2a2-44cb-961d-3254fed94b25\n",
      "Executing Procedure\n",
      "-----------------------------------------------\n",
      "|\"status\"                                     |\n",
      "-----------------------------------------------\n",
      "|SOURCE already exists, statement succeeded.  |\n",
      "-----------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|PROJECT_ID already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "|\"status\"                                 |\n",
      "-------------------------------------------\n",
      "|ID already exists, statement succeeded.  |\n",
      "-------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "|\"status\"                                     |\n",
      "-----------------------------------------------\n",
      "|RUN_ID already exists, statement succeeded.  |\n",
      "-----------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|EXP_NAME already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_TYPE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|ALGO_DETAILS already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|DATASET already exists, statement succeeded.  |\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|TARGET_COLUMN already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "--------------------------------------\n",
      "|\"status\"                            |\n",
      "--------------------------------------\n",
      "|Tag R2_SCORE successfully created.  |\n",
      "--------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|Tag MEAN_ABSOLUTE_ERROR successfully created.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|Tag MEAN_SQUARED_ERROR successfully created.  |\n",
      "------------------------------------------------\n",
      "\n",
      "Reading dataset features\n",
      "numerical_features:  ['FIXED_ACIDITY', 'SULPHATES', 'FREE_SULFUR_DIOXIDE', 'PH', 'CITRIC_ACID', 'CHLORIDES', 'RESIDUAL_SUGAR', 'VOLATILE_ACIDITY', 'DENSITY', 'ALCOHOL', 'TOTAL_SULFUR_DIOXIDE']\n",
      "categorical_features: []\n",
      "Setting up preprocessing pipeline based on dataset\n",
      "Selected preprocesing steps: \n",
      "[('scaler', <snowflake.ml.modeling.preprocessing.min_max_scaler.MinMaxScaler object at 0x7fa91255e190>)]\n",
      "Running data preprocessing pipeline\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"FIXED_ACIDITY\"      |\"SULPHATES\"          |\"FREE_SULFUR_DIOXIDE\"  |\"PH\"                 |\"CITRIC_ACID\"  |\"CHLORIDES\"          |\"RESIDUAL_SUGAR\"     |\"VOLATILE_ACIDITY\"   |\"DENSITY\"           |\"ALCOHOL\"            |\"TOTAL_SULFUR_DIOXIDE\"  |\"QUALITY\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.24778761061946908  |0.13772455089820365  |0.14084507042253522    |0.606299212598425    |0.0            |0.10684474123539231  |0.0684931506849315   |0.39726027397260266  |0.567547723935391   |0.15384615384615397  |0.0989399293286219      |5          |\n",
      "|0.2831858407079646   |0.2095808383233533   |0.33802816901408456    |0.3622047244094486   |0.0            |0.14357262103505844  |0.11643835616438356  |0.5205479452054794   |0.4941262848751933  |0.2153846153846155   |0.215547703180212       |5          |\n",
      "|0.2831858407079646   |0.1916167664670659   |0.19718309859154928    |0.4094488188976375   |0.04           |0.1335559265442404   |0.0958904109589041   |0.4383561643835616   |0.5088105726872243  |0.2153846153846155   |0.16961130742049468     |5          |\n",
      "|0.5840707964601769   |0.1497005988023952   |0.22535211267605634    |0.3307086614173227   |0.56           |0.10517529215358931  |0.0684931506849315   |0.10958904109589043  |0.5822320117474362  |0.2153846153846155   |0.19081272084805656     |6          |\n",
      "|0.24778761061946908  |0.13772455089820365  |0.14084507042253522    |0.606299212598425    |0.0            |0.10684474123539231  |0.0684931506849315   |0.39726027397260266  |0.567547723935391   |0.15384615384615397  |0.0989399293286219      |5          |\n",
      "|0.24778761061946908  |0.13772455089820365  |0.16901408450704225    |0.606299212598425    |0.0            |0.10517529215358931  |0.06164383561643835  |0.3698630136986301   |0.567547723935391   |0.15384615384615397  |0.12014134275618375     |5          |\n",
      "|0.2920353982300885   |0.07784431137724554  |0.19718309859154928    |0.44094488188976344  |0.06           |0.0951585976627713   |0.04794520547945205  |0.3287671232876712   |0.4647577092511028  |0.15384615384615397  |0.1872791519434629      |5          |\n",
      "|0.23893805309734517  |0.08383233532934128  |0.19718309859154928    |0.5118110236220472   |0.0            |0.08848080133555926  |0.02054794520547945  |0.363013698630137    |0.3325991189427384  |0.24615384615384617  |0.053003533568904596    |7          |\n",
      "|0.2831858407079646   |0.1437125748502994   |0.11267605633802817    |0.48818897637795233  |0.02           |0.10183639398998329  |0.07534246575342465  |0.3150684931506849   |0.4941262848751933  |0.1692307692307693   |0.04240282685512367     |7          |\n",
      "|0.256637168141593    |0.281437125748503    |0.22535211267605634    |0.4803149606299213   |0.36           |0.09849749582637728  |0.3561643835616438   |0.2602739726027397   |0.567547723935391   |0.32307692307692304  |0.3392226148409894      |5          |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Transformed dataset: \n",
      " None\n",
      "----Running Algorithm RandomForestRegressor----\n",
      "Running model pipeline RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on model with test dataset\n",
      "Generating Metrices\n",
      "{'r2_score': 1.0, 'mean_absolute_error': 0.0, 'mean_squared_error': 0.0}\n",
      "Started: Registering model on snowflake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/contextlib.py:119: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registeration of model completed!!!\n",
      "Final_recipe_0e0fb803_22db_4d88_9f2f_f6f75b6abcf0_7bbb5061_54d4_4862_8d47_7fbee388a4d1_bd215cc2_d2a2_44cb_961d_3254fed94b25\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "Stored Procedure Executed Successfully !\n",
      "[{'exp_name': 'Final_recipe', 'version': 'V1', 'matrices': {'model_metrics': {'r2_score': 1.0, 'mean_absolute_error': 0.0, 'mean_squared_error': 0.0}, 'project_id': '0001', 'source': 'EXP'}, 'algorithm_type': 'regression', 'algorithm': ['snowflake.ml.modeling.ensemble.RandomForestRegressor'], 'RUN_STATUS': 'SUCCESS', 'registry_model_name': 'Final_recipe_0e0fb803-22db-4d88-9f2f-f6f75b6abcf0_7bbb5061-54d4-4862-8d47-7fbee388a4d1_bd215cc2-d2a2-44cb-961d-3254fed94b25'}]\n",
      "Logging in mlflow completed !\n",
      "CPU times: user 9.3 s, sys: 971 ms, total: 10.3 s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initilization\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=run_experiment,\n",
    "                       name=\"run_experiment\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "# tagging session\n",
    "print(\"Setting tag to session object: tag= \", run_id)\n",
    "session.query_tag=run_id\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# procedure_response = session.call(\"run_experiment\", exp_data)\n",
    "procedure_response = run_experiment(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2686dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
