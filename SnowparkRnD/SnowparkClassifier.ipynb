{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec151ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "        \n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure \n",
    "def run_experiment(session: Session, exp_data: str) -> list:\n",
    "    # Imports\n",
    "    from snowflake.snowpark.session import Session\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "    from snowflake.ml.modeling.metrics import r2_score, accuracy_score, precision_score, roc_auc_score, \\\n",
    "        f1_score, recall_score, log_loss\n",
    "    from snowflake.snowpark.functions import col, is_null, regexp_replace, when, lit\n",
    "    from snowflake.snowpark.types import StringType\n",
    "    from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "    import importlib, sys, json, os, logging\n",
    "    from snowflake.ml.registry.registry import Registry\n",
    "    \n",
    "    \n",
    "    # Functions used in stored proc\n",
    "    def apply_data_cleansing(df):\n",
    "        \"\"\"\n",
    "        Method handles null values in snowpark dataframe.\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        df_cleaned: dataframe after null handling\n",
    "        \"\"\"\n",
    "        # fillna - Unknown and 0\n",
    "        schema_fields = df.schema.fields\n",
    "        fill_values = {field.name: \"UNKNOWN\" if isinstance(field.datatype, StringType) else 0 for field in schema_fields}\n",
    "        df_cleaned = df.fillna(fill_values)\n",
    "        return df_cleaned\n",
    "\n",
    "\n",
    "    def get_feature_columns(df):\n",
    "        \"\"\"\n",
    "        Identifies the numerical and categorical features in dataset.\n",
    "        Identifies features for label encoding and one hot encoding\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        :returns:\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        \"\"\"\n",
    "        schema_fields = df.schema.fields\n",
    "        features = df.columns\n",
    "        features.remove(exp_details.get(\"target_column\"))\n",
    "        df_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "        categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "        categorical_features = []  \n",
    "        for row in df_schema:\n",
    "            for typ in categorical_types:\n",
    "                if typ in row['type']:\n",
    "                    categorical_features.append(row['name'])\n",
    "                    break\n",
    "        numerical_features = list(set(features) - set(categorical_features))\n",
    "        print(f\"numerical_features:  {numerical_features}\")\n",
    "        print(f\"categorical_features: {categorical_features}\")\n",
    "        \n",
    "        #identify columns for labelencoding and onehotencoding   \n",
    "        le_column_features = []\n",
    "        oh_column_features = []\n",
    "        if len(categorical_features) >= 1:\n",
    "            print(f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for column in categorical_features:\n",
    "                if df.select(df[column]).distinct().count() >= 10:\n",
    "                    le_column_features.append(column)\n",
    "                elif column == exp_details.get(\"target_column\"):\n",
    "                    le_column_feature.append(column)\n",
    "                else:\n",
    "                    oh_column_features.append(column)\n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_features}\")\n",
    "            print(f\"Columns identified to be encoded with one hot encoder: {oh_column_features}\")\n",
    "        return categorical_features, numerical_features, le_column_features, oh_column_features\n",
    "\n",
    "\n",
    "    def create_and_run_preprocessing(df, categorical_features, numerical_features, le_column_features, oh_column_features):\n",
    "        \"\"\"\n",
    "        Based on different features column input creates preprocessing steps and run it on input dataframe\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        categorical_features: list of non-numerical feature columns\n",
    "        numerical_features: list of numerical feature columns\n",
    "        le_column_features: list of feature label encoder columns\n",
    "        oh_column_features: list of feature one hot encoder columns\n",
    "        :returns:\n",
    "        df_train: preprocessed train dataset\n",
    "        df_test: preprocessed test dataset\n",
    "        \"\"\"\n",
    "        #pipeline steps \n",
    "        print(\"Setting up preprocessing pipeline based on dataset\")\n",
    "        categorical_pp = {f'le_{column}':LabelEncoder(input_cols=column, output_cols=column) for column in le_column_features}\n",
    "        if len(oh_column_features)>0:\n",
    "            categorical_pp['oh_enc'] = OneHotEncoder(input_cols=oh_column_features, output_cols=oh_column_features, handle_unknown='ignore')\n",
    "        numerical_pp = {\n",
    "            'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "        }\n",
    "        steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_pp[key]!=[]] + \\\n",
    "        [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "        print(f\"Selected preprocesing steps: \\n{steps}\")    \n",
    "            \n",
    "        # Run preprocessing pipeline steps \n",
    "        print(\"Running data preprocessing pipeline\")\n",
    "        df = Pipeline(steps=steps).fit(df).transform(df)\n",
    "        print(f\"Transformed dataset: \\n {df.show()}\")\n",
    "        df_train, df_test = df.random_split(weights=[0.8, 0.2], seed=0)\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def run_estimator(df_train, df_test, input_cols):\n",
    "        \"\"\"\n",
    "        trains on df_train and creates model object for given algorithm/estimator.\n",
    "        runs prediction function of model object on test dataset\n",
    "        :param:\n",
    "        df_train: input training dataframe\n",
    "        df_test: input test dataframe\n",
    "        input_cols: list of input feature names\n",
    "        :returns:\n",
    "        df_pred: output predict dataframe\n",
    "        \"\"\"\n",
    "        for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "            algorithm = algorithm.rsplit('.', 1)\n",
    "            module = importlib.import_module(algorithm[0])\n",
    "            print(f\"----Running Algorithm {algorithm[1]}----\")\n",
    "            attr = getattr(module, algorithm[1])\n",
    "            pipe = Pipeline(steps=[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                                  , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                                  , output_cols=['PREDICTIONS']))]\n",
    "                   )\n",
    "    \n",
    "            # Fit the pipeline\n",
    "            print(f\"Running model pipeline {algorithm[1]}\")\n",
    "            model = pipe.fit(df_train)\n",
    "     \n",
    "            # Test the model\n",
    "            print(\"Running prediction on model with test dataset\")\n",
    "            df_pred = model.predict(df_test)\n",
    "            return model, df_pred\n",
    "\n",
    "    \n",
    "    def try_or(fn):\n",
    "        try:\n",
    "            out = fn()\n",
    "            return out\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "        \n",
    "    def eval_metrics(df_pred):\n",
    "        print(\"Generating Metrices\")\n",
    "        return {\n",
    "            'accuracy': try_or(lambda: accuracy_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'f1_score': try_or(lambda: f1_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'recall': try_or(lambda: recall_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'precision': try_or(lambda: precision_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS')),\n",
    "            'roc_auc': try_or(lambda: roc_auc_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS')),\n",
    "            'log_loss': try_or(lambda: log_loss(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS'))\n",
    "        }\n",
    "\n",
    "\n",
    "    def register_model(model, metrics_info):\n",
    "        print(\"Started: Registering model on snowflake\")\n",
    "        reg = Registry(session=session)\n",
    "        try:\n",
    "            model_name = exp_exp_details.get(\"project_id\")+\"_\"+exp_details.get(\"id\")+\"_\"+exp_details.get(\"run_id\")\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=model_name,\n",
    "                               comment=exp_details.get(\"description\"),\n",
    "                               version_name=\"V1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"xgboost\",\"scikit-learn==1.2.2\"],\n",
    "                               metrics=[{\"model_metrics\": metrics_info, \n",
    "                                         \"project_id\": exp_details.get(\"project_id\"),\n",
    "                                         \"id\": exp_details.get(\"id\"),\n",
    "                                         \"run_id\": exp_details.get(\"run_id\"),\n",
    "                                         \"algorithm_type\": exp_details.get(\"algorithm_type\"),\n",
    "                                         \"algo_details\": exp_details.get(\"algo_details\"),\n",
    "                                         \"dataset\": exp_details.get(\"dataset\"),\n",
    "                                         \"target_column\": exp_details.get(\"target_column\"),\n",
    "                                         \"exp_name\": exp_details.get(\"exp_name\"),\n",
    "                                         \"source\": \"EXP\"}])\n",
    "            print(\"Registeration of model completed!!!\")\n",
    "            return model_name\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "                pass\n",
    "            else:\n",
    "                log_message(\"ERROR\",\"Exception Occured while registering model\")\n",
    "                return str(ex).split('?')\n",
    "            \n",
    "            \n",
    "    def create_tags(session, exp_details, metric_names):\n",
    "        for key in exp_details.keys():\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {key}\")\n",
    "            tag.show()\n",
    "        for name in metric_names:\n",
    "            tag = session.sql(f\"CREATE TAG IF NOT EXISTS {name}\")\n",
    "            tag.show()\n",
    "\n",
    "        \n",
    "    def set_tags(session, m_name, exp_details, metric_info):\n",
    "        for key, value in exp_details.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "        for key, value in metric_info.items():\n",
    "            value = str(value).replace(\"'\",\"\\\"\")\n",
    "            tag = session.sql(f\"ALTER MODEL IF EXISTS {m_name} SET TAG {key}='{value}'\")\n",
    "            tag.show()\n",
    "    \n",
    "    # loading experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    metric_names=[\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\"]\n",
    "    \n",
    "    # creating user tags if not exist\n",
    "    create_tags(session, exp_details, metric_names)\n",
    "    \n",
    "    # Reading dataset\n",
    "    print(\"Reading dataset features\")\n",
    "    data = session.table(exp_details.get(\"dataset\"))\n",
    "    \n",
    "    # fillna\n",
    "    data = apply_data_cleansing(data)\n",
    "    \n",
    "    # Identify feature columns\n",
    "    categorical_features, numerical_features, le_column_features, oh_column_features = get_feature_columns(data)\n",
    "    \n",
    "    # Based on feature, do preprocessing\n",
    "    data_train, data_test = create_and_run_preprocessing(data, categorical_features, numerical_features, le_column_features, oh_column_features)\n",
    "    \n",
    "    # Run model training and prediction\n",
    "    input_cols = categorical_features+numerical_features\n",
    "    if exp_details.get(\"target_column\") in categorical_features:\n",
    "        input_cols.remove(exp_details.get(\"target_column\"))\n",
    "    model, data_pred = run_estimator(data_train, data_test, input_cols)\n",
    "    \n",
    "    # Evaluate model metrices\n",
    "    metrics_info = eval_metrics(data_pred)\n",
    "    \n",
    "    # Register model on snowflake registry\n",
    "    model_name = register_model(model, metrics_info)\n",
    "    \n",
    "    # Set relevant tags to model object\n",
    "    set_tags(session, model_name, exp_details, metric_info)\n",
    "    \n",
    "    return [{\"exp_name\":exp_details.get(\"exp_name\", \"sample_experiment\"),\n",
    "             \"version\":\"V1\",\n",
    "             \"matrices\":{\"model_metrics\": metrics_info, \"project_id\": \"0001\", \"source\": \"EXP\"},\n",
    "             \"algorithm_type\":exp_details.get(\"algorithm_type\"),\n",
    "             \"algorithm\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_model_name\":exp_details.get(\"project_id\")+\"_\"+exp_details.get(\"id\")+\"_\"+exp_details.get(\"run_id\")}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd4ed1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3cc38fbf-f6e3-42f9-933b-5b9557fe649e\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# project_id = str(uuid.uuid4())\n",
    "run_id = str(uuid.uuid4())\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "914d9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "Session has been created !\n",
      "Creating stored procedure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.18.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'snowflake-ml-python' in the local environment is 1.5.1, which does not fit the criteria for the requirement 'snowflake-ml-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored procedure has been created successfully!\n",
      "Setting tag to session object 3cc38fbf-f6e3-42f9-933b-5b9557fe649e\n",
      "Executing Procedure\n",
      "-----------------------------------------------\n",
      "|\"status\"                                     |\n",
      "-----------------------------------------------\n",
      "|SOURCE already exists, statement succeeded.  |\n",
      "-----------------------------------------------\n",
      "\n",
      "---------------------------------------------------\n",
      "|\"status\"                                         |\n",
      "---------------------------------------------------\n",
      "|PROJECT_ID already exists, statement succeeded.  |\n",
      "---------------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "|\"status\"                                 |\n",
      "-------------------------------------------\n",
      "|ID already exists, statement succeeded.  |\n",
      "-------------------------------------------\n",
      "\n",
      "-----------------------------------------------\n",
      "|\"status\"                                     |\n",
      "-----------------------------------------------\n",
      "|RUN_ID already exists, statement succeeded.  |\n",
      "-----------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|EXP_NAME already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ALGORITHM_TYPE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|ALGO_DETAILS already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|DATASET already exists, statement succeeded.  |\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|TARGET_COLUMN already exists, statement succeeded.  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|ACCURACY_SCORE already exists, statement succee...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------\n",
      "|\"status\"                                            |\n",
      "------------------------------------------------------\n",
      "|PRECISION_SCORE already exists, statement succe...  |\n",
      "------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------\n",
      "|\"status\"                                           |\n",
      "-----------------------------------------------------\n",
      "|RECALL_SCORE already exists, statement succeeded.  |\n",
      "-----------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|F1_SCORE already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "|\"status\"                                      |\n",
      "------------------------------------------------\n",
      "|ROC_AUC already exists, statement succeeded.  |\n",
      "------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "|\"status\"                                       |\n",
      "-------------------------------------------------\n",
      "|LOG_LOSS already exists, statement succeeded.  |\n",
      "-------------------------------------------------\n",
      "\n",
      "Reading dataset features\n",
      "numerical_features:  ['DEP_BLOCK_HIST', 'DISTANCE_GROUP', 'DAY_OF_WEEK', 'SNWD', 'MONTH', 'AIRLINE_AIRPORT_FLIGHTS_MONTH', 'AVG_MONTHLY_PASS_AIRLINE', 'NUMBER_OF_SEATS', 'TMAX', 'DAY_HISTORICAL', 'LATITUDE', 'PLANE_AGE', 'DEP_AIRPORT_HIST', 'CONCURRENT_FLIGHTS', 'FLT_ATTENDANTS_PER_PASS', 'GROUND_SERV_PER_PASS', 'LONGITUDE', 'SNOW', 'AVG_MONTHLY_PASS_AIRPORT', 'AIRPORT_FLIGHTS_MONTH', 'CARRIER_HISTORICAL', 'PRCP', 'AWND', 'AIRLINE_FLIGHTS_MONTH', 'SEGMENT_NUMBER']\n",
      "categorical_features: ['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT']\n",
      "['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT'] columns are non numeric in feature dataset, encoding required.\n",
      "Columns identified to be encoded with label encoder: ['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT']\n",
      "Columns identified to be encoded with one hot encoder: []\n",
      "Setting up preprocessing pipeline based on dataset\n",
      "Selected preprocesing steps: \n",
      "[('le_DEP_TIME_BLK', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7f62ea6a1e20>), ('le_CARRIER_NAME', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7f62ea6a1ee0>), ('le_DEPARTING_AIRPORT', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7f62ea5d7460>), ('le_PREVIOUS_AIRPORT', <snowflake.ml.modeling.preprocessing.label_encoder.LabelEncoder object at 0x7f62ea5d7ee0>), ('scaler', <snowflake.ml.modeling.preprocessing.min_max_scaler.MinMaxScaler object at 0x7f62ea6a1460>)]\n",
      "Running data preprocessing pipeline\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"DEP_BLOCK_HIST\"     |\"DISTANCE_GROUP\"     |\"DAY_OF_WEEK\"        |\"SNWD\"  |\"MONTH\"              |\"AIRLINE_AIRPORT_FLIGHTS_MONTH\"  |\"AVG_MONTHLY_PASS_AIRLINE\"  |\"NUMBER_OF_SEATS\"     |\"TMAX\"              |\"DAY_HISTORICAL\"     |\"LATITUDE\"           |\"PLANE_AGE\"  |\"DEP_AIRPORT_HIST\"   |\"CONCURRENT_FLIGHTS\"  |\"FLT_ATTENDANTS_PER_PASS\"  |\"GROUND_SERV_PER_PASS\"  |\"LONGITUDE\"          |\"SNOW\"  |\"AVG_MONTHLY_PASS_AIRPORT\"  |\"AIRPORT_FLIGHTS_MONTH\"  |\"CARRIER_HISTORICAL\"  |\"PRCP\"               |\"AWND\"               |\"AIRLINE_FLIGHTS_MONTH\"  |\"SEGMENT_NUMBER\"     |\"PREVIOUS_AIRPORT\"  |\"DEPARTING_AIRPORT\"  |\"CARRIER_NAME\"  |\"DEP_TIME_BLK\"  |\"DEP_DEL15\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.27522497654814015  |0.20000000000000004  |0.8333333333333334   |0.0     |0.2727272727272727   |0.008061191773920211             |0.9285148853085841          |0.2252559726962457    |0.5526315789473684  |0.43711144076048003  |0.5321264783972965   |0.5625       |0.44336796949528057  |0.037037037037037035  |0.41378505475033117        |0.6379310766886747      |0.8040475281327912   |0.0     |0.1744465023043245          |0.16796463286099078      |0.26291914704819064   |0.0                  |0.40981061782055256  |0.6796586592477664       |0.15384615384615385  |14.0                |10.0                 |6.0             |5.0             |0            |\n",
      "|0.2999138493221676   |0.1                  |0.16666666666666666  |0.0     |0.1818181818181818   |0.08940594512893327              |0.05725000106513142         |0.020477815699658702  |0.4122807017543859  |0.17092516018353376  |0.5078445570842386   |0.46875      |0.46790582787760393  |0.2777777777777778    |0.0                        |0.389352166528466       |0.9598840996383727   |0.0     |0.26489499288156393         |0.39085372994495843      |0.31894490003018344   |0.0                  |0.3542378143433716   |0.14810158186649547      |0.07692307692307693  |17.0                |37.0                 |7.0             |5.0             |0            |\n",
      "|0.393752088147564    |0.7000000000000001   |0.6666666666666666   |0.0     |0.09090909090909091  |0.21412540649475564              |0.621869201085582           |0.4402730375426621    |0.4649122807017544  |0.7970363849819914   |0.48358677286990104  |0.21875      |0.6377352756633737   |0.3333333333333333    |0.728469163216533          |1.0                     |0.6116888659284383   |0.0     |0.6222891447050592          |0.4517507904906898       |0.4376340377790309    |0.0                  |0.29183483390251475  |0.3382198205910153       |0.07692307692307693  |155.0               |85.0                 |16.0            |5.0             |0            |\n",
      "|0.23821544388258592  |1.0                  |0.8333333333333334   |0.0     |0.2727272727272727   |0.07442861723079741              |0.1867189342798414          |0.4675767918088737    |0.5526315789473684  |0.43711144076048003  |0.3428192131305817   |0.09375      |0.22484374207293006  |0.3333333333333333    |0.09279779051350562        |0.7548621460569017      |0.4597605624312122   |0.0     |0.6309663029648315          |0.4807940039817309       |0.23761938592506038   |0.0                  |0.20832039739211425  |0.13869420220070267      |0.07692307692307693  |216.0               |42.0                 |0.0             |4.0             |0            |\n",
      "|0.2462535919283162   |0.0                  |0.9999999999999999   |0.0     |0.6363636363636364   |0.2799432052397747               |1.0                         |0.3378839590443686    |0.9035087719298245  |0.5537678055932115   |0.3944243301955105   |0.625        |0.2593267896354779   |0.24074074074074076   |0.17732779474678284        |0.4136087725182285      |0.49632757575076925  |0.0     |0.42672806875606056         |0.3841199203653824       |0.44831874767540897   |0.0                  |0.13194660043464762  |0.9755586467640397       |0.07692307692307693  |259.0               |44.0                 |14.0            |4.0             |0            |\n",
      "|0.16483297144790038  |0.5000000000000001   |0.33333333333333337  |0.0     |0.4545454545454545   |0.272523244629689                |1.0                         |0.3378839590443686    |0.719298245614035   |0.7983002781408416   |0.48358677286990104  |0.40625      |0.5130004122713442   |0.4074074074074074    |0.17732779474678284        |0.4136087725182285      |0.6116888659284383   |0.0     |0.6222891447050592          |0.6083265019323106       |0.6835133676808427    |0.0                  |0.222291213908724    |0.9567617213275551       |0.07692307692307693  |75.0                |85.0                 |14.0            |2.0             |1            |\n",
      "|0.5192743030487511   |0.5000000000000001   |0.16666666666666666  |0.0     |0.0                  |0.09623047680117254              |0.621869201085582           |0.4402730375426621    |0.5087719298245613  |0.33104429030044114  |0.3428192131305817   |0.3125       |0.47062819673673706  |0.25                  |0.728469163216533          |1.0                     |0.4597605624312122   |0.0     |0.6309663029648315          |0.4867373228715306       |0.4109977896863793    |0.06641000962463907  |0.2430922073890096   |0.3623490806627076       |0.15384615384615385  |264.0               |42.0                 |16.0            |12.0            |0            |\n",
      "|0.29990579148013163  |0.5000000000000001   |0.0                  |0.0     |0.36363636363636365  |0.2334081436357807               |1.0                         |0.3378839590443686    |0.7894736842105262  |0.5366181916156211   |0.3306058411778904   |0.40625      |0.47795218540281403  |0.3425925925925926    |0.17732779474678284        |0.4136087725182285      |0.5316255250331303   |0.0     |0.4089989139000998          |0.39480618339384005      |0.6444875414157234    |0.0                  |0.16671841043154298  |0.9641627877944822       |0.15384615384615385  |115.0               |62.0                 |14.0            |5.0             |0            |\n",
      "|0.4128670736253012   |0.0                  |0.9999999999999999   |0.0     |0.9999999999999999   |0.2353318371272844               |1.0                         |0.3378839590443686    |0.4035087719298245  |0.7369822873786812   |0.3944243301955105   |0.34375      |0.3877976982709225   |0.2222222222222222    |0.17732779474678284        |0.4136087725182285      |0.49632757575076925  |0.0     |0.42672806875606056         |0.3528516219697857       |0.698429722790137     |0.0                  |0.04874262651350513  |0.960052074973695        |0.15384615384615385  |290.0               |44.0                 |14.0            |6.0             |0            |\n",
      "|0.1156724618565313   |0.4                  |0.16666666666666666  |0.0     |0.9090909090909091   |0.8932350112215454               |0.9285148853085841          |0.4641638225255973    |0.5438596491228069  |0.2927938912198539   |0.33555394641564074  |0.125        |0.46790582787760393  |0.8425925925925926    |0.41378505475033117        |0.6379310766886747      |0.8413894566609015   |0.0     |1.0                         |0.8798161377210446       |0.12760892299347198   |0.0                  |0.1875194039118286   |0.663483316391133        |0.0                  |186.0               |4.0                  |6.0             |3.0             |0            |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Transformed dataset: \n",
      " None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Running Algorithm XGBClassifier----\n",
      "Running model pipeline XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.18.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on model with test dataset\n",
      "Generating Metrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataFrame.flatten() is deprecated since 0.7.0. Use `DataFrame.join_table_function()` instead.\n",
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.18.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: Registering model on snowflake\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'log_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:368\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/registry/registry.py:156\u001b[0m, in \u001b[0;36mRegistry.log_model\u001b[0;34m(self, model, model_name, version_name, comment, metrics, conda_dependencies, pip_requirements, python_version, signatures, sample_input_data, code_paths, ext_modules, options)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently `pip_requirements` is not supported since Model can only executed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min Snowflake Warehouse where all dependencies are required to be retrieved \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom Snowflake Anaconda Channel.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_dependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpython_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_input_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_input_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mext_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mext_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/registry/_manager/model_manager.py:51\u001b[0m, in \u001b[0;36mModelManager.log_model\u001b[0;34m(self, model, model_name, version_name, comment, metrics, conda_dependencies, pip_requirements, python_version, signatures, sample_input_data, code_paths, ext_modules, options, statement_params)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     35\u001b[0m     model: model_types\u001b[38;5;241m.\u001b[39mSupportedModelType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     statement_params: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m model_version_impl\u001b[38;5;241m.\u001b[39mModelVersion:\n\u001b[0;32m---> 51\u001b[0m     database_name_id, schema_name_id, model_name_id \u001b[38;5;241m=\u001b[39m \u001b[43msql_identifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_fully_qualified_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version_name:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/utils/sql_identifier.py:87\u001b[0m, in \u001b[0;36mparse_fully_qualified_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_fully_qualified_name\u001b[39m(\n\u001b[1;32m     85\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     86\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[SqlIdentifier], Optional[SqlIdentifier], SqlIdentifier]:\n\u001b[0;32m---> 87\u001b[0m     db, schema, \u001b[38;5;28mobject\u001b[39m, _ \u001b[38;5;241m=\u001b[39m \u001b[43midentifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_schema_level_object_identifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable parse the input name `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` as fully qualified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/utils/identifier.py:159\u001b[0m, in \u001b[0;36mparse_schema_level_object_identifier\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid identifier. It should start with database.schema.object. Getting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    161\u001b[0m     res\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    162\u001b[0m     res\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    163\u001b[0m     res\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    164\u001b[0m     res\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mothers\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    165\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid identifier. It should start with database.schema.object. Getting 0e0fb803-22db-4d88-9f2f-f6f75b6abcf0_7bbb5061-54d4-4862-8d47-7fbee388a4d1_afb65a5a-082f-4f47-bc98-92de1d3a4055",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 186\u001b[0m, in \u001b[0;36mrun_experiment.<locals>.register_model\u001b[0;34m(model, metrics_info)\u001b[0m\n\u001b[1;32m    185\u001b[0m model_name \u001b[38;5;241m=\u001b[39m exp_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mexp_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mexp_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 186\u001b[0m mv \u001b[38;5;241m=\u001b[39m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mversion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mV1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpython_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3.9.19\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mconda_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscikit-learn==1.2.2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_metrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malgorithm_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malgorithm_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malgo_details\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malgo_details\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_column\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_column\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexp_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexp_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEXP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegisteration of model completed!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:390\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: (0000) Invalid identifier. It should start with database.schema.object. Getting 0e0fb803-22db-4d88-9f2f-f6f75b6abcf0_7bbb5061-54d4-4862-8d47-7fbee388a4d1_afb65a5a-082f-4f47-bc98-92de1d3a4055",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:25\u001b[0m\n",
      "Cell \u001b[0;32mIn[26], line 264\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(session, exp_data)\u001b[0m\n\u001b[1;32m    261\u001b[0m metrics_info \u001b[38;5;241m=\u001b[39m eval_metrics(data_pred)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Register model on snowflake registry\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[43mregister_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Set relevant tags to model object\u001b[39;00m\n\u001b[1;32m    267\u001b[0m set_tags(session, model_name, exp_details, metric_info)\n",
      "Cell \u001b[0;32mIn[26], line 210\u001b[0m, in \u001b[0;36mrun_experiment.<locals>.register_model\u001b[0;34m(model, metrics_info)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     \u001b[43mlog_message\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException Occured while registering model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ex)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_message' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initilization\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=run_experiment,\n",
    "                       name=\"run_experiment\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "# payload\n",
    "exp_data = '{\"source\":\"EXP\", \"project_id\":\"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\", \"id\":\"7bbb5061-54d4-4862-8d47-7fbee388a4d1\", \"run_id\":\"afb65a5a-082f-4f47-bc98-92de1d3a4055\", \"exp_name\": \"py_func_exp23\", \"algorithm_type\":\"classification\", \"algo_details\": {\"snowflake.ml.modeling.xgboost.XGBClassifier\": null}, \"dataset\": \"AIRLINE_DEP_DELAY_10K\", \"target_column\": \"DEP_DEL15\"}'\n",
    "\n",
    "# tagging session\n",
    "print(\"Setting tag to session object\", run_id)\n",
    "session.query_tag='afb65a5a-082f-4f47-bc98-92de1d3a4055'\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "procedure_response = session.call(\"run_experiment\", exp_data)\n",
    "# procedure_response = run_experiment(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae27996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
