{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from snowflake.ml.modeling.metrics import r2_score, accuracy_score, precision_score, roc_auc_score, \\\n",
    "    f1_score, recall_score, log_loss\n",
    "from snowflake.snowpark.functions import col, is_null, regexp_replace, when, lit\n",
    "from snowflake.snowpark.types import StringType\n",
    "from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "import importlib, sys, json, os, logging\n",
    "from snowflake.ml.registry.registry import Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec151ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "        \n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "        \n",
    "        \n",
    "def apply_data_cleansing(df):\n",
    "    \"\"\"\n",
    "    Method handles null values in snowpark dataframe.\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    :returns:\n",
    "    df_cleaned: dataframe after null handling\n",
    "    \"\"\"\n",
    "    # fillna - Unknown and 0\n",
    "    schema_fields = df.schema.fields\n",
    "    fill_values = {field.name: \"UNKNOWN\" if isinstance(field.datatype, StringType) else 0 for field in schema_fields}\n",
    "    df_cleaned = df.fillna(fill_values)\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def get_feature_columns(df):\n",
    "    \"\"\"\n",
    "    Identifies the numerical and categorical features in dataset.\n",
    "    Identifies features for label encoding and one hot encoding\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    :returns:\n",
    "    categorical_features: list of non-numerical feature columns\n",
    "    numerical_features: list of numerical feature columns\n",
    "    le_column_features: list of feature label encoder columns\n",
    "    oh_column_features: list of feature one hot encoder columns\n",
    "    \"\"\"\n",
    "    schema_fields = df.schema.fields\n",
    "    features = df.columns\n",
    "    features.remove(exp_details.get(\"target_column\"))\n",
    "    df_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []  \n",
    "    for row in df_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type']:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    print(f\"numerical_features:  {numerical_features}\")\n",
    "    print(f\"categorical_features: {categorical_features}\")\n",
    "    \n",
    "    #identify columns for labelencoding and onehotencoding   \n",
    "    le_column_features = []\n",
    "    oh_column_features = []\n",
    "    if len(categorical_features) >= 1:\n",
    "        print(f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for column in categorical_features:\n",
    "            if df.select(df[column]).distinct().count() >= 10:\n",
    "                le_column_features.append(column)\n",
    "            elif column == exp_details.get(\"target_column\"):\n",
    "                le_column_feature.append(column)\n",
    "            else:\n",
    "                oh_column_features.append(column)\n",
    "        print(f\"Columns identified to be encoded with label encoder: {le_column_features}\")\n",
    "        print(f\"Columns identified to be encoded with one hot encoder: {oh_column_features}\")\n",
    "    return categorical_features, numerical_features, le_column_features, oh_column_features\n",
    "\n",
    "\n",
    "def create_and_run_preprocessing(df, categorical_features, numerical_features, le_column_features, oh_column_features):\n",
    "    \"\"\"\n",
    "    Based on different features column input creates preprocessing steps and run it on input dataframe\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    categorical_features: list of non-numerical feature columns\n",
    "    numerical_features: list of numerical feature columns\n",
    "    le_column_features: list of feature label encoder columns\n",
    "    oh_column_features: list of feature one hot encoder columns\n",
    "    :returns:\n",
    "    df_train: preprocessed train dataset\n",
    "    df_test: preprocessed test dataset\n",
    "    \"\"\"\n",
    "    #pipeline steps \n",
    "    print(\"Setting up preprocessing pipeline based on dataset\")\n",
    "    categorical_pp = {f'le_{column}':LabelEncoder(input_cols=column, output_cols=column) for column in le_column_feature}\n",
    "    if len(oh_column_feature)>0:\n",
    "        categorical_pp['oh_enc'] = OneHotEncoder(input_cols=oh_column_feature, output_cols=oh_column_feature, handle_unknown='ignore')\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_pp[key]!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "    print(f\"Selected preprocesing steps: \\n{steps}\")    \n",
    "        \n",
    "    # Run preprocessing pipeline steps \n",
    "    print(\"Running data preprocessing pipeline\")\n",
    "    df = Pipeline(steps=steps).fit(df).transform(df)\n",
    "    print(f\"Transformed dataset: \\n {df.show()}\")\n",
    "    df_train, df_test = df.random_split(weights=[0.8, 0.2], seed=0)\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def run_estimator(df_train, df_test, input_cols):\n",
    "    \"\"\"\n",
    "    trains on df_train and creates model object for given algorithm/estimator.\n",
    "    runs prediction function of model object on test dataset\n",
    "    :param:\n",
    "    df_train: input training dataframe\n",
    "    df_test: input test dataframe\n",
    "    input_cols: list of input feature names\n",
    "    :returns:\n",
    "    df_pred: output predict dataframe\n",
    "    \"\"\"\n",
    "    for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        print(f\"----Running Algorithm {algorithm[1]}----\")\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        pipe = Pipeline(steps=[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                              , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                              , output_cols=['PREDICTIONS']))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        print(f\"Running model pipeline {algorithm[1]}\")\n",
    "        model = pipe.fit(df_train)\n",
    " \n",
    "        # Test the model\n",
    "        log_message(\"INFO\",\"Running prediction on model with test dataset\")\n",
    "        print(\"Running prediction on model with test dataset\")\n",
    "        df_pred = model.predict(df_test)\n",
    "        return model, df_pred\n",
    "\n",
    "    \n",
    "def try_or(fn):\n",
    "    try:\n",
    "        out = fn()\n",
    "        return out\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def eval_metrics(df_pred):\n",
    "    print(\"Generating Metrices\")\n",
    "    return {\n",
    "        'accuracy': try_or(lambda: accuracy_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "        'f1_score': try_or(lambda: f1_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "        'recall': try_or(lambda: recall_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "        'precision': try_or(lambda: precision_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names='PREDICTIONS'))\n",
    "        'roc_auc': try_or(lambda: roc_auc_score(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS'))\n",
    "        'log_loss': try_or(lambda: log_loss(df=df_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names='PREDICTIONS'))\n",
    "    }\n",
    "\n",
    "\n",
    "def register_model(model, metrics_info):\n",
    "    print(\"Started: Registering model on snowflake\")\n",
    "    reg = Registry(session=session)\n",
    "    try:\n",
    "        model_name = exp_details.get(\"project_id\")+\"_\"+exp_details.get(\"id\")+\"_\"+exp_details.get(\"run_id\")\n",
    "        mv = reg.log_model(model=model,\n",
    "                           model_name=model_name,\n",
    "                           comment=exp_details.get(\"description\"),\n",
    "                           version_name=\"V1\",\n",
    "                           python_version=\"3.9.19\",\n",
    "                           conda_dependencies=[\"xgboost\",\"scikit-learn==1.2.2\"],\n",
    "                           metrics=[{\"model_metrics\": metrics_info, \n",
    "                                     \"project_id\": exp_details.get(\"project_id\"),\n",
    "                                     \"id\": exp_details.get(\"id\"),\n",
    "                                     \"run_id\": exp_details.get(\"run_id\"),\n",
    "                                     \"algorithm_type\": exp_details.get(\"algorithm_type\"),\n",
    "                                     \"algo_details\": exp_details.get(\"algorithm_type\")\n",
    "                                     \"source\": \"EXP\"}])\n",
    "        log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "    except Exception as ex:\n",
    "        key = 'Processing aborted due to error 370001' \n",
    "        if key in str(ex):\n",
    "            log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "            pass\n",
    "        else:\n",
    "            log_message(\"ERROR\",\"Exception Occured while registering model\")\n",
    "            return str(ex).split('?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d9fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
