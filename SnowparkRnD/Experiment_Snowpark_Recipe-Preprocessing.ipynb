{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exp_data = '{\"name\": \"moremetrices01\", \"algo_details\": {\"snowflake.ml.modeling.ensemble.GradientBoostingClassifier\": null}, \"id\": \"367\", \"dataset\": \"AIRLINE_DEP_DELAY_10K\", \"target_column\": \"DEP_DEL15\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3665e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, os\n",
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5308de",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a65f02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure\n",
    "def train_ml_models(session: Session, exp_data: str) -> list:\n",
    "    # variable for holding logs\n",
    "    logs = []\n",
    "    \n",
    "    # function for accumulating logs\n",
    "    def log_message(level: str, message: str):\n",
    "        logs.append(f\"{level}: {message}\")\n",
    "        \n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "         r2_score, accuracy_score, precision_score, roc_auc_score, f1_score, recall_score\n",
    "    from snowflake.snowpark.functions import col, last_value, row_number, first_value, regexp_replace\n",
    "    from snowflake.snowpark.window import Window\n",
    "    import importlib, sys, json\n",
    "\n",
    "\n",
    "    log_message(\"INFO\",\"Starting Experiment Recipe Execution\")\n",
    "    \n",
    "    # Experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    # Read dataset, Random split\n",
    "    log_message(\"INFO\",\"Reading and Identifing dataset features\")\n",
    "    data = session.table(exp_details.get(\"dataset\"))\n",
    "    \n",
    "    # Data Preprocessing: Validating and encoding the data if required and imputing null values.\n",
    "    window_spec = Window.order_by(exp_details.get(\"target_column\"))\n",
    "    data_row_num = data.with_column('ROW_NUM', row_number().over(window_spec))\n",
    "    columns = data_row_num.columns\n",
    "    columns.remove('ROW_NUM')\n",
    "    # forward fillna\n",
    "    data_ff = data_row_num.select(\n",
    "            [data_row_num['ROW_NUM']] + [\n",
    "                last_value(col(column), ignore_nulls=True).over(Window.order_by('ROW_NUM')).alias(column)\n",
    "                for column in columns\n",
    "            ]\n",
    "        )\n",
    "    # backward fillna\n",
    "    data_bf = data_row_num.select(\n",
    "            [data_row_num['ROW_NUM']] + [\n",
    "                first_value(col(column), ignore_nulls=True).over(Window.order_by(data_ff['ROW_NUM'].desc())).alias(column)\n",
    "                for column in columns\n",
    "            ]\n",
    "        )\n",
    "    data = data_bf.drop('ROW_NUM')\n",
    "    \n",
    "    # Replace special character(- with _)\n",
    "    schema_fields = data.schema.fields\n",
    "    data = data.select([\n",
    "        regexp_replace(col(field.name),\"-\", \"_\").alias(field.name)\n",
    "        for field in schema_fields])\n",
    "    print(schema_fields)\n",
    "    schema_fields = data.schema.fields\n",
    "    print(\"schhema after special char handling\",schema_fields)\n",
    "    features = data.columns\n",
    "#     features.remove(exp_details.get(\"target_column\"))\n",
    "    \n",
    "    # get features\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []  \n",
    "    for row in data_schema:\n",
    "        print(row)\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type']:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    print(f\"numerical_features:  {numerical_features}\")\n",
    "    print(f\"categorical_features_oe: {categorical_features}\")\n",
    "    log_message(\"INFO\",f\"numerical_features:  {numerical_features}\")\n",
    "    log_message(\"INFO\",f\"categorical_features_oe: {categorical_features}\")\n",
    "    \n",
    "    #identify columns for labelencoding and onehotencoding   \n",
    "    le_column_feature = []\n",
    "    oh_column_feature = []\n",
    "    if len(categorical_features) >= 1:\n",
    "        print(f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for column in categorical_features:\n",
    "            if data.select(data[column]).distinct().count() >= 10:\n",
    "                le_column_feature.append(column)\n",
    "            else:\n",
    "                oh_column_feature.append(column)\n",
    "\n",
    "        log_message(\"INFO\",f\"Columns identified to be encoded with label encoder: {le_column_feature}\")\n",
    "        log_message(\"INFO\",f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "    \n",
    "    \n",
    "    #pipeline steps \n",
    "    log_message(\"INFO\",\"Setting up preprocessing pipeline based on dataset\")\n",
    "    categorical_pp = {\n",
    "        'label_enc': [LabelEncoder(input_cols=le_column_feature, output_cols=le_column_feature), le_column_feature],\n",
    "        'oh_enc': [OneHotEncoder(input_cols=oh_column_feature, output_cols=oh_column_feature), oh_column_feature]\n",
    "    }\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key][0]) for key in categorical_pp if categorical_pp[key][1]!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "    \n",
    "    \n",
    "    input_cols = categorical_features+numerical_features\n",
    "    input_cols.remove(exp_details.get(\"target_column\"))\n",
    "    df_train, df_test = data.drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically import selected algorithms\n",
    "    for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        log_message(\"INFO\",f\"Running Algorithm {algorithm[1]}\")\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        \n",
    "        pipe = Pipeline(steps=steps+[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                              , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        log_message(\"INFO\",f\"Running model pipeline {algorithm[1]}\")\n",
    "        model = pipe.fit(df_train)\n",
    " \n",
    "        # Test the model\n",
    "        log_message(\"INFO\",\"Running prediction on model with test dataset\")\n",
    "        df_test_pred = model.predict(df_test)\n",
    "        \n",
    "        # metrices\n",
    "        log_message(\"INFO\",\"Generating Metrices\")\n",
    "        accuracy = accuracy_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        f1_score = f1_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        recall_score = recall_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        precision_score = precision_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        roc_auc_score = roc_auc_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        print(\"Execution Completed\")\n",
    "        print(f'{algorithm[1]} MSE: {accuracy}')\n",
    "        print(f'{algorithm[1]} R2: {precision_score}')\n",
    "        print(f'{algorithm[1]} R2: {roc_auc_score}')\n",
    "        \n",
    "\n",
    "        # LOG MODEL INTO SNOWFLAKE REGISTRY\n",
    "        from snowflake.ml.registry.registry import Registry\n",
    "        reg = Registry(session=session)\n",
    "        # Log the model\n",
    "        log_message(\"INFO\",\"Started: Registering model on snowflake\")\n",
    "        try:\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=exp_details.get(\"name\", \"sample_experiment\")+\"_\"+algorithm[1],\n",
    "                               comment=\"test\",\n",
    "                               version_name=\"run1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "                               metrics=[{\"model_metrics\": {\"roc_auc_score\": roc_auc_score, \"precision_score\": precision_score, \"f1_score\": f1_score, \"recall_score\": recall_score, \"accuracy_score\": accuracy}, \"project_id\": \"0001\", \"type\": \"EXP\"}])\n",
    "            log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "                pass\n",
    "            else:\n",
    "                log_message(\"ERROR\",\"Exception Occured while registering model\")\n",
    "                return str(ex).split('?')\n",
    "    return [{\"Execution Logs:\": \"\\n\".join(logs),\n",
    "             \"EXP_NAME\":exp_details.get(\"name\", \"sample_experiment\"),\n",
    "             \"Version\":\"Run1\",\n",
    "             \"matrices\":{\"model_metrics\": {\"roc_auc_score\": roc_auc_score, \"precision_score\": precision_score, \"f1_score\": f1_score, \"recall_score\": recall_score, \"accuracy_score\": accuracy}, \"project_id\": \"0001\", \"type\": \"EXP\"},\n",
    "             \"Alogirthm_Type\":\"Regression\",\n",
    "             \"Alogithms\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_exp_name\":\"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24313b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.10.1, Python Version: 3.9.18, Platform: Linux-5.10.215-203.850.amzn2.x86_64-x86_64-with-glibc2.34\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:snowflake.snowpark.session:Snowpark Session information: \n",
      "\"version\" : 1.18.0,\n",
      "\"python.version\" : 3.9.18,\n",
      "\"python.connector.version\" : 3.10.1,\n",
      "\"python.connector.session.id\" : 96125691347502,\n",
      "\"os.name\" : Linux\n",
      "\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 2\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.18.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-ml-python' in the local environment is 1.5.1, which does not fit the criteria for the requirement 'snowflake-ml-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Stored procedure has been created successfully!\n",
      "Executing Procedure\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "[StructField('MONTH', LongType(), nullable=True), StructField('DAY_OF_WEEK', LongType(), nullable=True), StructField('DEP_DEL15', LongType(), nullable=True), StructField('DEP_TIME_BLK', StringType(16777216), nullable=True), StructField('DISTANCE_GROUP', LongType(), nullable=True), StructField('SEGMENT_NUMBER', LongType(), nullable=True), StructField('CONCURRENT_FLIGHTS', LongType(), nullable=True), StructField('NUMBER_OF_SEATS', LongType(), nullable=True), StructField('CARRIER_NAME', StringType(16777216), nullable=True), StructField('AIRPORT_FLIGHTS_MONTH', LongType(), nullable=True), StructField('AIRLINE_FLIGHTS_MONTH', LongType(), nullable=True), StructField('AIRLINE_AIRPORT_FLIGHTS_MONTH', LongType(), nullable=True), StructField('AVG_MONTHLY_PASS_AIRPORT', LongType(), nullable=True), StructField('AVG_MONTHLY_PASS_AIRLINE', LongType(), nullable=True), StructField('FLT_ATTENDANTS_PER_PASS', DoubleType(), nullable=True), StructField('GROUND_SERV_PER_PASS', DoubleType(), nullable=True), StructField('PLANE_AGE', LongType(), nullable=True), StructField('DEPARTING_AIRPORT', StringType(16777216), nullable=True), StructField('LATITUDE', DoubleType(), nullable=True), StructField('LONGITUDE', DoubleType(), nullable=True), StructField('PREVIOUS_AIRPORT', StringType(16777216), nullable=True), StructField('PRCP', DoubleType(), nullable=True), StructField('SNOW', DoubleType(), nullable=True), StructField('SNWD', DoubleType(), nullable=True), StructField('TMAX', DoubleType(), nullable=True), StructField('AWND', DoubleType(), nullable=True), StructField('CARRIER_HISTORICAL', DoubleType(), nullable=True), StructField('DEP_AIRPORT_HIST', DoubleType(), nullable=True), StructField('DAY_HISTORICAL', DoubleType(), nullable=True), StructField('DEP_BLOCK_HIST', DoubleType(), nullable=True)]\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 30\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 30\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 30\n",
      "Row(name='MONTH', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DAY_OF_WEEK', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DEP_DEL15', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DEP_TIME_BLK', type='VARCHAR(16777216)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DISTANCE_GROUP', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='SEGMENT_NUMBER', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='CONCURRENT_FLIGHTS', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='NUMBER_OF_SEATS', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='CARRIER_NAME', type='VARCHAR(16777216)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='AIRPORT_FLIGHTS_MONTH', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='AIRLINE_FLIGHTS_MONTH', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='AIRLINE_AIRPORT_FLIGHTS_MONTH', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='AVG_MONTHLY_PASS_AIRPORT', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='AVG_MONTHLY_PASS_AIRLINE', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='FLT_ATTENDANTS_PER_PASS', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='GROUND_SERV_PER_PASS', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='PLANE_AGE', type='NUMBER(38,0)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DEPARTING_AIRPORT', type='VARCHAR(16777216)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='LATITUDE', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='LONGITUDE', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='PREVIOUS_AIRPORT', type='VARCHAR(16777216)', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='PRCP', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='SNOW', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='SNWD', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='TMAX', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='AWND', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='CARRIER_HISTORICAL', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DEP_AIRPORT_HIST', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DAY_HISTORICAL', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "Row(name='DEP_BLOCK_HIST', type='FLOAT', kind='COLUMN', null?='Y', default=None, primary key='N', unique key='N', check=None, expression=None, comment=None, policy name=None, privacy domain=None)\n",
      "numerical_features:  ['DEP_DEL15', 'AWND', 'DEP_BLOCK_HIST', 'GROUND_SERV_PER_PASS', 'NUMBER_OF_SEATS', 'AIRLINE_FLIGHTS_MONTH', 'LATITUDE', 'AIRPORT_FLIGHTS_MONTH', 'TMAX', 'AVG_MONTHLY_PASS_AIRPORT', 'SNOW', 'LONGITUDE', 'AIRLINE_AIRPORT_FLIGHTS_MONTH', 'FLT_ATTENDANTS_PER_PASS', 'DAY_OF_WEEK', 'SNWD', 'PRCP', 'CONCURRENT_FLIGHTS', 'AVG_MONTHLY_PASS_AIRLINE', 'MONTH', 'PLANE_AGE', 'SEGMENT_NUMBER', 'CARRIER_HISTORICAL', 'DISTANCE_GROUP', 'DAY_HISTORICAL', 'DEP_AIRPORT_HIST']\n",
      "categorical_features_oe: ['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT']\n",
      "['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT'] columns are non numeric in feature dataset, encoding required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 4\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 11\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:845: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:846: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 11\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "(2113) Non-numeric input column MONTH datatype StringType(16777216) is not supported by the MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowflakeMLException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:368\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/framework/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(ds, data_source\u001b[38;5;241m.\u001b[39mDataSource) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_sources)\n\u001b[0;32m--> 436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/min_max_scaler.py:163\u001b[0m, in \u001b[0;36mMinMaxScaler._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_snowpark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/min_max_scaler.py:183\u001b[0m, in \u001b[0;36mMinMaxScaler._fit_snowpark\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_snowpark\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: snowpark\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_column_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     computed_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute(dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_cols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_states)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/preprocessing/min_max_scaler.py:133\u001b[0m, in \u001b[0;36mMinMaxScaler._check_input_column_types\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(field\u001b[38;5;241m.\u001b[39mdatatype), T\u001b[38;5;241m.\u001b[39m_NumericType):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException(\n\u001b[1;32m    134\u001b[0m         error_code\u001b[38;5;241m=\u001b[39merror_codes\u001b[38;5;241m.\u001b[39mINVALID_DATA_TYPE,\n\u001b[1;32m    135\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-numeric input column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m datatype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;241m.\u001b[39mdatatype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not supported by the MinMaxScaler.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         ),\n\u001b[1;32m    139\u001b[0m     )\n",
      "\u001b[0;31mSnowflakeMLException\u001b[0m: TypeError('(2113) Non-numeric input column MONTH datatype StringType(16777216) is not supported by the MinMaxScaler.')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting Procedure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# procedure_response = session.call(\"train_ml_models\", exp_data)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m procedure_response \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ml_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStored Procedure Executed Successfully !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(procedure_response)\n",
      "Cell \u001b[0;32mIn[18], line 141\u001b[0m, in \u001b[0;36mtrain_ml_models\u001b[0;34m(session, exp_data)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Fit the pipeline\u001b[39;00m\n\u001b[1;32m    140\u001b[0m log_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgorithm[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 141\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m    144\u001b[0m log_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning prediction on model with test dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:373\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# already handled via a nested decorated function\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_snowflake_ml_handled\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m_snowflake_ml_handled:\n\u001b[0;32m--> 373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowpark_exceptions\u001b[38;5;241m.\u001b[39mSnowparkClientException):\n\u001b[1;32m    375\u001b[0m         me \u001b[38;5;241m=\u001b[39m snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException(\n\u001b[1;32m    376\u001b[0m             error_code\u001b[38;5;241m=\u001b[39merror_codes\u001b[38;5;241m.\u001b[39mINTERNAL_SNOWPARK_ERROR, original_exception\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m    377\u001b[0m         )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:368\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m telemetry_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    360\u001b[0m     func_name\u001b[38;5;241m=\u001b[39m_get_full_func_name(func),\n\u001b[1;32m    361\u001b[0m     function_category\u001b[38;5;241m=\u001b[39mTelemetryField\u001b[38;5;241m.\u001b[39mFUNC_CAT_USAGE\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m     custom_tags\u001b[38;5;241m=\u001b[39mcustom_tags,\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException):\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;66;03m# already handled via a nested decorated function\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/pipeline/pipeline.py:441\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, dataset, squash)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_snowpark_dataframe_within_one_sproc(session\u001b[38;5;241m=\u001b[39msession, dataset\u001b[38;5;241m=\u001b[39mdataset)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     transformed_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_estimator()\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m estimator:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/modeling/pipeline/pipeline.py:260\u001b[0m, in \u001b[0;36mPipeline._fit_transform_dataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, trans \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_transformers():\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_step_feature_consumption_info(\n\u001b[1;32m    258\u001b[0m         step_name\u001b[38;5;241m=\u001b[39mname, all_cols\u001b[38;5;241m=\u001b[39mtransformed_dataset\u001b[38;5;241m.\u001b[39mcolumns[:], input_cols\u001b[38;5;241m=\u001b[39mtrans\u001b[38;5;241m.\u001b[39mget_input_cols()\n\u001b[1;32m    259\u001b[0m     )\n\u001b[0;32m--> 260\u001b[0m     \u001b[43mtrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     transformed_dataset \u001b[38;5;241m=\u001b[39m trans\u001b[38;5;241m.\u001b[39mtransform(transformed_dataset)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_dataset\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/7e0b365a-f7cb-4d2a-ba2a-e8ed02dbe50c/3.9/snowflake/ml/_internal/telemetry.py:390\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m update_stmt_params_if_snowpark_df(res, statement_params)\n",
      "\u001b[0;31mTypeError\u001b[0m: (2113) Non-numeric input column MONTH datatype StringType(16777216) is not supported by the MinMaxScaler."
     ]
    }
   ],
   "source": [
    "# Initilization\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=train_ml_models,\n",
    "                       name=\"train_ml_models\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# procedure_response = session.call(\"train_ml_models\", exp_data)\n",
    "procedure_response = train_ml_models(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62811208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7acf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
