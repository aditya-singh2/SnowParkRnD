{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e114909",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = '{\"project_id\":\"1234\", \"id\":\"1234\", \"run_id\":\"1234\", \"exp_name\": \"py_func_exp7\", \"algorithm_type\":\"classification\", \"algo_details\": {\"snowflake.ml.modeling.naive_bayes.MultinomialNB\": null}, \"dataset\": \"AIRLINE_DEP_DELAY_10K\", \"target_column\": \"DEP_DEL15\"}'\n",
    "metric_names = [\"accuracy_score\",\"precision_score\",\"recall_score\",\"f1_score\",\"roc_auc\",\"log_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# exp_data = '{\"name\": \"py_func_exp6\", \"algo_details\": {\"snowflake.ml.modeling.naive_bayes.MultinomialNB\": null}, \"id\": \"367\", \"dataset\": \"AIRLINE_DEP_DELAY_100K\", \"target_column\": \"DEP_DEL15\"}'\n",
    "# exp_data = '{\"name\": \"vaibhav_exp2\", \"algo_details\": {\"snowflake.ml.modeling.neighbors.KNeighborsClassifier\": null, \"snowflake.ml.modeling.naive_bayes.MultinomialNB\": null, \"snowflake.ml.modeling.ensemble.GradientBoostingClassifier\": null}, \"id\": \"367\", \"dataset\": \"AIRLINE_DEP_DELAY_100K\", \"target_column\": \"DEP_DEL15\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3665e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, os\n",
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f5308de",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a65f02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "        \n",
    "def create_tags(session, exp_details):\n",
    "    for key in exp_details.keys():\n",
    "        tag = session.sql(f\"CREATE TAG IF NOT EXISTS {key}\")\n",
    "    for name in metric_names:\n",
    "        tag = session.sql(f\"CREATE TAG IF NOT EXISTS {name}\")\n",
    "\n",
    "\n",
    "def set_tags(model, metric_info):\n",
    "    for key, value in exp_details.items():\n",
    "        model.set_tag(key, str(value))\n",
    "    for key, value in metric_info:\n",
    "        model.set_tag(key, str(value) )\n",
    "\n",
    "# Stored Procedure\n",
    "def train_ml_models(session: Session, exp_data: str) -> list:\n",
    "    # variable for holding logs\n",
    "    logs = []\n",
    "    \n",
    "    # function for accumulating logs\n",
    "    def log_message(level: str, message: str):\n",
    "        logs.append(f\"{level}: {message}\")\n",
    "      \n",
    "    #imports\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "    from snowflake.ml.modeling.metrics import r2_score, accuracy_score, precision_score, roc_auc_score, f1_score, recall_score\n",
    "    from snowflake.snowpark.functions import col, is_null, regexp_replace, when, lit\n",
    "    from snowflake.snowpark.types import StringType\n",
    "    from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "    import importlib, sys, json\n",
    "        \n",
    "    \n",
    "    log_message(\"INFO\",\"Starting Experiment Recipe Execution\")\n",
    "    \n",
    "    # Experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    create_tags(session, exp_details)\n",
    "    \n",
    "    # Read dataset, Random split\n",
    "    log_message(\"INFO\",\"Reading and Identifing dataset features\")\n",
    "    data = session.table(exp_details.get(\"dataset\"))\n",
    "    \n",
    "    # Replace special character(- with _)\n",
    "    schema_fields = data.schema.fields\n",
    "    data = data.select([\n",
    "        regexp_replace(regexp_replace(col(field.name),\"-\", \"_\"), \"\\\\.\",\"\").alias(field.name) if isinstance(field.datatype, StringType) else col(field.name)\n",
    "        for field in schema_fields])\n",
    "    \n",
    "    #fillna\n",
    "    fill_values = {field.name: \"Unknown\" if isinstance(field.datatype, StringType) else 0 for field in schema_fields}\n",
    "    data = data.fillna(fill_values)\n",
    "    \n",
    "    \n",
    "    # get features\n",
    "    schema_fields = data.schema.fields\n",
    "    features = data.columns\n",
    "    features.remove(exp_details.get(\"target_column\"))\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []  \n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type']:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    log_message(\"INFO\",f\"numerical_features:  {numerical_features}\")\n",
    "    log_message(\"INFO\",f\"categorical_features: {categorical_features}\")\n",
    "    \n",
    "    \n",
    "    #identify columns for labelencoding and onehotencoding   \n",
    "    le_column_feature = []\n",
    "    oh_column_feature = []\n",
    "    if len(categorical_features) >= 1:\n",
    "        print(f\"{categorical_features} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for column in categorical_features:\n",
    "            if data.select(data[column]).distinct().count() >= 10:\n",
    "                le_column_feature.append(column)\n",
    "            elif column == exp_details.get(\"target_column\"):\n",
    "                le_column_feature.append(column)\n",
    "            else:\n",
    "                oh_column_feature.append(column)\n",
    "        log_message(\"INFO\",f\"Columns identified to be encoded with label encoder: {le_column_feature}\")\n",
    "        log_message(\"INFO\",f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "        \n",
    "    \n",
    "    #pipeline steps \n",
    "    log_message(\"INFO\",\"Setting up preprocessing pipeline based on dataset\")\n",
    "    categorical_pp = {f'le_{column}':LabelEncoder(input_cols=column, output_cols=column) for column in le_column_feature}\n",
    "    if len(oh_column_feature)>0:\n",
    "        categorical_pp['oh_enc'] = OneHotEncoder(input_cols=oh_column_feature, output_cols=oh_column_feature, handle_unknown='ignore')\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_pp[key]!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "        \n",
    "        \n",
    "    # Run preprocessing pipeline steps \n",
    "    log_message(\"INFO\",\"Running data preprocessing pipeline\")\n",
    "    print(\"Running data preprocessing pipeline\")\n",
    "    print(f\"Selected preprocesing steps: \\n{steps}\") \n",
    "    pp_pipeline = Pipeline(steps=steps)\n",
    "    data = pp_pipeline.fit(data).transform(data)\n",
    "    print(data.show())\n",
    "    \n",
    "    # Split train and test data\n",
    "    df_train, df_test = data.random_split(weights=[0.8, 0.2], seed=0)\n",
    "    input_cols = categorical_features+numerical_features\n",
    "    if exp_details.get(\"target_column\") in categorical_features:\n",
    "        input_cols.remove(exp_details.get(\"target_column\"))\n",
    "        \n",
    " \n",
    "    # dynamically import selected algorithms\n",
    "    for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        log_message(\"INFO\",f\"----Running Algorithm {algorithm[1]}----\")\n",
    "        print(f\"----Running Algorithm {algorithm[1]}----\")\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        \n",
    "        pipe = Pipeline(steps=[(\"algorithm\", attr(input_cols=input_cols\n",
    "                                              , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        log_message(\"INFO\",f\"Running model pipeline {algorithm[1]}\")\n",
    "        print(f\"Running model pipeline {algorithm[1]}\")\n",
    "        model = pipe.fit(df_train)\n",
    " \n",
    "        # Test the model\n",
    "        log_message(\"INFO\",\"Running prediction on model with test dataset\")\n",
    "        print(\"Running prediction on model with test dataset\")\n",
    "        df_test_pred = model.predict(df_test)\n",
    " \n",
    "        # metrices\n",
    "        log_message(\"INFO\",\"Generating Metrices\")\n",
    "        print(\"Generating Metrices\")\n",
    "        accuracy = accuracy_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        f1_sc = f1_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        recall_sc = recall_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        precision_sc = precision_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        roc_auc_sc = roc_auc_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "#         except SnowparkSQLException as se:\n",
    "#             print(se.message)\n",
    "#             accuracy=f1_sc=recall_sc=precision_sc=roc_auc_sc = 0.0\n",
    "        log_message(\"INFO\",\"Metrices generation completed!!!\")\n",
    "        print(\"Metrices generation completed!!!\")\n",
    "        \n",
    "\n",
    "        # LOG MODEL INTO SNOWFLAKE REGISTRY\n",
    "        from snowflake.ml.registry.registry import Registry\n",
    "        reg = Registry(session=session)\n",
    "        \n",
    "        # Log the model\n",
    "        log_message(\"INFO\",\"Started: Registering model on snowflake\")\n",
    "        print(\"Started: Registering model on snowflake\")\n",
    "        try:\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=exp_details.get(\"name\", \"sample_experiment\")+\"_\"+algorithm[1],\n",
    "                               comment=\"test\",\n",
    "                               version_name=\"run1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"xgboost\",\"scikit-learn==1.2.2\"],\n",
    "                               metrics=[{\"model_metrics\": {\"roc_auc\": roc_auc_sc, \"precision_score\": precision_sc, \"f1_score\": f1_sc, \"recall_score\": recall_sc, \"accuracy_score\": accuracy}, \"project_id\": \"0001\", \"type\": \"EXP\"}])\n",
    "            log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "                pass\n",
    "            else:\n",
    "                log_message(\"ERROR\",\"Exception Occured while registering model\")\n",
    "                return str(ex).split('?')\n",
    "            \n",
    "        print(\"trying to set tag\")\n",
    "        m = reg.get_model(exp_details.get(\"name\", \"sample_experiment\")+\"_\"+algorithm[1])\n",
    "#         tag = session.sql(f\"ALTER MODEL IF EXISTS {exp_details.get('name', 'sample_experiment')+'_'+algorithm[1]} SET TAG 'accuracy' = {accuracy}\")\n",
    "        set_tags(m, {\"roc_auc_score\": roc_auc_sc, \"precision_score\": precision_sc, \"f1_score\": f1_sc, \"recall_score\": recall_sc, \"accuracy_score\": accuracy})\n",
    "        print(m.show_tags())\n",
    "    return [{\"Execution Logs:\": \"\\n\".join(logs),\n",
    "             \"EXP_NAME\":exp_details.get(\"name\", \"sample_experiment\"),\n",
    "             \"Version\":\"Run1\",\n",
    "             \"matrices\":{\"model_metrics\": {\"roc_auc_score\": roc_auc_sc, \"precision_score\": precision_sc, \"f1_score\": f1_sc, \"recall_score\": recall_sc, \"accuracy_score\": accuracy}, \"project_id\": \"0001\", \"type\": \"EXP\"},\n",
    "             \"Alogirthm_Type\":\"Regression\",\n",
    "             \"Alogithms\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_exp_name\":\"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24313b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.10.1, Python Version: 3.9.18, Platform: Linux-5.10.218-208.862.amzn2.x86_64-x86_64-with-glibc2.34\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:snowflake.snowpark.session:Snowpark Session information: \n",
      "\"version\" : 1.18.0,\n",
      "\"python.version\" : 3.9.18,\n",
      "\"python.connector.version\" : 3.10.1,\n",
      "\"python.connector.session.id\" : 96125692440978,\n",
      "\"os.name\" : Linux\n",
      "\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 2\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.18.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-ml-python' in the local environment is 1.5.1, which does not fit the criteria for the requirement 'snowflake-ml-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Stored procedure has been created successfully!\n",
      "Executing Procedure\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exp_details' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:21\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m, in \u001b[0;36mtrain_ml_models\u001b[0;34m(session, exp_data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Experiment details\u001b[39;00m\n\u001b[1;32m     55\u001b[0m exp_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(exp_data)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mcreate_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Read dataset, Random split\u001b[39;00m\n\u001b[1;32m     60\u001b[0m log_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading and Identifing dataset features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mcreate_tags\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tags\u001b[39m(session):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexp_details\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     22\u001b[0m         tag \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TAG IF NOT EXISTS \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m metric_names:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_details' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initilization\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=train_ml_models,\n",
    "                       name=\"train_ml_models\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# session.query_tag='my_session_for_sproc'\n",
    "# procedure_response = session.call(\"train_ml_models\", exp_data)\n",
    "# q_id = session.sql(\"select * from table(information_schema.query_history()) where query_tag='my_session_for_sproc'\").to_pandas()\n",
    "procedure_response = train_ml_models(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc8a131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "------------------------------------\n",
      "|\"status\"                          |\n",
      "------------------------------------\n",
      "|Statement executed successfully.  |\n",
      "------------------------------------\n",
      "\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 2\n",
      "{'FIRST_DB.PUBLIC.ACCURACY': '0.799', 'FIRST_DB.PUBLIC.PRECISION_SCORE': '0.68'}\n"
     ]
    }
   ],
   "source": [
    "# from snowflake.ml.registry.registry import Registry\n",
    "# reg = Registry(session=session)\n",
    "# m = reg.get_model('PY_FUNC_EXP6_MULTINOMIALNB')\n",
    "# tag = session.sql(f\"ALTER MODEL IF EXISTS PY_FUNC_EXP6_MULTINOMIALNB SET TAG precision_score='0.68', accuracy='0.799'\")\n",
    "# tag.show()\n",
    "# print(m.show_tags())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56d6a1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_ID</th>\n",
       "      <th>QUERY_TEXT</th>\n",
       "      <th>DATABASE_NAME</th>\n",
       "      <th>SCHEMA_NAME</th>\n",
       "      <th>QUERY_TYPE</th>\n",
       "      <th>SESSION_ID</th>\n",
       "      <th>USER_NAME</th>\n",
       "      <th>ROLE_NAME</th>\n",
       "      <th>WAREHOUSE_NAME</th>\n",
       "      <th>WAREHOUSE_SIZE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>QUERY_ACCELERATION_BYTES_SCANNED</th>\n",
       "      <th>QUERY_ACCELERATION_PARTITIONS_SCANNED</th>\n",
       "      <th>QUERY_ACCELERATION_UPPER_LIMIT_SCALE_FACTOR</th>\n",
       "      <th>BYTES_WRITTEN_TO_RESULT</th>\n",
       "      <th>ROWS_WRITTEN_TO_RESULT</th>\n",
       "      <th>ROWS_INSERTED</th>\n",
       "      <th>QUERY_RETRY_TIME</th>\n",
       "      <th>QUERY_RETRY_CAUSE</th>\n",
       "      <th>FAULT_HANDLING_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01b53f31-0000-6c40-0000-576d070e605e</td>\n",
       "      <td>select * from table(information_schema.query_h...</td>\n",
       "      <td>FIRST_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>96125692378674</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>FOSFOR_INSIGHT_WH</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01b53f2f-0000-6c44-0000-576d070e35da</td>\n",
       "      <td>CALL train_ml_models('{\"name\": \"py_func_exp3\",...</td>\n",
       "      <td>FIRST_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>CALL</td>\n",
       "      <td>96125692378674</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>FOSFOR_INSIGHT_WH</td>\n",
       "      <td>X-Small</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01b53f2f-0000-6c40-0000-576d070e6052</td>\n",
       "      <td>describe procedure TRAIN_ML_MODELS(STRING)</td>\n",
       "      <td>FIRST_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>DESCRIBE</td>\n",
       "      <td>96125692378674</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>FOSFOR_INSIGHT_WH</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4246</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01b53f2d-0000-6c56-0000-576d070e5602</td>\n",
       "      <td>select query_id, query_text from table(informa...</td>\n",
       "      <td>FIRST_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>SELECT</td>\n",
       "      <td>96125692378642</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>FOSFOR_INSIGHT_WH</td>\n",
       "      <td>X-Small</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01b53f2c-0000-6c8d-0000-576d070e44c2</td>\n",
       "      <td>CALL train_ml_models('{\"name\": \"py_func_exp3\",...</td>\n",
       "      <td>FIRST_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>CALL</td>\n",
       "      <td>96125692378642</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>FOSFOR_INSIGHT_WH</td>\n",
       "      <td>X-Small</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01b53f2c-0000-6c40-0000-576d070e6016</td>\n",
       "      <td>describe procedure TRAIN_ML_MODELS(STRING)</td>\n",
       "      <td>FIRST_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>DESCRIBE</td>\n",
       "      <td>96125692378642</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>ADITYASINGH</td>\n",
       "      <td>FOSFOR_INSIGHT_WH</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4246</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               QUERY_ID  \\\n",
       "0  01b53f31-0000-6c40-0000-576d070e605e   \n",
       "1  01b53f2f-0000-6c44-0000-576d070e35da   \n",
       "2  01b53f2f-0000-6c40-0000-576d070e6052   \n",
       "3  01b53f2d-0000-6c56-0000-576d070e5602   \n",
       "4  01b53f2c-0000-6c8d-0000-576d070e44c2   \n",
       "5  01b53f2c-0000-6c40-0000-576d070e6016   \n",
       "\n",
       "                                          QUERY_TEXT DATABASE_NAME  \\\n",
       "0  select * from table(information_schema.query_h...      FIRST_DB   \n",
       "1  CALL train_ml_models('{\"name\": \"py_func_exp3\",...      FIRST_DB   \n",
       "2         describe procedure TRAIN_ML_MODELS(STRING)      FIRST_DB   \n",
       "3  select query_id, query_text from table(informa...      FIRST_DB   \n",
       "4  CALL train_ml_models('{\"name\": \"py_func_exp3\",...      FIRST_DB   \n",
       "5         describe procedure TRAIN_ML_MODELS(STRING)      FIRST_DB   \n",
       "\n",
       "  SCHEMA_NAME QUERY_TYPE      SESSION_ID    USER_NAME    ROLE_NAME  \\\n",
       "0      PUBLIC    UNKNOWN  96125692378674  ADITYASINGH  ADITYASINGH   \n",
       "1      PUBLIC       CALL  96125692378674  ADITYASINGH  ADITYASINGH   \n",
       "2      PUBLIC   DESCRIBE  96125692378674  ADITYASINGH  ADITYASINGH   \n",
       "3      PUBLIC     SELECT  96125692378642  ADITYASINGH  ADITYASINGH   \n",
       "4      PUBLIC       CALL  96125692378642  ADITYASINGH  ADITYASINGH   \n",
       "5      PUBLIC   DESCRIBE  96125692378642  ADITYASINGH  ADITYASINGH   \n",
       "\n",
       "      WAREHOUSE_NAME WAREHOUSE_SIZE  ... TRANSACTION_ID  \\\n",
       "0  FOSFOR_INSIGHT_WH           None  ...              0   \n",
       "1  FOSFOR_INSIGHT_WH        X-Small  ...              0   \n",
       "2  FOSFOR_INSIGHT_WH           None  ...              0   \n",
       "3  FOSFOR_INSIGHT_WH        X-Small  ...              0   \n",
       "4  FOSFOR_INSIGHT_WH        X-Small  ...              0   \n",
       "5  FOSFOR_INSIGHT_WH           None  ...              0   \n",
       "\n",
       "   QUERY_ACCELERATION_BYTES_SCANNED QUERY_ACCELERATION_PARTITIONS_SCANNED  \\\n",
       "0                                 0                                     0   \n",
       "1                                 0                                     0   \n",
       "2                                 0                                     0   \n",
       "3                                 0                                     0   \n",
       "4                                 0                                     0   \n",
       "5                                 0                                     0   \n",
       "\n",
       "  QUERY_ACCELERATION_UPPER_LIMIT_SCALE_FACTOR  BYTES_WRITTEN_TO_RESULT  \\\n",
       "0                                           0                        0   \n",
       "1                                           0                      375   \n",
       "2                                           0                     4246   \n",
       "3                                           0                      718   \n",
       "4                                           0                      375   \n",
       "5                                           0                     4246   \n",
       "\n",
       "  ROWS_WRITTEN_TO_RESULT ROWS_INSERTED QUERY_RETRY_TIME  QUERY_RETRY_CAUSE  \\\n",
       "0                      0             0                0               None   \n",
       "1                      1             0                0               None   \n",
       "2                     12             0                0               None   \n",
       "3                      3             0                0               None   \n",
       "4                      1             0                0               None   \n",
       "5                     12             0                0               None   \n",
       "\n",
       "   FAULT_HANDLING_TIME  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "\n",
       "[6 rows x 56 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1bd12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['QUERY_ID', 'QUERY_TEXT', 'DATABASE_NAME', 'SCHEMA_NAME', 'QUERY_TYPE',\n",
       "       'SESSION_ID', 'USER_NAME', 'ROLE_NAME', 'WAREHOUSE_NAME',\n",
       "       'WAREHOUSE_SIZE', 'WAREHOUSE_TYPE', 'CLUSTER_NUMBER', 'QUERY_TAG',\n",
       "       'EXECUTION_STATUS', 'ERROR_CODE', 'ERROR_MESSAGE', 'START_TIME',\n",
       "       'END_TIME', 'TOTAL_ELAPSED_TIME', 'BYTES_SCANNED', 'ROWS_PRODUCED',\n",
       "       'COMPILATION_TIME', 'EXECUTION_TIME', 'QUEUED_PROVISIONING_TIME',\n",
       "       'QUEUED_REPAIR_TIME', 'QUEUED_OVERLOAD_TIME',\n",
       "       'TRANSACTION_BLOCKED_TIME', 'OUTBOUND_DATA_TRANSFER_CLOUD',\n",
       "       'OUTBOUND_DATA_TRANSFER_REGION', 'OUTBOUND_DATA_TRANSFER_BYTES',\n",
       "       'INBOUND_DATA_TRANSFER_CLOUD', 'INBOUND_DATA_TRANSFER_REGION',\n",
       "       'INBOUND_DATA_TRANSFER_BYTES', 'CREDITS_USED_CLOUD_SERVICES',\n",
       "       'LIST_EXTERNAL_FILE_TIME', 'RELEASE_VERSION',\n",
       "       'EXTERNAL_FUNCTION_TOTAL_INVOCATIONS',\n",
       "       'EXTERNAL_FUNCTION_TOTAL_SENT_ROWS',\n",
       "       'EXTERNAL_FUNCTION_TOTAL_RECEIVED_ROWS',\n",
       "       'EXTERNAL_FUNCTION_TOTAL_SENT_BYTES',\n",
       "       'EXTERNAL_FUNCTION_TOTAL_RECEIVED_BYTES',\n",
       "       'IS_CLIENT_GENERATED_STATEMENT', 'QUERY_HASH', 'QUERY_HASH_VERSION',\n",
       "       'QUERY_PARAMETERIZED_HASH', 'QUERY_PARAMETERIZED_HASH_VERSION',\n",
       "       'TRANSACTION_ID', 'QUERY_ACCELERATION_BYTES_SCANNED',\n",
       "       'QUERY_ACCELERATION_PARTITIONS_SCANNED',\n",
       "       'QUERY_ACCELERATION_UPPER_LIMIT_SCALE_FACTOR',\n",
       "       'BYTES_WRITTEN_TO_RESULT', 'ROWS_WRITTEN_TO_RESULT', 'ROWS_INSERTED',\n",
       "       'QUERY_RETRY_TIME', 'QUERY_RETRY_CAUSE', 'FAULT_HANDLING_TIME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_id.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62811208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn               1.3.2      \n",
      "scipy                      1.13.1     \n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep -i sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7acf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
