{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b83883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exp_data = '{\"name\": \"testsize00\", \"algo_details\": {\"snowflake.ml.modeling.ensemble.GradientBoostingClassifier\": null}, \"id\": \"367\", \"dataset\": \"EMPLOYEE\", \"target_column\": \"LEAVEORNOT\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb3665e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, os\n",
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f5308de",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a65f02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure\n",
    "def train_ml_models(session: Session, exp_data: str) -> list:\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "    import importlib, os, json\n",
    "    import logging\n",
    "    # from snowflake.snowpark import Session, FileOperation\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    logger = logging.getLogger()\n",
    "    logger.info(\"Imports Done! Starting Experiment Recipe Execution\")\n",
    "    \n",
    "    # Experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    # Adding dependent packages to session\n",
    "    session.add_packages(\"snowflake-snowpark-python\", \"snowflake-ml-python\")\n",
    "    \n",
    "    # Read dataset, Random split\n",
    "    df_train, df_test = session.table(exp_details.get(\"dataset\")).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    features = df_train.columns\n",
    "    features.remove(exp_details.get(\"target_column\"))\n",
    "    \n",
    "    # get features\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=exp_details.get(\"target_column\"):\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    categorical_features_oe = list(map(lambda a: a+'_OE', categorical_features))\n",
    "    print(\"numerical_features: \", numerical_features)\n",
    "    print(\"categorical_features_oe: \", categorical_features_oe)\n",
    "    \n",
    "    \n",
    "    #pipeline steps \n",
    "    categorical_pp = {\n",
    "        'ord': OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe) \n",
    "    }\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_features!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "    \n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically import selected algorithms\n",
    "    for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        logger.info(algorithm[1])\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        \n",
    "        pipe = Pipeline(steps=steps+[(\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "                                              , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        model = pipe.fit(df_train)\n",
    "         \n",
    "        # Test the model\n",
    "        df_test_pred = model.predict(df_test)\n",
    "        \n",
    "        # metrices\n",
    "        mse = mean_squared_error(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        mae = mean_absolute_error(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        r2 = r2_score(df=df_test_pred, y_true_col_name=exp_details.get(\"target_column\"), y_pred_col_name=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        print(\"Execution Completed\")\n",
    "        print(f'{algorithm[1]} MSE: {mse}')\n",
    "        print(f'{algorithm[1]} MAE: {mae}')\n",
    "        print(f'{algorithm[1]} R2: {r2}')\n",
    "        \n",
    "        print('Model Size:', sys.getsizeof(model))\n",
    "        \n",
    "\n",
    "        # LOG MODEL INTO SNOWFLAKE REGISTRY\n",
    "        from snowflake.ml.registry.registry import Registry\n",
    "        reg = Registry(session=session)\n",
    "        # Log the model\n",
    "        model_name = f\"expname_{algorithm[1]}\"\n",
    "        try:\n",
    "            logger.info(\"logging model\")\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=exp_details.get(\"name\", \"sample_experiment\")+\"_\"+algorithm[1],\n",
    "                               comment=\"test\",\n",
    "                               version_name=\"run1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "                               metrics=[{\"model_metrics\": {\"MSE\": mse, \"MAE\": mae, \"r2\": r2}, \"project_id\": \"0001\", \"type\": \"EXP\"}])\n",
    "            logger.info(\"logging of model completed!!!\")\n",
    "        except Exception as ex:\n",
    "            logger.info(\"Exception Occured\")\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                pass\n",
    "            else:\n",
    "                return str(ex).split('?')\n",
    "    return [{\"EXP_NAME\":exp_details.get(\"name\", \"sample_experiment\"),\n",
    "             \"Version\":\"Run1\",\n",
    "             \"matrices\":{\"model_metrics\": {\"MSE\": mse, \"MAE\": mae, \"r2\": r2}, \"project_id\": \"0001\", \"type\": \"EXP\"},\n",
    "             \"Alogirthm_Type\":\"Regression\",\n",
    "             \"Alogithms\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_exp_name\":\"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24313b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.10.1, Python Version: 3.9.18, Platform: Linux-5.10.215-203.850.amzn2.x86_64-x86_64-with-glibc2.34\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:snowflake.snowpark.session:Snowpark Session information: \n",
      "\"version\" : 1.18.0,\n",
      "\"python.version\" : 3.9.18,\n",
      "\"python.connector.version\" : 3.10.1,\n",
      "\"python.connector.session.id\" : 96125690844958,\n",
      "\"os.name\" : Linux\n",
      "\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 2\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.18.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-ml-python' in the local environment is 1.5.1, which does not fit the criteria for the requirement 'snowflake-ml-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Stored procedure has been created successfully!\n",
      "Executing Procedure\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 12\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "Stored Procedure Executed Successfully !\n",
      "[\n",
      "  {\n",
      "    \"Alogirthm_Type\": \"Regression\",\n",
      "    \"Alogithms\": [\n",
      "      \"snowflake.ml.modeling.ensemble.GradientBoostingClassifier\"\n",
      "    ],\n",
      "    \"EXP_NAME\": \"testsize00\",\n",
      "    \"RUN_STATUS\": \"SUCCESS\",\n",
      "    \"Version\": \"Run1\",\n",
      "    \"matrices\": {\n",
      "      \"model_metrics\": {\n",
      "        \"MAE\": 1.605210000000000e-01,\n",
      "        \"MSE\": 1.605206073752712e-01,\n",
      "        \"r2\": 3.184015984021989e-01\n",
      "      },\n",
      "      \"project_id\": \"0001\",\n",
      "      \"type\": \"EXP\"\n",
      "    },\n",
      "    \"registry_exp_name\": \"\"\n",
      "  }\n",
      "]\n",
      "Logging in mlflow completed !\n"
     ]
    }
   ],
   "source": [
    "# Initilization\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "# stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "# session.sproc.register(func=train_ml_models,\n",
    "#                        name=\"train_ml_models\",\n",
    "#                        packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "#                        isPermanant=False,\n",
    "#                        stage_location=stage,\n",
    "#                        replace=True)\n",
    "# print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# procedure_response = session.call(\"train_ml_models\", exp_data)\n",
    "procedure_response = train_ml_models(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62811208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
