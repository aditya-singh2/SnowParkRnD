{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(sf_pass, algos, dataset, target):    \n",
    "    import os, importlib\n",
    "    from snowflake.snowpark import Session\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "#     from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "    from snowflake.ml.modeling.compose import ColumnTransformer\n",
    "    from snowflake.snowpark import Session, FileOperation\n",
    "\n",
    "    connection_parameters = {\n",
    "        \"account\": \"ug94937.us-east4.gcp\",\n",
    "        \"user\": \"ADITYASINGH\",\n",
    "        \"password\": sf_pass,\n",
    "        \"role\": \"ADITYASINGH\",  # optional\n",
    "        \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "        \"database\": \"FIRST_DB\",  # optional\n",
    "        \"schema\": \"PUBLIC\",  # optional\n",
    "    } \n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "    \n",
    "    # Read dataset\n",
    "    df_train, df_test = session.table(dataset).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    print(df_train.show())\n",
    "    features = df_train.columns\n",
    "    features.remove(target)\n",
    "    \n",
    "    # generating feature names\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {dataset}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=target:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    categorical_features_oe = list(map(lambda a: a+'_OE', categorical_features))\n",
    "    print(\"numerical_features: \", numerical_features)\n",
    "    print(\"categorical_features_oe: \", categorical_features_oe)\n",
    "    \n",
    "#     #Numerical pipeline\n",
    "#     numeric_transform = Pipeline(steps=[\n",
    "#         (\"scaler\", MinMaxScaler(output_cols=numerical_features))\n",
    "#     ]\n",
    "#     )\n",
    "    \n",
    "#     #Categorical pipeline\n",
    "#     categoric_transform = Pipeline(steps=[\n",
    "#         (\"ord\", OrdinalEncoder(output_cols=categorical_features_oe))\n",
    "#     ]\n",
    "#     )\n",
    "    \n",
    "#     #preprocessor\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         output_cols=categorical_features_oe+numerical_features+[target],\n",
    "#         transformers=[\n",
    "#             ('num', numeric_transform, numerical_features),\n",
    "#             ('cat', categoric_transform, categorical_features)\n",
    "#         ],\n",
    "#         remainder='passthrough'\n",
    "#     )\n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically generate list of selected algorithms for imports\n",
    "    \n",
    "    #pipeline steps #elif key=='num' and numerical_features!=[]\n",
    "    categorical_pp = {\n",
    "        'ord': OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe) \n",
    "    }\n",
    "    \n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = []\n",
    "    steps.append([(key, categorical_pp[key]) for key in categorical_pp if categorical_features!=[]])\n",
    "    steps.append([(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]])\n",
    "    print(steps)\n",
    "    \n",
    "    df_all_pred = None\n",
    "    for algorithm in algos:\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        print(algorithm[1])\n",
    "        attr = getattr(module, algorithm[1])\n",
    "#         pipe = Pipeline(steps=[\n",
    "#                 (\"ord\", OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe)),\n",
    "#                 (\"scaler\", MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)),\n",
    "#                 (\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "#                                               , label_cols=[target]\n",
    "#                                               , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))\n",
    "#                  ]\n",
    "#                )\n",
    "        pipe = Pipeline(steps=steps+[(\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "                                              , label_cols=[target]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "#         pipe = Pipeline(steps=[\n",
    "#             ('preprocessor', preprocessor),\n",
    "#             ('algorithm', attr(input_cols=categorical_features+numerical_features\n",
    "#                                               , label_cols=[target]\n",
    "#                                               , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))\n",
    "#         ])\n",
    "        # Fit the pipeline\n",
    "        xgb_model = pipe.fit(df_train)\n",
    "         \n",
    "        # Test the model\n",
    "        df_test_pred = xgb_model.predict(df_test)\n",
    "        \n",
    "        #combining predictions\n",
    "        if df_all_pred is None:\n",
    "            df_all_pred = df_test_pred.select(df_test_pred[f'PREDICTIONS_{algorithm[1]}'.upper()])\n",
    "        else:\n",
    "            df_all_pred = df_all_pred.join(df_test_pred.select(df_test_pred[f'PREDICTIONS_{algorithm[1]}'.upper()]))\n",
    "            \n",
    "        # metrices\n",
    "        mse = mean_squared_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        mae = mean_absolute_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        r2 = r2_score(df=df_test_pred, y_true_col_name=target, y_pred_col_name=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        print(f'{algorithm[1]} MSE: {mse}')\n",
    "        print(f'{algorithm[1]} MAE: {mae}')\n",
    "        print(f'{algorithm[1]} R2: {r2}')\n",
    "        \n",
    "    return df_all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0f11cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"EDUCATION\"  |\"JOININGYEAR\"  |\"CITY\"     |\"PAYMENTTIER\"  |\"AGE\"  |\"GENDER\"  |\"EVERBENCHED\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|Bachelors    |2017           |Bangalore  |3              |34     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2013           |Pune       |1              |28     |Female    |No             |3                            |1             |\n",
      "|Bachelors    |2014           |New Delhi  |3              |38     |Female    |No             |2                            |0             |\n",
      "|Masters      |2016           |Bangalore  |3              |27     |Male      |No             |5                            |1             |\n",
      "|Masters      |2017           |Pune       |3              |24     |Male      |Yes            |2                            |1             |\n",
      "|Bachelors    |2016           |Bangalore  |3              |22     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2015           |New Delhi  |3              |38     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2016           |Bangalore  |3              |34     |Female    |No             |2                            |1             |\n",
      "|Bachelors    |2016           |Pune       |3              |23     |Male      |No             |1                            |0             |\n",
      "|Masters      |2017           |New Delhi  |2              |37     |Male      |No             |2                            |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "None\n",
      "numerical_features:  ['EXPERIENCEINCURRENTDOMAIN', 'PAYMENTTIER', 'JOININGYEAR', 'AGE']\n",
      "categorical_features_oe:  ['EDUCATION_OE', 'CITY_OE', 'GENDER_OE', 'EVERBENCHED_OE']\n",
      "[[('ord', <snowflake.ml.modeling.preprocessing.ordinal_encoder.OrdinalEncoder object at 0x7e77d867fc10>)], [('scaler', <snowflake.ml.modeling.preprocessing.min_max_scaler.MinMaxScaler object at 0x7e77d867fc70>)]]\n",
      "GaussianNB\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mrun_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSF_Password\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnowflake.ml.modeling.naive_bayes.GaussianNB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnowflake.ml.modeling.neighbors.KNeighborsClassifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m               \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEMPLOYEE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLEAVEORNOT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 96\u001b[0m, in \u001b[0;36mrun_exp\u001b[0;34m(sf_pass, algos, dataset, target)\u001b[0m\n\u001b[1;32m     87\u001b[0m         attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, algorithm[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#         pipe = Pipeline(steps=[\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#                 (\"ord\", OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe)),\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#                 (\"scaler\", MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#                  ]\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#                )\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m         pipe \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malgorithm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features_oe\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnumerical_features\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPREDICTIONS_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43malgorithm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#         pipe = Pipeline(steps=[\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#             ('preprocessor', preprocessor),\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m#             ('algorithm', attr(input_cols=categorical_features+numerical_features\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m#         ])\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;66;03m# Fit the pipeline\u001b[39;00m\n\u001b[1;32m    107\u001b[0m         xgb_model \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mfit(df_train)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/modeling/pipeline/pipeline.py:112\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_signature_dict: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, ModelSignature]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m deps: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpd\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, obj \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base\u001b[38;5;241m.\u001b[39mBaseTransformer):\n\u001b[1;32m    114\u001b[0m         deps \u001b[38;5;241m=\u001b[39m deps \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_get_dependencies())\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "test = run_exp(os.environ.get('SF_Password'),\n",
    "               ['snowflake.ml.modeling.naive_bayes.GaussianNB',\n",
    "                'snowflake.ml.modeling.neighbors.KNeighborsClassifier',\n",
    "               ],\n",
    "               'EMPLOYEE', \n",
    "               'LEAVEORNOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc1cb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "|\"PREDICTIONS_GAUSSIANNB\"  |\"PREDICTIONS_KNEIGHBORSCLASSIFIER\"  |\n",
      "-----------------------------------------------------------------\n",
      "|1                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "|1                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "|1                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "|0                         |0                                   |\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cd2080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"FIXED_ACIDITY\"  |\"VOLATILE_ACIDITY\"  |\"CITRIC_ACID\"  |\"RESIDUAL_SUGAR\"  |\"CHLORIDES\"  |\"FREE_SULFUR_DIOXIDE\"  |\"TOTAL_SULFUR_DIOXIDE\"  |\"DENSITY\"  |\"PH\"  |\"SULPHATES\"  |\"ALCOHOL\"  |\"QUALITY\"  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|7.4              |0.7                 |0.0            |1.9               |0.076        |11.0                   |34.0                    |0.9978     |3.51  |0.56         |9.4        |5          |\n",
      "|7.8              |0.88                |0.0            |2.6               |0.098        |25.0                   |67.0                    |0.9968     |3.2   |0.68         |9.8        |5          |\n",
      "|7.8              |0.76                |0.04           |2.3               |0.092        |15.0                   |54.0                    |0.997      |3.26  |0.65         |9.8        |5          |\n",
      "|11.2             |0.28                |0.56           |1.9               |0.075        |17.0                   |60.0                    |0.998      |3.16  |0.58         |9.8        |6          |\n",
      "|7.4              |0.7                 |0.0            |1.9               |0.076        |11.0                   |34.0                    |0.9978     |3.51  |0.56         |9.4        |5          |\n",
      "|7.4              |0.66                |0.0            |1.8               |0.075        |13.0                   |40.0                    |0.9978     |3.51  |0.56         |9.4        |5          |\n",
      "|7.9              |0.6                 |0.06           |1.6               |0.069        |15.0                   |59.0                    |0.9964     |3.3   |0.46         |9.4        |5          |\n",
      "|7.3              |0.65                |0.0            |1.2               |0.065        |15.0                   |21.0                    |0.9946     |3.39  |0.47         |10.0       |7          |\n",
      "|7.8              |0.58                |0.02           |2.0               |0.073        |9.0                    |18.0                    |0.9968     |3.36  |0.57         |9.5        |7          |\n",
      "|7.5              |0.5                 |0.36           |6.1               |0.071        |17.0                   |102.0                   |0.9978     |3.35  |0.8          |10.5       |5          |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "None\n",
      "numerical_features:  ['TOTAL_SULFUR_DIOXIDE', 'CHLORIDES', 'VOLATILE_ACIDITY', 'DENSITY', 'SULPHATES', 'PH', 'FIXED_ACIDITY', 'ALCOHOL', 'RESIDUAL_SUGAR', 'FREE_SULFUR_DIOXIDE', 'CITRIC_ACID']\n",
      "categorical_features_oe:  []\n",
      "SGDRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SGDRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor MSE: 0.5911036852513518\n",
      "SGDRegressor MAE: 0.5638203185808013\n",
      "SGDRegressor R2: 0.2573450961761776\n",
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LinearSVR from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR MSE: 0.48555950380657903\n",
      "LinearSVR MAE: 0.497915045290663\n",
      "LinearSVR R2: 0.38994941903148417\n"
     ]
    }
   ],
   "source": [
    "test = run_exp(os.environ.get('SF_Password'),\n",
    "               ['snowflake.ml.modeling.linear_model.SGDRegressor',\n",
    "                'snowflake.ml.modeling.svm.LinearSVR',\n",
    "               ],\n",
    "               'ALCOHOL_QUALITY', \n",
    "               'QUALITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd2683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "|\"PREDICTIONS_SGDREGRESSOR\"  |\"PREDICTIONS_LINEARSVR\"  |\n",
      "--------------------------------------------------------\n",
      "|5.367994358476709           |5.269499192414458        |\n",
      "|5.367994358476709           |5.091083657079792        |\n",
      "|5.367994358476709           |5.302380489762069        |\n",
      "|5.367994358476709           |4.964908195867796        |\n",
      "|5.367994358476709           |4.859939892167627        |\n",
      "|5.367994358476709           |5.843309701689729        |\n",
      "|5.367994358476709           |6.6160259500357          |\n",
      "|5.367994358476709           |5.336366639516772        |\n",
      "|5.367994358476709           |5.142199548781186        |\n",
      "|5.367994358476709           |5.646059298483008        |\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce6695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
