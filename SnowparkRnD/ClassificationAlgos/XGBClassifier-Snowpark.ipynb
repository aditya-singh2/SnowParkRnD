{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, DoubleType, StringType\n",
    "import snowflake.snowpark.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d01210",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "#     \"authenticator\": \"externalbrowser\", # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4355a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : ADITYASINGH\n",
      "Role                        : \"ADITYASINGH\"\n",
      "Database                    : \"FIRST_DB\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"FOSFOR_INSIGHT_WH\"\n",
      "Snowflake version           : 8.20.10\n",
      "Snowpark for Python version : 1.17.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Edit the connection.json before creating the session object below\n",
    "# Create Snowflake Session object\n",
    "# connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae506c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.snowpark import Session, FileOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6496c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = session.table('EMPLOYEE')\n",
    "df_train, df_test = session.table('EMPLOYEE').drop('ROW').random_split(weights=[0.9, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c35e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"EDUCATION\"  |\"JOININGYEAR\"  |\"CITY\"     |\"PAYMENTTIER\"  |\"AGE\"  |\"GENDER\"  |\"EVERBENCHED\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|Bachelors    |2017           |Bangalore  |3              |34     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2013           |Pune       |1              |28     |Female    |No             |3                            |1             |\n",
      "|Bachelors    |2014           |New Delhi  |3              |38     |Female    |No             |2                            |0             |\n",
      "|Masters      |2016           |Bangalore  |3              |27     |Male      |No             |5                            |1             |\n",
      "|Masters      |2017           |Pune       |3              |24     |Male      |Yes            |2                            |1             |\n",
      "|Bachelors    |2016           |Bangalore  |3              |22     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2015           |New Delhi  |3              |38     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2016           |Bangalore  |3              |34     |Female    |No             |2                            |1             |\n",
      "|Bachelors    |2016           |Pune       |3              |23     |Male      |No             |1                            |0             |\n",
      "|Masters      |2017           |New Delhi  |2              |37     |Male      |No             |2                            |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70261a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDUCATION', 'JOININGYEAR', 'CITY', 'PAYMENTTIER', 'AGE', 'GENDER', 'EVERBENCHED', 'EXPERIENCEINCURRENTDOMAIN']\n"
     ]
    }
   ],
   "source": [
    "cols = df_train.columns\n",
    "cols.remove('LEAVEORNOT')\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ba4f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = session.sql(\"DESCRIBE TABLE EMPLOYEE\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86eedb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "categorical_columns = []\n",
    "for row in data_schema:\n",
    "    for typ in categorical_types:\n",
    "        if typ in row['type'] and row['name']!='LEAVEORNOT':\n",
    "            categorical_columns.append(row['name'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9769588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = list(set(cols) - set(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07eab110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE', 'EXPERIENCEINCURRENTDOMAIN', 'JOININGYEAR', 'PAYMENTTIER']\n",
      "['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4114d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_oe = list(map(lambda a: a+'_OE', categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7e5d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDUCATION_OE', 'CITY_OE', 'GENDER_OE', 'EVERBENCHED_OE']\n",
      "['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_columns_oe)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c27b0633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "ename": "SnowparkColumnException",
     "evalue": "(1300) (1105): The DataFrame does not contain the column named PRICE.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkColumnException\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/_internal/telemetry.py:367\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/modeling/metrics/regression.py:536\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(df, y_true_col_names, y_pred_col_names, sample_weight_col_name, multioutput, squared)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_outputs):\n\u001b[1;32m    534\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_column(\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i),\n\u001b[0;32m--> 536\u001b[0m         F\u001b[38;5;241m.\u001b[39mpow(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m df[y_pred[i]], \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m    537\u001b[0m     )\n\u001b[1;32m    539\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    540\u001b[0m     [\n\u001b[1;32m    541\u001b[0m         metrics_utils\u001b[38;5;241m.\u001b[39mweighted_sum(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     ]\n\u001b[1;32m    550\u001b[0m )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/dataframe.py:1022\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Column):\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/dataframe.py:1063\u001b[0m, in \u001b[0;36mDataFrame.col\u001b[0;34m(self, col_name)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/dataframe.py:4085\u001b[0m, in \u001b[0;36mDataFrame._resolve\u001b[0;34m(self, col_name)\u001b[0m\n\u001b[1;32m   4084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4085\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mDF_CANNOT_RESOLVE_COLUMN_NAME(\n\u001b[1;32m   4086\u001b[0m         col_name\n\u001b[1;32m   4087\u001b[0m     )\n",
      "\u001b[0;31mSnowparkColumnException\u001b[0m: (1105): The DataFrame does not contain the column named PRICE.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSnowparkColumnException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_test_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(df_test)\n\u001b[0;32m---> 17\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_test_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true_col_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPRICE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_col_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPREDICTION\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(df\u001b[38;5;241m=\u001b[39mdf_test_pred, y_true_col_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRICE\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_pred_col_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREDICTION\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(df\u001b[38;5;241m=\u001b[39mdf_test_pred, y_true_col_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRICE\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_pred_col_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREDICTION\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/_internal/telemetry.py:389\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m update_stmt_params_if_snowpark_df(res, statement_params)\n",
      "\u001b[0;31mSnowparkColumnException\u001b[0m: (1300) (1105): The DataFrame does not contain the column named PRICE."
     ]
    }
   ],
   "source": [
    "# Define a pipeline that does the preprocessing and training of \n",
    "# a XGBRegressor model\n",
    "pipe = Pipeline(steps=[\n",
    "          (\"ord\", OrdinalEncoder(input_cols=categorical_columns, output_cols=categorical_columns_oe)),\n",
    "          (\"scaler\", MinMaxScaler(input_cols=numerical_columns, output_cols=numerical_columns)),\n",
    "          (\"regressor\", XGBClassifier(input_cols=categorical_columns_oe+numerical_columns\n",
    "                                      , label_cols=[\"LEAVEORNOT\"]\n",
    "                                      , output_cols=['PREDICTION'], n_jobs=-1))\n",
    "         ]\n",
    "       )\n",
    " \n",
    "# Fit the pipeline\n",
    "xgb_model = pipe.fit(df_train)\n",
    " \n",
    "# Test the model\n",
    "df_test_pred = xgb_model.predict(df_test)\n",
    "mse = mean_squared_error(df=df_test_pred, y_true_col_names=\"LEAVEORNOT\", y_pred_col_names=\"PREDICTION\")\n",
    "mae = mean_absolute_error(df=df_test_pred, y_true_col_names=\"LEAVEORNOT\", y_pred_col_names=\"PREDICTION\")\n",
    "r2 = r2_score(df=df_test_pred, y_true_col_name=\"LEAVEORNOT\", y_pred_col_name=\"PREDICTION\")\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddedd64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df, target_column):\n",
    "    \"\"\"\n",
    "    Checking whether encoding required in target and feature datasets.\n",
    "    If required, then encoding them with label and one hot encoding.\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    target_column: target column\n",
    "    :returns:\n",
    "    df_target: target dataframe\n",
    "    le_target: target label encoder object\n",
    "    df_feature: feature dataframe\n",
    "    le_dict_feature: dict of feature label encoder objects\n",
    "    oh_enc_feature: feature one hot encoder object\n",
    "    le_column_feature: list of feature label encoder columns\n",
    "    oh_column_feature: list of feature one hot encoder columns\n",
    "    \"\"\"\n",
    "    df_target = df[[target_column]]\n",
    "    le_target = None\n",
    "    # Target column validation and encoding\n",
    "    if df.dtypes[target_column].name in ['object', 'bool']:\n",
    "        print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "        le_target = LabelEncoder()\n",
    "        df_target[target_column] = pd.DataFrame(le_target.fit_transform(df_target[target_column].astype(str)))\n",
    "        print(f\"Target column label encoded {df_target[target_column]}, object: {le_target}\")\n",
    "\n",
    "    # Feature column validation and encoding\n",
    "    df_feature = df.drop(target_column, axis=1)\n",
    "    non_numeric_cols = df_feature.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    le_dict_feature = {}\n",
    "    le_column_feature = []\n",
    "    oh_column_feature = []\n",
    "    oh_enc_feature = None\n",
    "    if len(non_numeric_cols) >= 1:\n",
    "        print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for col in non_numeric_cols:\n",
    "            if df_feature[col].nunique() >= 10:\n",
    "                le_column_feature.append(col)\n",
    "            else:\n",
    "                oh_column_feature.append(col)\n",
    "\n",
    "        print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "              f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "\n",
    "        # columns to be label encoded\n",
    "        if len(le_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            for col in le_column_feature:\n",
    "                le_dict_feature[col] = LabelEncoder()\n",
    "                df_feature[col] = le_dict_feature[col].fit_transform(df_feature[col].astype(str))\n",
    "                print(f\"{col} column label encoded {df_feature[col]}, object: {le_dict_feature[col]}\")\n",
    "\n",
    "        # columns to be one hot encoded\n",
    "        if len(oh_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "            unique_combinations_list = unique_combinations.columns.tolist()\n",
    "            oh_enc_feature = OneHotEncoder()\n",
    "            oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "            df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "            df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "            df_feature = df_feature.join(df_oh_enc)\n",
    "            print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                  f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "        print(f\"final feature df created: {df_feature}\")\n",
    "    return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26534e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Education', 'City', 'Gender', 'EverBenched'] columns are non numeric in feature dataset, encoding required.\n",
      "Columns identified to be encoded with label encoder: []\n",
      "Columns identified to be encoded with one hot encoder: ['Education', 'City', 'Gender', 'EverBenched']\n",
      "new one hot encoded df: [[1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]]\n",
      "one hot encoder object: OneHotEncoder()\n",
      "\n",
      "final feature df created:       JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
      "0            2017            3   34                          0   \n",
      "1            2013            1   28                          3   \n",
      "2            2014            3   38                          2   \n",
      "3            2016            3   27                          5   \n",
      "4            2017            3   24                          2   \n",
      "...           ...          ...  ...                        ...   \n",
      "4648         2013            3   26                          4   \n",
      "4649         2013            2   37                          2   \n",
      "4650         2018            3   27                          5   \n",
      "4651         2012            3   30                          2   \n",
      "4652         2015            3   33                          4   \n",
      "\n",
      "      Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
      "0                     1.0                0.0            0.0             1.0   \n",
      "1                     1.0                0.0            0.0             0.0   \n",
      "2                     1.0                0.0            0.0             0.0   \n",
      "3                     0.0                1.0            0.0             1.0   \n",
      "4                     0.0                1.0            0.0             0.0   \n",
      "...                   ...                ...            ...             ...   \n",
      "4648                  1.0                0.0            0.0             1.0   \n",
      "4649                  0.0                1.0            0.0             0.0   \n",
      "4650                  0.0                1.0            0.0             0.0   \n",
      "4651                  1.0                0.0            0.0             1.0   \n",
      "4652                  1.0                0.0            0.0             1.0   \n",
      "\n",
      "      City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
      "0                0.0        0.0            0.0          1.0             1.0   \n",
      "1                0.0        1.0            1.0          0.0             1.0   \n",
      "2                1.0        0.0            1.0          0.0             1.0   \n",
      "3                0.0        0.0            0.0          1.0             1.0   \n",
      "4                0.0        1.0            0.0          1.0             0.0   \n",
      "...              ...        ...            ...          ...             ...   \n",
      "4648             0.0        0.0            1.0          0.0             1.0   \n",
      "4649             0.0        1.0            0.0          1.0             1.0   \n",
      "4650             1.0        0.0            0.0          1.0             1.0   \n",
      "4651             0.0        0.0            0.0          1.0             0.0   \n",
      "4652             0.0        0.0            0.0          1.0             0.0   \n",
      "\n",
      "      EverBenched_Yes  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 1.0  \n",
      "...               ...  \n",
      "4648              0.0  \n",
      "4649              0.0  \n",
      "4650              0.0  \n",
      "4651              1.0  \n",
      "4652              1.0  \n",
      "\n",
      "[4653 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature = encoding(data,'LeaveOrNot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c95bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_No</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "\n",
       "   Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
       "0                  1.0                0.0            0.0             1.0   \n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
       "0             0.0        0.0            0.0          1.0             1.0   \n",
       "1             0.0        1.0            1.0          0.0             1.0   \n",
       "2             1.0        0.0            1.0          0.0             1.0   \n",
       "3             0.0        0.0            0.0          1.0             1.0   \n",
       "4             0.0        1.0            0.0          1.0             0.0   \n",
       "\n",
       "   EverBenched_Yes  LeaveOrNot  \n",
       "0              0.0           0  \n",
       "1              0.0           1  \n",
       "2              0.0           0  \n",
       "3              0.0           1  \n",
       "4              1.0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pandas = pd.concat([df_feature, df_target], axis=1)\n",
    "features_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae71aceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOININGYEAR</th>\n",
       "      <th>PAYMENTTIER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCEINCURRENTDOMAIN</th>\n",
       "      <th>EDUCATION_BACHELORS</th>\n",
       "      <th>EDUCATION_MASTERS</th>\n",
       "      <th>EDUCATION_PHD</th>\n",
       "      <th>CITY_BANGALORE</th>\n",
       "      <th>CITY_NEW_DELHI</th>\n",
       "      <th>CITY_PUNE</th>\n",
       "      <th>GENDER_FEMALE</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>EVERBENCHED_NO</th>\n",
       "      <th>EVERBENCHED_YES</th>\n",
       "      <th>LEAVEORNOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JOININGYEAR  PAYMENTTIER  AGE  EXPERIENCEINCURRENTDOMAIN  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "\n",
       "   EDUCATION_BACHELORS  EDUCATION_MASTERS  EDUCATION_PHD  CITY_BANGALORE  \\\n",
       "0                  1.0                0.0            0.0             1.0   \n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   CITY_NEW_DELHI  CITY_PUNE  GENDER_FEMALE  GENDER_MALE  EVERBENCHED_NO  \\\n",
       "0             0.0        0.0            0.0          1.0             1.0   \n",
       "1             0.0        1.0            1.0          0.0             1.0   \n",
       "2             1.0        0.0            1.0          0.0             1.0   \n",
       "3             0.0        0.0            0.0          1.0             1.0   \n",
       "4             0.0        1.0            0.0          1.0             0.0   \n",
       "\n",
       "   EVERBENCHED_YES  LEAVEORNOT  \n",
       "0              0.0           0  \n",
       "1              0.0           1  \n",
       "2              0.0           0  \n",
       "3              0.0           1  \n",
       "4              1.0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_pandas=features_pandas.drop(\"Unnamed: 0\", axis=1)\n",
    "features_pandas.columns = map(str.upper, features_pandas.columns)\n",
    "features_pandas.columns = features_pandas.columns.str.replace(' ', '_')\n",
    "features_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85205f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"JOININGYEAR\"  |\"PAYMENTTIER\"  |\"AGE\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"EDUCATION_BACHELORS\"  |\"EDUCATION_MASTERS\"  |\"EDUCATION_PHD\"  |\"CITY_BANGALORE\"  |\"CITY_NEW_DELHI\"  |\"CITY_PUNE\"  |\"GENDER_FEMALE\"  |\"GENDER_MALE\"  |\"EVERBENCHED_NO\"  |\"EVERBENCHED_YES\"  |\"LEAVEORNOT\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2017           |3              |34     |0                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2013           |1              |28     |3                            |1.0                    |0.0                  |0.0              |0.0               |0.0               |1.0          |1.0              |0.0            |1.0               |0.0                |1             |\n",
      "|2014           |3              |38     |2                            |1.0                    |0.0                  |0.0              |0.0               |1.0               |0.0          |1.0              |0.0            |1.0               |0.0                |0             |\n",
      "|2016           |3              |27     |5                            |0.0                    |1.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |1             |\n",
      "|2017           |3              |24     |2                            |0.0                    |1.0                  |0.0              |0.0               |0.0               |1.0          |0.0              |1.0            |0.0               |1.0                |1             |\n",
      "|2016           |3              |22     |0                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2015           |3              |38     |0                            |1.0                    |0.0                  |0.0              |0.0               |1.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2016           |3              |34     |2                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |1.0              |0.0            |1.0               |0.0                |1             |\n",
      "|2016           |3              |23     |1                            |1.0                    |0.0                  |0.0              |0.0               |0.0               |1.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2017           |2              |37     |2                            |0.0                    |1.0                  |0.0              |0.0               |1.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = session.create_dataframe(features_pandas)\n",
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0deaefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS=list(features_df.columns)\n",
    "FEATURE_COLUMNS.remove('LEAVEORNOT')\n",
    "# print(FEATURE_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f58a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize all the features for modeling\n",
    "# CATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\n",
    "\n",
    "# CATEGORICAL_COLUMNS_OE = [\"FIXED_ACIDITY\",\"VOLATILE_ACIDITY\",\"CITRIC_ACID\",\"RESIDUAL_SUGAR\",\"CHLORIDES\",\"FREE_SULFUR_DIOXIDE\",\"TOTAL_SULFUR_DIOXIDE\",\"DENSITY\",\"PH\",\"SULPHATES\",\"ALCOHOL\"] # To name the ordinal encoded columns\n",
    "# NUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TABLE_PCT\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "LABEL_COLUMNS = [\"LEAVEORNOT\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]\n",
    "\n",
    "# input_cols=FEATURE_COLUMNS\n",
    "# label_cols=LABEL_COLUMNS\n",
    "# output_cols=OUTPUT_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89eae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    input_cols=FEATURE_COLUMNS,\n",
    "    label_cols=LABEL_COLUMNS,\n",
    "    output_cols=OUTPUT_COLUMNS\n",
    ")\n",
    "model.fit(features_df)\n",
    "\n",
    "# Use the model to make predictions.\n",
    "predictions = model.predict(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ccdb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "|\"PREDICTION\"  |\n",
      "----------------\n",
      "|0             |\n",
      "|1             |\n",
      "|0             |\n",
      "|1             |\n",
      "|1             |\n",
      "|0             |\n",
      "|0             |\n",
      "|0             |\n",
      "|0             |\n",
      "|0             |\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions[OUTPUT_COLUMNS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f11cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
