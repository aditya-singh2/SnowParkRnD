{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(sf_pass, algos, dataset, target):    \n",
    "    import os, importlib\n",
    "    from snowflake.snowpark import Session\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "#     from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "    from snowflake.snowpark import Session, FileOperation\n",
    "\n",
    "    connection_parameters = {\n",
    "        \"account\": \"ug94937.us-east4.gcp\",\n",
    "        \"user\": \"ADITYASINGH\",\n",
    "        \"password\": sf_pass,\n",
    "        \"role\": \"ADITYASINGH\",  # optional\n",
    "        \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "        \"database\": \"FIRST_DB\",  # optional\n",
    "        \"schema\": \"PUBLIC\",  # optional\n",
    "    } \n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "    \n",
    "    # Read dataset\n",
    "    df_train, df_test = session.table(dataset).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    features = df_train.columns\n",
    "    features.remove(target)\n",
    "    \n",
    "    # generating feature names\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {dataset}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=target:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    categorical_features_oe = list(map(lambda a: a+'_OE', categorical_features))\n",
    "    \n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically generate list of selected algorithms for imports\n",
    "    for algorithm in algos:\n",
    "        df_all_pred = None\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        pipe = Pipeline(steps=[\n",
    "                  (\"ord\", OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe)),\n",
    "                  (\"scaler\", MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)),\n",
    "                  (\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "                                              , label_cols=[target]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}']))\n",
    "                 ]\n",
    "               )\n",
    "         \n",
    "        # Fit the pipeline\n",
    "        xgb_model = pipe.fit(df_train)\n",
    "         \n",
    "        # Test the model\n",
    "        df_test_pred = xgb_model.predict(df_test)\n",
    "        \n",
    "        #combining predictions\n",
    "        if df_all_pred is None:\n",
    "#             schema = StructType([\n",
    "#                 StructField(f\"PREDICTIONS_{algorithm[1]}\", IntegerType)\n",
    "#             ])\n",
    "#             df_all_pred = session.create_dataframe([], schema)\n",
    "            df_all_pred = df_test_pred.select(df_test_pred['PREDICTIONS'])\n",
    "        else:\n",
    "            df_all_pred[f\"PREDICTIONS_{algorithm[1]}\"] = df_test_pred[f'PREDICTIONS_{algorithm[1]}']\n",
    "        # metrices\n",
    "        mse = mean_squared_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=f'PREDICTIONS_{algorithm[1]}')\n",
    "        mae = mean_absolute_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=f'PREDICTIONS_{algorithm[1]}')\n",
    "        r2 = r2_score(df=df_test_pred, y_true_col_name=target, y_pred_col_name=f'PREDICTIONS_{algorithm[1]}')\n",
    "        print(f'{algorithm[1]} MSE: {mse}')\n",
    "        print(f'{algorithm[1]} MAE: {mae}')\n",
    "        print(f'{algorithm[1]} R2: {r2}')\n",
    "    return df_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0f11cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator AdaBoostRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1727640136965599\n",
      "MAE: 0.31845926309526407\n",
      "R2: 0.26641396693757746\n"
     ]
    }
   ],
   "source": [
    "test = run_exp(os.environ.get('SF_Password'),\n",
    "               ['snowflake.ml.modeling.naive_bayes.GaussianNB',\n",
    "                'snowflake.ml.modeling.neighbors.KNeighborsClassifier',\n",
    "               ],\n",
    "               'EMPLOYEE', \n",
    "               'LEAVEORNOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a22d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "#    from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.snowpark import Session, FileOperation\n",
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} \n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6720719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "            StructField(\"PREDICTIONS\", IntegerType())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87eb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = session.table(\"EMPLOYEE\").drop('ROW').random_split(weights=[0.9, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09f5470c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ea9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pred2 = df_train.select(df_train['CITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0212f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pred = df_all_pred.join(df_all_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0d4fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "|\"LEAVEORNOT\"  |\"CITY\"     |\n",
      "----------------------------\n",
      "|0             |Bangalore  |\n",
      "|0             |Bangalore  |\n",
      "|0             |New Delhi  |\n",
      "|0             |Pune       |\n",
      "|0             |Bangalore  |\n",
      "|0             |New Delhi  |\n",
      "|0             |New Delhi  |\n",
      "|0             |Bangalore  |\n",
      "|0             |Pune       |\n",
      "|0             |New Delhi  |\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "438fac7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostRegressor'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = 'snowflake.ml.modeling.ensemble.AdaBoostRegressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1cb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
