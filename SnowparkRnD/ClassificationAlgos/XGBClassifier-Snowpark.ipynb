{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(sf_pass, algos, dataset, target):    \n",
    "    import os, importlib\n",
    "    from snowflake.snowpark import Session\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "#     from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "    from snowflake.snowpark import Session, FileOperation\n",
    "\n",
    "    connection_parameters = {\n",
    "        \"account\": \"ug94937.us-east4.gcp\",\n",
    "        \"user\": \"ADITYASINGH\",\n",
    "        \"password\": sf_pass,\n",
    "        \"role\": \"ADITYASINGH\",  # optional\n",
    "        \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "        \"database\": \"FIRST_DB\",  # optional\n",
    "        \"schema\": \"PUBLIC\",  # optional\n",
    "    } \n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "    \n",
    "    # Read dataset\n",
    "    df_train, df_test = session.table(dataset).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    features = df_train.columns\n",
    "    features.remove(target)\n",
    "    \n",
    "    # generating feature names\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {dataset}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=target:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    categorical_features_oe = list(map(lambda a: a+'_OE', categorical_features))\n",
    "    \n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically generate list of selected algorithms for imports\n",
    "    for algorithm in algos:\n",
    "        df_all_pred = None\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        pipe = Pipeline(steps=[\n",
    "                  (\"ord\", OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe)),\n",
    "                  (\"scaler\", MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)),\n",
    "                  (\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "                                              , label_cols=[target]\n",
    "                                              , output_cols=['PREDICTION']))\n",
    "                 ]\n",
    "               )\n",
    "         \n",
    "        # Fit the pipeline\n",
    "        xgb_model = pipe.fit(df_train)\n",
    "         \n",
    "        # Test the model\n",
    "        df_test_pred = xgb_model.predict(df_test)\n",
    "        \n",
    "        #combining predictions\n",
    "        if df_all_pred is None:\n",
    "            schema = StructType([\n",
    "                StructField(f\"PREDICTIONS_{algorithm[1]}\", IntegerType)\n",
    "            ])\n",
    "            df_all_pred = session.create_dataframe([], schema)\n",
    "            df_all_pred = df_test_pred['PREDICTIONS']\n",
    "        else:\n",
    "            df_all_pred[f\"PREDICTIONS_{algorithm[1]}\"] = df_test_pred['PREDICTIONS']\n",
    "        # metrices\n",
    "        mse = mean_squared_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=\"PREDICTION\")\n",
    "        mae = mean_absolute_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=\"PREDICTION\")\n",
    "        r2 = r2_score(df=df_test_pred, y_true_col_name=target, y_pred_col_name=\"PREDICTION\")\n",
    "        print(f'MSE: {mse}')\n",
    "        print(f'MAE: {mae}')\n",
    "        print(f'R2: {r2}')\n",
    "    return df_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0f11cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator AdaBoostRegressor from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1727640136965599\n",
      "MAE: 0.31845926309526407\n",
      "R2: 0.26641396693757746\n"
     ]
    }
   ],
   "source": [
    "test = run_exp(os.environ.get('SF_Password'),\n",
    "               ['snowflake.ml.modeling.naive_bayes.GaussianNB',\n",
    "                'snowflake.ml.modeling.neighbors.KNeighborsClassifier',\n",
    "               ],\n",
    "               'EMPLOYEE', \n",
    "               'LEAVEORNOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a22d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "#    from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.snowpark import Session, FileOperation\n",
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} \n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6720719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "            StructField(\"PREDICTIONS\", IntegerType())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79974e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = session.table(\"EMPLOYEE\").drop('ROW').random_split(weights=[0.9, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09f5470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pred = session.create_dataframe([], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80ea9872",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid type for join. Must be Dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_all_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdf_all_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPREDICTION\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft_outer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/telemetry.py:202\u001b[0m, in \u001b[0;36mdf_api_usage.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 202\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     plan \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# Some DataFrame APIs call other DataFrame APIs, so we need to remove the extra call\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/dataframe.py:2496\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, right, on, how, lsuffix, rsuffix, match_condition, **kwargs)\u001b[0m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2484\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type for join column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(using_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2485\u001b[0m         )\n\u001b[1;32m   2487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_join_dataframes(\n\u001b[1;32m   2488\u001b[0m         right,\n\u001b[1;32m   2489\u001b[0m         using_columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2493\u001b[0m         match_condition\u001b[38;5;241m=\u001b[39mmatch_condition,\n\u001b[1;32m   2494\u001b[0m     )\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type for join. Must be Dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid type for join. Must be Dataframe"
     ]
    }
   ],
   "source": [
    "df_all_pred = df_train.select(df_train[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0212f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c0d4fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "|\"PREDICTIONS\"  |\n",
      "-----------------\n",
      "|               |\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "438fac7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdaBoostRegressor'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = 'snowflake.ml.modeling.ensemble.AdaBoostRegressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1cb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
