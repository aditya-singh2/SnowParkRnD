{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, DoubleType, StringType\n",
    "import snowflake.snowpark.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d01210",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "#     \"authenticator\": \"externalbrowser\", # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4355a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : ADITYASINGH\n",
      "Role                        : \"ADITYASINGH\"\n",
      "Database                    : \"FIRST_DB\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"FOSFOR_INSIGHT_WH\"\n",
      "Snowflake version           : 8.20.10\n",
      "Snowpark for Python version : 1.17.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Edit the connection.json before creating the session object below\n",
    "# Create Snowflake Session object\n",
    "# connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae506c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.snowpark import Session, FileOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6496c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = session.table('EMPLOYEE')\n",
    "df_train, df_test = session.table('EMPLOYEE').drop('ROW').random_split(weights=[0.9, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c35e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"EDUCATION\"  |\"JOININGYEAR\"  |\"CITY\"     |\"PAYMENTTIER\"  |\"AGE\"  |\"GENDER\"  |\"EVERBENCHED\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"LEAVEORNOT\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|Bachelors    |2017           |Bangalore  |3              |34     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2013           |Pune       |1              |28     |Female    |No             |3                            |1             |\n",
      "|Bachelors    |2014           |New Delhi  |3              |38     |Female    |No             |2                            |0             |\n",
      "|Masters      |2016           |Bangalore  |3              |27     |Male      |No             |5                            |1             |\n",
      "|Masters      |2017           |Pune       |3              |24     |Male      |Yes            |2                            |1             |\n",
      "|Bachelors    |2016           |Bangalore  |3              |22     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2015           |New Delhi  |3              |38     |Male      |No             |0                            |0             |\n",
      "|Bachelors    |2016           |Bangalore  |3              |34     |Female    |No             |2                            |1             |\n",
      "|Bachelors    |2016           |Pune       |3              |23     |Male      |No             |1                            |0             |\n",
      "|Masters      |2017           |New Delhi  |2              |37     |Male      |No             |2                            |0             |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70261a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDUCATION', 'JOININGYEAR', 'CITY', 'PAYMENTTIER', 'AGE', 'GENDER', 'EVERBENCHED', 'EXPERIENCEINCURRENTDOMAIN', 'LEAVEORNOT']\n"
     ]
    }
   ],
   "source": [
    "cols = df_train.columns\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba4f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = session.sql(\"DESCRIBE TABLE EMPLOYEE\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86eedb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "categorical_columns = []\n",
    "for row in data_schema:\n",
    "    for typ in categorical_types:\n",
    "        if typ in row['type']:\n",
    "            categorical_columns.append(row['name'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9769588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = list(set(cols) - set(categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6303ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JOININGYEAR', 'PAYMENTTIER', 'LEAVEORNOT', 'AGE', 'EXPERIENCEINCURRENTDOMAIN']\n",
      "['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f918dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_oe = list(map(lambda a: a+'_OE', categorical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146fd219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDUCATION_OE', 'CITY_OE', 'GENDER_OE', 'EVERBENCHED_OE']\n",
      "['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_columns_oe)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68f128cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1300) (1304): 01b4a0e3-0000-655a-0000-576d06b8207a: 002028 (42601): SQL compilation error:\nambiguous column name 'LEAVEORNOT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/_internal/telemetry.py:367\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/modeling/xgboost/xgb_classifier.py:455\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    453\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect(selected_cols)\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_snowpark_cols \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m    457\u001b[0m  \u001b[38;5;66;03m# If we are already in a stored procedure, no need to kick off another one.\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/dataframe.py:1056\u001b[0m, in \u001b[0;36mDataFrame.columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all column names as a list.\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;03mThe returned column names are consistent with the Snowflake database object `identifier syntax <https://docs.snowflake.com/en/sql-reference/identifiers-syntax.html>`_.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m==================================   ==========================\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1056\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/dataframe.py:4102\u001b[0m, in \u001b[0;36mDataFrame.schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The definition of the columns in this DataFrame (the \"relational schema\" for\u001b[39;00m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;124;03mthe DataFrame).\u001b[39;00m\n\u001b[1;32m   4101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StructType\u001b[38;5;241m.\u001b[39m_from_attributes(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattributes\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:319\u001b[0m, in \u001b[0;36mSnowflakePlan.attributes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattributes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Attribute]:\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# No simplifier case relies on this schema_query change to update SHOW TABLES to a nested sql friendly query.\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/analyzer/schema_utils.py:91\u001b[0m, in \u001b[0;36manalyze_attributes\u001b[0;34m(sql, session)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_result_meta_to_attribute(session\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mdescription)\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_result_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/session.py:2104\u001b[0m, in \u001b[0;36mSession._get_result_attributes\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_result_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Attribute]:\n\u001b[0;32m-> 2104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:191\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    189\u001b[0m     e\n\u001b[1;32m    190\u001b[0m )\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:122\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/server_connection.py:233\u001b[0m, in \u001b[0;36mServerConnection.get_result_attributes\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@SnowflakePlan\u001b[39m\u001b[38;5;241m.\u001b[39mDecorator\u001b[38;5;241m.\u001b[39mwrap_exception\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Attribute]:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_result_meta_to_attribute(\u001b[43mrun_new_describe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/snowpark/_internal/analyzer/schema_utils.py:144\u001b[0m, in \u001b[0;36mrun_new_describe\u001b[0;34m(cursor, query)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cursor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_describe_internal\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# Pyright does not perform narrowing here\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_describe_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/connector/cursor.py:1120\u001b[0m, in \u001b[0;36mSnowflakeCursor._describe_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_describe_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_internal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/connector/cursor.py:1080\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1080\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    344\u001b[0m cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b4a0e3-0000-655a-0000-576d06b8207a: 002028 (42601): SQL compilation error:\nambiguous column name 'LEAVEORNOT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m           (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mord\u001b[39m\u001b[38;5;124m\"\u001b[39m, OrdinalEncoder(input_cols\u001b[38;5;241m=\u001b[39mcategorical_columns, output_cols\u001b[38;5;241m=\u001b[39mcategorical_columns_oe)),\n\u001b[1;32m      5\u001b[0m           (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, MinMaxScaler(input_cols\u001b[38;5;241m=\u001b[39mnumerical_columns, output_cols\u001b[38;5;241m=\u001b[39mnumerical_columns)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m          ]\n\u001b[1;32m     10\u001b[0m        )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the pipeline\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_test_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(df_test)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/_internal/telemetry.py:372\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException):\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;66;03m# already handled via a nested decorated function\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_snowflake_ml_handled\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m_snowflake_ml_handled:\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowpark_exceptions\u001b[38;5;241m.\u001b[39mSnowparkClientException):\n\u001b[1;32m    374\u001b[0m         me \u001b[38;5;241m=\u001b[39m snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException(\n\u001b[1;32m    375\u001b[0m             error_code\u001b[38;5;241m=\u001b[39merror_codes\u001b[38;5;241m.\u001b[39mINTERNAL_SNOWPARK_ERROR, original_exception\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m    376\u001b[0m         )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/_internal/telemetry.py:367\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m telemetry_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    359\u001b[0m     func_name\u001b[38;5;241m=\u001b[39m_get_full_func_name(func),\n\u001b[1;32m    360\u001b[0m     function_category\u001b[38;5;241m=\u001b[39mTelemetryField\u001b[38;5;241m.\u001b[39mFUNC_CAT_USAGE\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m     custom_tags\u001b[38;5;241m=\u001b[39mcustom_tags,\n\u001b[1;32m    365\u001b[0m )\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, snowml_exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException):\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;66;03m# already handled via a nested decorated function\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/modeling/pipeline/pipeline.py:251\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator:\n\u001b[1;32m    250\u001b[0m     all_cols \u001b[38;5;241m=\u001b[39m transformed_dataset\u001b[38;5;241m.\u001b[39mcolumns[:]\n\u001b[0;32m--> 251\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_step_feature_consumption_info(\n\u001b[1;32m    254\u001b[0m         step_name\u001b[38;5;241m=\u001b[39mestimator[\u001b[38;5;241m0\u001b[39m], all_cols\u001b[38;5;241m=\u001b[39mall_cols, input_cols\u001b[38;5;241m=\u001b[39mestimator[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget_input_cols()\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_signatures(dataset\u001b[38;5;241m=\u001b[39mdataset)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/5fc8e328-978d-48c7-b3ec-89dee2264cf3/3.9/snowflake/ml/_internal/telemetry.py:389\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m update_stmt_params_if_snowpark_df(res, statement_params)\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1300) (1304): 01b4a0e3-0000-655a-0000-576d06b8207a: 002028 (42601): SQL compilation error:\nambiguous column name 'LEAVEORNOT'"
     ]
    }
   ],
   "source": [
    "# Define a pipeline that does the preprocessing and training of \n",
    "# a XGBRegressor model\n",
    "pipe = Pipeline(steps=[\n",
    "          (\"ord\", OrdinalEncoder(input_cols=categorical_columns, output_cols=categorical_columns_oe)),\n",
    "          (\"scaler\", MinMaxScaler(input_cols=numerical_columns, output_cols=numerical_columns)),\n",
    "          (\"regressor\", XGBClassifier(input_cols=categorical_columns_oe+numerical_columns\n",
    "                                      , label_cols=[\"LEAVEORNOT\"]\n",
    "                                      , output_cols=['PREDICTION'], n_jobs=-1))\n",
    "         ]\n",
    "       )\n",
    " \n",
    "# Fit the pipeline\n",
    "xgb_model = pipe.fit(df_train)\n",
    " \n",
    "# Test the model\n",
    "df_test_pred = xgb_model.predict(df_test)\n",
    "mse = mean_squared_error(df=df_test_pred, y_true_col_names=\"PRICE\", y_pred_col_names=\"PREDICTION\")\n",
    "mae = mean_absolute_error(df=df_test_pred, y_true_col_names=\"PRICE\", y_pred_col_names=\"PREDICTION\")\n",
    "r2 = r2_score(df=df_test_pred, y_true_col_name=\"PRICE\", y_pred_col_name=\"PREDICTION\")\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddedd64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df, target_column):\n",
    "    \"\"\"\n",
    "    Checking whether encoding required in target and feature datasets.\n",
    "    If required, then encoding them with label and one hot encoding.\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    target_column: target column\n",
    "    :returns:\n",
    "    df_target: target dataframe\n",
    "    le_target: target label encoder object\n",
    "    df_feature: feature dataframe\n",
    "    le_dict_feature: dict of feature label encoder objects\n",
    "    oh_enc_feature: feature one hot encoder object\n",
    "    le_column_feature: list of feature label encoder columns\n",
    "    oh_column_feature: list of feature one hot encoder columns\n",
    "    \"\"\"\n",
    "    df_target = df[[target_column]]\n",
    "    le_target = None\n",
    "    # Target column validation and encoding\n",
    "    if df.dtypes[target_column].name in ['object', 'bool']:\n",
    "        print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "        le_target = LabelEncoder()\n",
    "        df_target[target_column] = pd.DataFrame(le_target.fit_transform(df_target[target_column].astype(str)))\n",
    "        print(f\"Target column label encoded {df_target[target_column]}, object: {le_target}\")\n",
    "\n",
    "    # Feature column validation and encoding\n",
    "    df_feature = df.drop(target_column, axis=1)\n",
    "    non_numeric_cols = df_feature.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    le_dict_feature = {}\n",
    "    le_column_feature = []\n",
    "    oh_column_feature = []\n",
    "    oh_enc_feature = None\n",
    "    if len(non_numeric_cols) >= 1:\n",
    "        print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for col in non_numeric_cols:\n",
    "            if df_feature[col].nunique() >= 10:\n",
    "                le_column_feature.append(col)\n",
    "            else:\n",
    "                oh_column_feature.append(col)\n",
    "\n",
    "        print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "              f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "\n",
    "        # columns to be label encoded\n",
    "        if len(le_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            for col in le_column_feature:\n",
    "                le_dict_feature[col] = LabelEncoder()\n",
    "                df_feature[col] = le_dict_feature[col].fit_transform(df_feature[col].astype(str))\n",
    "                print(f\"{col} column label encoded {df_feature[col]}, object: {le_dict_feature[col]}\")\n",
    "\n",
    "        # columns to be one hot encoded\n",
    "        if len(oh_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "            unique_combinations_list = unique_combinations.columns.tolist()\n",
    "            oh_enc_feature = OneHotEncoder()\n",
    "            oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "            df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "            df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "            df_feature = df_feature.join(df_oh_enc)\n",
    "            print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                  f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "        print(f\"final feature df created: {df_feature}\")\n",
    "    return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26534e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Education', 'City', 'Gender', 'EverBenched'] columns are non numeric in feature dataset, encoding required.\n",
      "Columns identified to be encoded with label encoder: []\n",
      "Columns identified to be encoded with one hot encoder: ['Education', 'City', 'Gender', 'EverBenched']\n",
      "new one hot encoded df: [[1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]]\n",
      "one hot encoder object: OneHotEncoder()\n",
      "\n",
      "final feature df created:       JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
      "0            2017            3   34                          0   \n",
      "1            2013            1   28                          3   \n",
      "2            2014            3   38                          2   \n",
      "3            2016            3   27                          5   \n",
      "4            2017            3   24                          2   \n",
      "...           ...          ...  ...                        ...   \n",
      "4648         2013            3   26                          4   \n",
      "4649         2013            2   37                          2   \n",
      "4650         2018            3   27                          5   \n",
      "4651         2012            3   30                          2   \n",
      "4652         2015            3   33                          4   \n",
      "\n",
      "      Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
      "0                     1.0                0.0            0.0             1.0   \n",
      "1                     1.0                0.0            0.0             0.0   \n",
      "2                     1.0                0.0            0.0             0.0   \n",
      "3                     0.0                1.0            0.0             1.0   \n",
      "4                     0.0                1.0            0.0             0.0   \n",
      "...                   ...                ...            ...             ...   \n",
      "4648                  1.0                0.0            0.0             1.0   \n",
      "4649                  0.0                1.0            0.0             0.0   \n",
      "4650                  0.0                1.0            0.0             0.0   \n",
      "4651                  1.0                0.0            0.0             1.0   \n",
      "4652                  1.0                0.0            0.0             1.0   \n",
      "\n",
      "      City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
      "0                0.0        0.0            0.0          1.0             1.0   \n",
      "1                0.0        1.0            1.0          0.0             1.0   \n",
      "2                1.0        0.0            1.0          0.0             1.0   \n",
      "3                0.0        0.0            0.0          1.0             1.0   \n",
      "4                0.0        1.0            0.0          1.0             0.0   \n",
      "...              ...        ...            ...          ...             ...   \n",
      "4648             0.0        0.0            1.0          0.0             1.0   \n",
      "4649             0.0        1.0            0.0          1.0             1.0   \n",
      "4650             1.0        0.0            0.0          1.0             1.0   \n",
      "4651             0.0        0.0            0.0          1.0             0.0   \n",
      "4652             0.0        0.0            0.0          1.0             0.0   \n",
      "\n",
      "      EverBenched_Yes  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 1.0  \n",
      "...               ...  \n",
      "4648              0.0  \n",
      "4649              0.0  \n",
      "4650              0.0  \n",
      "4651              1.0  \n",
      "4652              1.0  \n",
      "\n",
      "[4653 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature = encoding(data,'LeaveOrNot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c95bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_No</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "\n",
       "   Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
       "0                  1.0                0.0            0.0             1.0   \n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
       "0             0.0        0.0            0.0          1.0             1.0   \n",
       "1             0.0        1.0            1.0          0.0             1.0   \n",
       "2             1.0        0.0            1.0          0.0             1.0   \n",
       "3             0.0        0.0            0.0          1.0             1.0   \n",
       "4             0.0        1.0            0.0          1.0             0.0   \n",
       "\n",
       "   EverBenched_Yes  LeaveOrNot  \n",
       "0              0.0           0  \n",
       "1              0.0           1  \n",
       "2              0.0           0  \n",
       "3              0.0           1  \n",
       "4              1.0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pandas = pd.concat([df_feature, df_target], axis=1)\n",
    "features_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae71aceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOININGYEAR</th>\n",
       "      <th>PAYMENTTIER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCEINCURRENTDOMAIN</th>\n",
       "      <th>EDUCATION_BACHELORS</th>\n",
       "      <th>EDUCATION_MASTERS</th>\n",
       "      <th>EDUCATION_PHD</th>\n",
       "      <th>CITY_BANGALORE</th>\n",
       "      <th>CITY_NEW_DELHI</th>\n",
       "      <th>CITY_PUNE</th>\n",
       "      <th>GENDER_FEMALE</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>EVERBENCHED_NO</th>\n",
       "      <th>EVERBENCHED_YES</th>\n",
       "      <th>LEAVEORNOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JOININGYEAR  PAYMENTTIER  AGE  EXPERIENCEINCURRENTDOMAIN  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "\n",
       "   EDUCATION_BACHELORS  EDUCATION_MASTERS  EDUCATION_PHD  CITY_BANGALORE  \\\n",
       "0                  1.0                0.0            0.0             1.0   \n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   CITY_NEW_DELHI  CITY_PUNE  GENDER_FEMALE  GENDER_MALE  EVERBENCHED_NO  \\\n",
       "0             0.0        0.0            0.0          1.0             1.0   \n",
       "1             0.0        1.0            1.0          0.0             1.0   \n",
       "2             1.0        0.0            1.0          0.0             1.0   \n",
       "3             0.0        0.0            0.0          1.0             1.0   \n",
       "4             0.0        1.0            0.0          1.0             0.0   \n",
       "\n",
       "   EVERBENCHED_YES  LEAVEORNOT  \n",
       "0              0.0           0  \n",
       "1              0.0           1  \n",
       "2              0.0           0  \n",
       "3              0.0           1  \n",
       "4              1.0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_pandas=features_pandas.drop(\"Unnamed: 0\", axis=1)\n",
    "features_pandas.columns = map(str.upper, features_pandas.columns)\n",
    "features_pandas.columns = features_pandas.columns.str.replace(' ', '_')\n",
    "features_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85205f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"JOININGYEAR\"  |\"PAYMENTTIER\"  |\"AGE\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"EDUCATION_BACHELORS\"  |\"EDUCATION_MASTERS\"  |\"EDUCATION_PHD\"  |\"CITY_BANGALORE\"  |\"CITY_NEW_DELHI\"  |\"CITY_PUNE\"  |\"GENDER_FEMALE\"  |\"GENDER_MALE\"  |\"EVERBENCHED_NO\"  |\"EVERBENCHED_YES\"  |\"LEAVEORNOT\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2017           |3              |34     |0                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2013           |1              |28     |3                            |1.0                    |0.0                  |0.0              |0.0               |0.0               |1.0          |1.0              |0.0            |1.0               |0.0                |1             |\n",
      "|2014           |3              |38     |2                            |1.0                    |0.0                  |0.0              |0.0               |1.0               |0.0          |1.0              |0.0            |1.0               |0.0                |0             |\n",
      "|2016           |3              |27     |5                            |0.0                    |1.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |1             |\n",
      "|2017           |3              |24     |2                            |0.0                    |1.0                  |0.0              |0.0               |0.0               |1.0          |0.0              |1.0            |0.0               |1.0                |1             |\n",
      "|2016           |3              |22     |0                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2015           |3              |38     |0                            |1.0                    |0.0                  |0.0              |0.0               |1.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2016           |3              |34     |2                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |1.0              |0.0            |1.0               |0.0                |1             |\n",
      "|2016           |3              |23     |1                            |1.0                    |0.0                  |0.0              |0.0               |0.0               |1.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2017           |2              |37     |2                            |0.0                    |1.0                  |0.0              |0.0               |1.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = session.create_dataframe(features_pandas)\n",
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0deaefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS=list(features_df.columns)\n",
    "FEATURE_COLUMNS.remove('LEAVEORNOT')\n",
    "# print(FEATURE_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f58a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize all the features for modeling\n",
    "# CATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\n",
    "\n",
    "# CATEGORICAL_COLUMNS_OE = [\"FIXED_ACIDITY\",\"VOLATILE_ACIDITY\",\"CITRIC_ACID\",\"RESIDUAL_SUGAR\",\"CHLORIDES\",\"FREE_SULFUR_DIOXIDE\",\"TOTAL_SULFUR_DIOXIDE\",\"DENSITY\",\"PH\",\"SULPHATES\",\"ALCOHOL\"] # To name the ordinal encoded columns\n",
    "# NUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"TABLE_PCT\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "LABEL_COLUMNS = [\"LEAVEORNOT\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]\n",
    "\n",
    "# input_cols=FEATURE_COLUMNS\n",
    "# label_cols=LABEL_COLUMNS\n",
    "# output_cols=OUTPUT_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89eae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    input_cols=FEATURE_COLUMNS,\n",
    "    label_cols=LABEL_COLUMNS,\n",
    "    output_cols=OUTPUT_COLUMNS\n",
    ")\n",
    "model.fit(features_df)\n",
    "\n",
    "# Use the model to make predictions.\n",
    "predictions = model.predict(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ccdb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "|\"PREDICTION\"  |\n",
      "----------------\n",
      "|0             |\n",
      "|1             |\n",
      "|0             |\n",
      "|1             |\n",
      "|1             |\n",
      "|0             |\n",
      "|0             |\n",
      "|0             |\n",
      "|0             |\n",
      "|0             |\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions[OUTPUT_COLUMNS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f11cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
