{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606818fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake-snowpark-python snowflake-ml-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79433dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling scikit-learn-1.4.1.post1:\n",
      "  Successfully uninstalled scikit-learn-1.4.1.post1\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/57/aa/483fbe6b5314bce2d49801e6cec1f2139a9c220d0d51494788fff47233b3/scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Collecting numpy>=1.14.6\n",
      "  Using cached https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting joblib>=0.11\n",
      "  Using cached https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl\n",
      "Collecting scipy>=1.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlflow 2.6.0 has requirement pytz<2024, but you'll have pytz 2024.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.5.1 has requirement scikit-learn<1.4,>=1.2.1, but you'll have scikit-learn 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.5.1 has requirement xgboost<2,>=1.7.3, but you'll have xgboost 2.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement itsdangerous==2.0.1, but you'll have itsdangerous 2.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Jinja2==3.0.3, but you'll have jinja2 3.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement matplotlib==3.6.0; python_version >= \"3.8\", but you'll have matplotlib 3.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.4.2 numpy-1.26.4 scikit-learn-1.0.2 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall scikit-learn -y \n",
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838fd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a45ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": \"Enlightme#2024\",\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "    \"database\": \"SFSALESSHARED_SFC_SAMPLES_GCPUSEAST4_SAMPLE_DATA\",  # optional\n",
    "    \"schema\": \"INFORMATION_SCHEMA\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab95951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Create a session with your preferred method\n",
    "# session =\n",
    "\n",
    "NUMERICAL_COLS = [\"X1\", \"X2\", \"X3\"]\n",
    "CATEGORICAL_COLS = [\"C1\", \"C2\", \"C3\"]\n",
    "FEATURE_COLS = NUMERICAL_COLS + CATEGORICAL_COLS\n",
    "CATEGORICAL_OUTPUT_COLS = [\"C1_OUT\", \"C2_OUT\", \"C3_OUT\"]\n",
    "FEATURE_OUTPUT_COLS = [\"X1_FEAT_OUT\", \"X2_FEAT_OUT\", \"X3_FEAT_OUT\", \"C1_FEAT_OUT\", \"C2_FEAT_OUT\", \"C3_FEAT_OUT\"]\n",
    "\n",
    "# Create a dataset with numerical and categorical features\n",
    "X, _ = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=3,\n",
    "    noise=0.1,\n",
    "    random_state=0,\n",
    ")\n",
    "X = pd.DataFrame(X, columns=NUMERICAL_COLS)\n",
    "\n",
    "def generate_random_string(length):\n",
    "    return \"\".join(random.choices(string.ascii_uppercase, k=length))\n",
    "\n",
    "categorical_feature_length = 2\n",
    "categorical_features = {}\n",
    "for c in CATEGORICAL_COLS:\n",
    "    categorical_column = [generate_random_string(categorical_feature_length) for _ in range(X.shape[0])]\n",
    "    categorical_features[c] = categorical_column\n",
    "\n",
    "X = X.assign(**categorical_features)\n",
    "\n",
    "features_df = session.create_dataframe(X)\n",
    "\n",
    "# Fit a pipeline with OrdinalEncoder and MinMaxScaler on Snowflake\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"OE\",\n",
    "            OrdinalEncoder(\n",
    "                input_cols=CATEGORICAL_COLS,\n",
    "                output_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"MMS\",\n",
    "            MinMaxScaler(\n",
    "                input_cols=NUMERICAL_COLS + CATEGORICAL_OUTPUT_COLS,\n",
    "                output_cols=FEATURE_OUTPUT_COLS,\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(features_df)\n",
    "\n",
    "# Use the pipeline to transform a dataset.\n",
    "result = pipeline.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e14469",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'available_if' from 'sklearn.utils.metaestimators' (/packages/Python-3.9/e27fb36a-d855-4aa4-b253-d16eac3af4e8/3.9/sklearn/utils/metaestimators.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_classification\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowflakeLoginOptions\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Session\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/ml/modeling/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m pkg_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\n\u001b[1;32m      5\u001b[0m pkg_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m----> 6\u001b[0m exportable_classes \u001b[38;5;241m=\u001b[39m \u001b[43minit_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_classes_from_modules_in_pkg_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpkg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpkg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m exportable_classes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[k] \u001b[38;5;241m=\u001b[39m v\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/ml/_internal/init_utils.py:26\u001b[0m, in \u001b[0;36mfetch_classes_from_modules_in_pkg_dir\u001b[0;34m(pkg_dir, pkg_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# import the module and iterate through its attributes\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpkg_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attribute_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(module):\n\u001b[1;32m     28\u001b[0m         attribute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, attribute_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/snowflake/ml/modeling/xgboost/xgb_classifier.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m available_if\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTransformer, _process_cols\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m telemetry\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'available_if' from 'sklearn.utils.metaestimators' (/packages/Python-3.9/e27fb36a-d855-4aa4-b253-d16eac3af4e8/3.9/sklearn/utils/metaestimators.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Create a session with your preferred method\n",
    "# session =\n",
    "\n",
    "FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "LABEL_COLS = [\"Y\"]\n",
    "OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# Set up data.\n",
    "X, y = make_classification(\n",
    "    n_samples=40000,\n",
    "    n_features=6,\n",
    "    n_informative=4,\n",
    "    n_redundant=1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "y = pd.DataFrame(y, columns=LABEL_COLS)\n",
    "\n",
    "features_pandas = pd.concat([X, y], axis=1)\n",
    "features_df = session.create_dataframe(features_pandas)\n",
    "\n",
    "# Train an XGBoost model on snowflake.\n",
    "xgboost_model = XGBClassifier(\n",
    "    input_cols=FEATURE_COLS,\n",
    "    label_cols=LABEL_COLS,\n",
    "    output_cols=OUTPUT_COLS\n",
    ")\n",
    "\n",
    "xgboost_model.fit(features_df)\n",
    "\n",
    "# Use the model to make predictions.\n",
    "predictions = xgboost_model.predict(features_df)\n",
    "predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4334fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudpickle                2.2.1      \n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -i cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06f845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
