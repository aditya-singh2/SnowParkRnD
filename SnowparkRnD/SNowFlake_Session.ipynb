{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606818fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting snowflake-snowpark-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/68/b3496e1d59e8c8b302df7fa5c4ce851a687b8b8ddb92d6f6254bfce77009/snowflake_snowpark_python-1.17.0-py3-none-any.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-ml-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/59/baf64a782ef609514f6d1ad11735504267d04794097d8a29809c4b4b2a38/snowflake_ml_python-1.5.1-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 53.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/6b/6600ac24725c7388255b2f5add93f91e58a5d7efaf4af244fdbcc11a541b/PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736kB)\n",
      "\u001b[K     |████████████████████████████████| 737kB 46.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-connector-python<4.0.0,>=3.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/a8/02ea1064d444d63cc8e97d8a7f4aa7606278ebe886513ea07b9d296caf8b/snowflake_connector_python-3.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 51.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions<5.0.0,>=4.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl\n",
      "Collecting cloudpickle!=2.1.0,!=2.2.0,<=2.2.1,>=1.6.0; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "Collecting setuptools>=40.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/88/70c5767a0e43eb4451c2200f07d042a4bcd7639276003a9c54a68cfcc1f8/setuptools-70.0.0-py3-none-any.whl (863kB)\n",
      "\u001b[K     |██████████████████████████████  | 808kB 51.1MB/s eta 0:00:01^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-snowpark-python snowflake-ml-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79433dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Uninstalling cloudpickle-2.2.1:\n",
      "  Successfully uninstalled cloudpickle-2.2.1\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting cloudpickle==2.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "\u001b[31mERROR: mlflow 2.10.0 has requirement pytz<2024, but you'll have pytz 2024.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.5.1 has requirement xgboost<2,>=1.7.3, but you'll have xgboost 2.0.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cloudpickle\n",
      "Successfully installed cloudpickle-2.2.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall cloudpickle -y \n",
    "!pip install cloudpickle==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838fd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, DoubleType, StringType\n",
    "import snowflake.snowpark.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a45ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": \"Enlightme#2024\",\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "#     \"authenticator\": \"externalbrowser\", # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96877200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : ADITYASINGH\n",
      "Role                        : \"ADITYASINGH\"\n",
      "Database                    : \"FIRST_DB\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"FOSFOR_INSIGHT_WH\"\n",
      "Snowflake version           : 8.20.0\n",
      "Snowpark for Python version : 1.17.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Edit the connection.json before creating the session object below\n",
    "# Create Snowflake Session object\n",
    "# connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c644b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Create a session with your preferred method\n",
    "# session =\n",
    "\n",
    "NUMERICAL_COLS = [\"X1\", \"X2\", \"X3\"]\n",
    "CATEGORICAL_COLS = [\"C1\", \"C2\", \"C3\"]\n",
    "FEATURE_COLS = NUMERICAL_COLS + CATEGORICAL_COLS\n",
    "CATEGORICAL_OUTPUT_COLS = [\"C1_OUT\", \"C2_OUT\", \"C3_OUT\"]\n",
    "FEATURE_OUTPUT_COLS = [\"X1_FEAT_OUT\", \"X2_FEAT_OUT\", \"X3_FEAT_OUT\", \"C1_FEAT_OUT\", \"C2_FEAT_OUT\", \"C3_FEAT_OUT\"]\n",
    "\n",
    "# Create a dataset with numerical and categorical features\n",
    "X, _ = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=3,\n",
    "    noise=0.1,\n",
    "    random_state=0,\n",
    ")\n",
    "X = pd.DataFrame(X, columns=NUMERICAL_COLS)\n",
    "\n",
    "def generate_random_string(length):\n",
    "    return \"\".join(random.choices(string.ascii_uppercase, k=length))\n",
    "\n",
    "categorical_feature_length = 2\n",
    "categorical_features = {}\n",
    "for c in CATEGORICAL_COLS:\n",
    "    categorical_column = [generate_random_string(categorical_feature_length) for _ in range(X.shape[0])]\n",
    "    categorical_features[c] = categorical_column\n",
    "\n",
    "X = X.assign(**categorical_features)\n",
    "\n",
    "features_df = session.create_dataframe(X)\n",
    "\n",
    "# Fit a pipeline with OrdinalEncoder and MinMaxScaler on Snowflake\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"OE\",\n",
    "            OrdinalEncoder(\n",
    "                input_cols=CATEGORICAL_COLS,\n",
    "                output_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"MMS\",\n",
    "            MinMaxScaler(\n",
    "                input_cols=NUMERICAL_COLS + CATEGORICAL_OUTPUT_COLS,\n",
    "                output_cols=FEATURE_OUTPUT_COLS,\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(features_df)\n",
    "\n",
    "# Use the pipeline to transform a dataset.\n",
    "result = pipeline.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c48058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.dataframe.DataFrame at 0x7ad30f4d2d60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e14469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'numpy' in the local environment is 1.24.4, which does not fit the criteria for the requirement 'numpy==1.24.3'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Create a session with your preferred method\n",
    "# session =\n",
    "\n",
    "FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "LABEL_COLS = [\"Y\"]\n",
    "OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# Set up data.\n",
    "X, y = make_classification(\n",
    "    n_samples=40000,\n",
    "    n_features=6,\n",
    "    n_informative=4,\n",
    "    n_redundant=1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "y = pd.DataFrame(y, columns=LABEL_COLS)\n",
    "\n",
    "features_pandas = pd.concat([X, y], axis=1)\n",
    "features_df = session.create_dataframe(features_pandas)\n",
    "\n",
    "# Train an XGBoost model on snowflake.\n",
    "xgboost_model = XGBClassifier(\n",
    "    input_cols=FEATURE_COLS,\n",
    "    label_cols=LABEL_COLS,\n",
    "    output_cols=OUTPUT_COLS\n",
    ")\n",
    "\n",
    "xgboost_model.fit(features_df)\n",
    "\n",
    "# Use the model to make predictions.\n",
    "predictions = xgboost_model.predict(features_df)\n",
    "predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4334fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudpickle                3.0.0      \n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -i cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06f845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
