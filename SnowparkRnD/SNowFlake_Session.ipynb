{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606818fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake-snowpark-python snowflake-ml-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79433dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling scikit-learn-1.4.1.post1:\n",
      "  Successfully uninstalled scikit-learn-1.4.1.post1\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/57/aa/483fbe6b5314bce2d49801e6cec1f2139a9c220d0d51494788fff47233b3/scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Collecting numpy>=1.14.6\n",
      "  Using cached https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting joblib>=0.11\n",
      "  Using cached https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl\n",
      "Collecting scipy>=1.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mlflow 2.6.0 has requirement pytz<2024, but you'll have pytz 2024.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.5.1 has requirement scikit-learn<1.4,>=1.2.1, but you'll have scikit-learn 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.5.1 has requirement xgboost<2,>=1.7.3, but you'll have xgboost 2.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement itsdangerous==2.0.1, but you'll have itsdangerous 2.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Jinja2==3.0.3, but you'll have jinja2 3.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement matplotlib==3.6.0; python_version >= \"3.8\", but you'll have matplotlib 3.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.4.2 numpy-1.26.4 scikit-learn-1.0.2 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall scikit-learn -y \n",
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838fd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a45ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": \"Enlightme#2024\",\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Edit the connection.json before creating the session object below\n",
    "# Create Snowflake Session object\n",
    "# connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab95951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c644b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create_temp_table is deprecated. We still respect this parameter when it is True but please consider using `table_type=\"temporary\"` instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'snowflake.snowpark.session' has no attribute '_get_active_sessions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Fit a pipeline with OrdinalEncoder and MinMaxScaler on Snowflake\u001b[39;00m\n\u001b[1;32m     43\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     44\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     45\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[1;32m     60\u001b[0m )\n\u001b[0;32m---> 62\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Use the pipeline to transform a dataset.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m result \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(features_df)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/ml/_internal/telemetry.py:263\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# get an active session\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m         active_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_active_sessions\u001b[49m()))\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# server no default session\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mSnowparkSessionException:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'snowflake.snowpark.session' has no attribute '_get_active_sessions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Create a session with your preferred method\n",
    "# session =\n",
    "\n",
    "NUMERICAL_COLS = [\"X1\", \"X2\", \"X3\"]\n",
    "CATEGORICAL_COLS = [\"C1\", \"C2\", \"C3\"]\n",
    "FEATURE_COLS = NUMERICAL_COLS + CATEGORICAL_COLS\n",
    "CATEGORICAL_OUTPUT_COLS = [\"C1_OUT\", \"C2_OUT\", \"C3_OUT\"]\n",
    "FEATURE_OUTPUT_COLS = [\"X1_FEAT_OUT\", \"X2_FEAT_OUT\", \"X3_FEAT_OUT\", \"C1_FEAT_OUT\", \"C2_FEAT_OUT\", \"C3_FEAT_OUT\"]\n",
    "\n",
    "# Create a dataset with numerical and categorical features\n",
    "X, _ = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=3,\n",
    "    noise=0.1,\n",
    "    random_state=0,\n",
    ")\n",
    "X = pd.DataFrame(X, columns=NUMERICAL_COLS)\n",
    "\n",
    "def generate_random_string(length):\n",
    "    return \"\".join(random.choices(string.ascii_uppercase, k=length))\n",
    "\n",
    "categorical_feature_length = 2\n",
    "categorical_features = {}\n",
    "for c in CATEGORICAL_COLS:\n",
    "    categorical_column = [generate_random_string(categorical_feature_length) for _ in range(X.shape[0])]\n",
    "    categorical_features[c] = categorical_column\n",
    "\n",
    "X = X.assign(**categorical_features)\n",
    "\n",
    "features_df = session.create_dataframe(X)\n",
    "\n",
    "# Fit a pipeline with OrdinalEncoder and MinMaxScaler on Snowflake\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"OE\",\n",
    "            OrdinalEncoder(\n",
    "                input_cols=CATEGORICAL_COLS,\n",
    "                output_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            \"MMS\",\n",
    "            MinMaxScaler(\n",
    "                input_cols=NUMERICAL_COLS + CATEGORICAL_OUTPUT_COLS,\n",
    "                output_cols=FEATURE_OUTPUT_COLS,\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(features_df)\n",
    "\n",
    "# Use the pipeline to transform a dataset.\n",
    "result = pipeline.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e14469",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "003540 (42501): SQL execution error: Creating stage on shared database 'SFSALESSHARED_SFC_SAMPLES_GCPUSEAST4_SAMPLE_DATA' is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/pandas_tools.py:103\u001b[0m, in \u001b[0;36m_create_temp_stage\u001b[0;34m(cursor, database, schema, quote_identifiers, compression, auto_create_table, overwrite)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[43m_do_create_temp_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_create_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# User may not have the privilege to create stage on the target schema, so fall back to use current schema as\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# the old behavior.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/pandas_tools.py:83\u001b[0m, in \u001b[0;36m_do_create_temp_stage\u001b[0;34m(cursor, stage_location, compression, auto_create_table, overwrite)\u001b[0m\n\u001b[1;32m     82\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating stage with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_stage_sql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_stage_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_is_internal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/cursor.py:1132\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1132\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    344\u001b[0m cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 003540 (42501): SQL execution error: Creating stage on shared database 'SFSALESSHARED_SFC_SAMPLES_GCPUSEAST4_SAMPLE_DATA' is not allowed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y, columns\u001b[38;5;241m=\u001b[39mLABEL_COLS)\n\u001b[1;32m     28\u001b[0m features_pandas \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X, y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m features_df \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_pandas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Train an XGBoost model on snowflake.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m xgboost_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     33\u001b[0m     input_cols\u001b[38;5;241m=\u001b[39mFEATURE_COLS,\n\u001b[1;32m     34\u001b[0m     label_cols\u001b[38;5;241m=\u001b[39mLABEL_COLS,\n\u001b[1;32m     35\u001b[0m     output_cols\u001b[38;5;241m=\u001b[39mOUTPUT_COLS\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/snowpark/session.py:1382\u001b[0m, in \u001b[0;36mSession.create_dataframe\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m   1379\u001b[0m sf_database \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39m_get_current_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1380\u001b[0m sf_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39m_get_current_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1382\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf_database\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msf_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquote_identifiers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_create_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_temp_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m set_api_call_source(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession.create_dataframe[pandas]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/snowpark/session.py:1296\u001b[0m, in \u001b[0;36mSession.write_pandas\u001b[0;34m(self, df, table_name, database, schema, chunk_size, compression, on_error, parallel, quote_identifiers, auto_create_table, create_temp_table, overwrite, table_type)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mDF_PANDAS_TABLE_DOES_NOT_EXIST_EXCEPTION(\n\u001b[1;32m   1293\u001b[0m             location\n\u001b[1;32m   1294\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpe\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pe\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1299\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable(location)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/snowpark/session.py:1275\u001b[0m, in \u001b[0;36mSession.write_pandas\u001b[0;34m(self, df, table_name, database, schema, chunk_size, compression, on_error, parallel, quote_identifiers, auto_create_table, create_temp_table, overwrite, table_type)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m         location \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1271\u001b[0m             (database \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m database \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1272\u001b[0m             \u001b[38;5;241m+\u001b[39m (schema \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1273\u001b[0m             \u001b[38;5;241m+\u001b[39m (table_name)\n\u001b[1;32m   1274\u001b[0m         )\n\u001b[0;32m-> 1275\u001b[0m     success, nchunks, nrows, ci_output \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquote_identifiers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote_identifiers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_create_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_create_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m pe:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pe\u001b[38;5;241m.\u001b[39mmsg\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/pandas_tools.py:319\u001b[0m, in \u001b[0;36mwrite_pandas\u001b[0;34m(conn, df, table_name, database, schema, chunk_size, compression, on_error, parallel, quote_identifiers, auto_create_table, create_temp_table, overwrite, table_type, use_logical_type, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     sql_use_logical_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m USE_LOGICAL_TYPE = FALSE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    318\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m--> 319\u001b[0m stage_location \u001b[38;5;241m=\u001b[39m \u001b[43m_create_temp_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquote_identifiers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_create_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmp_folder:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m chunk_helper(df, chunk_size):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/pandas_tools.py:113\u001b[0m, in \u001b[0;36m_create_temp_stage\u001b[0;34m(cursor, database, schema, quote_identifiers, compression, auto_create_table, overwrite)\u001b[0m\n\u001b[1;32m    109\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating stage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed. Exception \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Fall back to use current schema\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m     stage_location \u001b[38;5;241m=\u001b[39m stage_name\n\u001b[0;32m--> 113\u001b[0m     \u001b[43m_do_create_temp_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_create_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stage_location\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/pandas_tools.py:83\u001b[0m, in \u001b[0;36m_do_create_temp_stage\u001b[0;34m(cursor, stage_location, compression, auto_create_table, overwrite)\u001b[0m\n\u001b[1;32m     81\u001b[0m create_stage_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TEMP STAGE /* Python:snowflake.connector.pandas_tools.write_pandas() */ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FILE_FORMAT=(TYPE=PARQUET COMPRESSION=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompression\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m BINARY_AS_TEXT=FALSE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mauto_create_table\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39moverwrite\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating stage with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_stage_sql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_stage_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_is_internal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/cursor.py:1132\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1129\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1130\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1132\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    298\u001b[0m             error_class,\n\u001b[1;32m    299\u001b[0m             error_value,\n\u001b[1;32m    300\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    219\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 003540 (42501): SQL execution error: Creating stage on shared database 'SFSALESSHARED_SFC_SAMPLES_GCPUSEAST4_SAMPLE_DATA' is not allowed."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Create a session with your preferred method\n",
    "# session =\n",
    "\n",
    "FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "LABEL_COLS = [\"Y\"]\n",
    "OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# Set up data.\n",
    "X, y = make_classification(\n",
    "    n_samples=40000,\n",
    "    n_features=6,\n",
    "    n_informative=4,\n",
    "    n_redundant=1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "y = pd.DataFrame(y, columns=LABEL_COLS)\n",
    "\n",
    "features_pandas = pd.concat([X, y], axis=1)\n",
    "features_df = session.create_dataframe(features_pandas)\n",
    "\n",
    "# Train an XGBoost model on snowflake.\n",
    "xgboost_model = XGBClassifier(\n",
    "    input_cols=FEATURE_COLS,\n",
    "    label_cols=LABEL_COLS,\n",
    "    output_cols=OUTPUT_COLS\n",
    ")\n",
    "\n",
    "xgboost_model.fit(features_df)\n",
    "\n",
    "# Use the model to make predictions.\n",
    "predictions = xgboost_model.predict(features_df)\n",
    "predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853c218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4334fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudpickle                2.2.1      \n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -i cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06f845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
