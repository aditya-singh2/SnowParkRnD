{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(sf_pass, algos, dataset, target):    \n",
    "    import os, importlib\n",
    "    from snowflake.snowpark import Session\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType\n",
    "    from snowflake.ml.modeling.compose import ColumnTransformer\n",
    "    from snowflake.snowpark import Session, FileOperation\n",
    "\n",
    "    connection_parameters = {\n",
    "        \"account\": \"ug94937.us-east4.gcp\",\n",
    "        \"user\": \"ADITYASINGH\",\n",
    "        \"password\": sf_pass,\n",
    "        \"role\": \"ADITYASINGH\",  # optional\n",
    "        \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "        \"database\": \"FIRST_DB\",  # optional\n",
    "        \"schema\": \"PUBLIC\",  # optional\n",
    "    } \n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "    \n",
    "    # Read dataset\n",
    "    df_train, df_test = session.table(dataset).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    print(df_train.show())\n",
    "    features = df_train.columns\n",
    "    features.remove(target)\n",
    "    \n",
    "    # generating feature names\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {dataset}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=target:\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    categorical_features_oe = list(map(lambda a: a+'_OE', categorical_features))\n",
    "    print(\"numerical_features: \", numerical_features)\n",
    "    print(\"categorical_features_oe: \", categorical_features_oe)\n",
    "    \n",
    "#     #Numerical pipeline\n",
    "#     numeric_transform = Pipeline(steps=[\n",
    "#         (\"scaler\", MinMaxScaler(output_cols=numerical_features))\n",
    "#     ]\n",
    "#     )\n",
    "    \n",
    "#     #Categorical pipeline\n",
    "#     categoric_transform = Pipeline(steps=[\n",
    "#         (\"ord\", OrdinalEncoder(output_cols=categorical_features_oe))\n",
    "#     ]\n",
    "#     )\n",
    "    \n",
    "#     #preprocessor\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         output_cols=categorical_features_oe+numerical_features+[target],\n",
    "#         transformers=[\n",
    "#             ('num', numeric_transform, numerical_features),\n",
    "#             ('cat', categoric_transform, categorical_features)\n",
    "#         ],\n",
    "#         remainder='passthrough'\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    #pipeline steps \n",
    "    categorical_pp = {\n",
    "        'ord': OrdinalEncoder(input_cols=categorical_features, output_cols=categorical_features_oe) \n",
    "    }\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_features!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "\n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically generate list of selected algorithms for imports\n",
    "    df_all_pred = None\n",
    "    for algorithm in algos:\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        print(algorithm[1])\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        \n",
    "        pipe = Pipeline(steps=steps+[(\"algorithm\", attr(input_cols=categorical_features_oe+numerical_features\n",
    "                                              , label_cols=[target]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        xgb_model = pipe.fit(df_train)\n",
    "         \n",
    "        # Test the model\n",
    "        df_test_pred = xgb_model.predict(df_test)\n",
    "        \n",
    "        #combining predictions\n",
    "        if df_all_pred is None:\n",
    "            df_all_pred = df_test_pred.select(df_test_pred[f'PREDICTIONS_{algorithm[1]}'.upper()])\n",
    "        else:\n",
    "            df_all_pred = df_all_pred.join(df_test_pred.select(df_test_pred[f'PREDICTIONS_{algorithm[1]}'.upper()]))\n",
    "            \n",
    "        # metrices\n",
    "        mse = mean_squared_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        mae = mean_absolute_error(df=df_test_pred, y_true_col_names=target, y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        r2 = r2_score(df=df_test_pred, y_true_col_name=target, y_pred_col_name=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        print(f'{algorithm[1]} MSE: {mse}')\n",
    "        print(f'{algorithm[1]} MAE: {mae}')\n",
    "        print(f'{algorithm[1]} R2: {r2}')\n",
    "        \n",
    "    return df_all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6889c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.registry.registry import Registry\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"\",\n",
    "    \"password\": \"\",\n",
    "    \"role\": \"VAIBHAV\",\n",
    "    \"database\": \"FDC_DEV_VAIBHAV\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "\n",
    "# Stored Procedure\n",
    "def train_ml_models(session: Session) -> list:\n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "    # from snowflake.snowpark import Session, FileOperation\n",
    "    # 2] Model Recipe Execution\n",
    "    # Random split\n",
    "    df_train, df_test = session.table(\"diamonds\").drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    cat_cols = [\"CUT\", \"COLOR\", \"CLARITY\"]\n",
    "    cat_cols_oe = [\"CUT_OE\", \"COLOR_OE\", \"CLARITY_OE\"]\n",
    "    num_cols = [\"CARAT\", \"DEPTH\", \"TABLE_PCT\", \"X\", \"Y\", \"Z\"]\n",
    "    # Define a pipeline that does the preprocessing and training of\n",
    "    # a XGBRegressor model\n",
    "    pipe = Pipeline(steps=[(\"ord\", OrdinalEncoder(input_cols=cat_cols, output_cols=cat_cols_oe)),\n",
    "                           (\"scaler\", MinMaxScaler(input_cols=num_cols, output_cols=num_cols)),\n",
    "                           (\"regressor\", XGBRegressor(input_cols=cat_cols_oe + num_cols, label_cols=[\"PRICE\"],\n",
    "                                                      output_cols=['PREDICTION'], n_jobs=-1))\n",
    "                           ])\n",
    "    # Fit the pipeline\n",
    "    xgb_model = pipe.fit(df_train)\n",
    "    # Test the model\n",
    "    df_test_pred = xgb_model.predict(df_test)\n",
    "    mse = mean_squared_error(df=df_test_pred, y_true_col_names=\"PRICE\", y_pred_col_names=\"PREDICTION\")\n",
    "    mae = mean_absolute_error(df=df_test_pred, y_true_col_names=\"PRICE\", y_pred_col_names=\"PREDICTION\")\n",
    "    r2 = r2_score(df=df_test_pred, y_true_col_name=\"PRICE\", y_pred_col_name=\"PREDICTION\")\n",
    "    print(\"Execution Completed\")\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'R2: {r2}')\n",
    "\n",
    "    # LOG MODEL INTO SNOWFLAKE REGISTRY\n",
    "    from snowflake.ml.registry.registry import Registry\n",
    "    reg = Registry(session=session)\n",
    "    # Log the model\n",
    "    model_name = \"diamonds_model_v30\"\n",
    "    try:\n",
    "        mv = reg.log_model(model=xgb_model,\n",
    "                           model_name=model_name,\n",
    "                           comment=\"test\",\n",
    "                           version_name=\"run1\",\n",
    "                           python_version=\"3.9.19\",\n",
    "                           conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "                           metrics={\"model_metrics\": {\"score\": 96}, \"project_id\": \"0001\", \"type\": \"EXP\"})\n",
    "    except Exception as ex:\n",
    "        pass\n",
    "    return [{\"EXP_NAME\":\"\"+model_name,\n",
    "             \"Version\":\"Run1\",\n",
    "             \"matrices\":{\"model_metrics\": {\"MSE\": mse, \"MAE\": mae, \"r2\": r2}, \"project_id\": \"0001\", \"type\": \"EXP\"},\n",
    "             \"Alogirthm_Type\":\"Regression\",\n",
    "             \"Alogithm\": \"XGBRegressor\",\n",
    "             \"RUN_STATUS\":\"SUCESS\",\n",
    "             \"registry_exp_name\":\"\"}]\n",
    "\n",
    "\n",
    "# Initilization\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=train_ml_models,\n",
    "                       name=\"train_ml_models\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "print(\"Executing Stored Procedure\")\n",
    "procedure_response = session.call(\"train_ml_models\")\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = run_exp(os.environ.get('SF_Password'),\n",
    "               ['snowflake.ml.modeling.linear_model.SGDRegressor',\n",
    "                'snowflake.ml.modeling.svm.LinearSVR',\n",
    "               ],\n",
    "               'ALCOHOL_QUALITY', \n",
    "               'QUALITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c7d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
