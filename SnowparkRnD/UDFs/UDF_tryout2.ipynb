{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Python file for udf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b5ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(sf_pass, dataset, target):\n",
    "    import os\n",
    "    from snowflake.snowpark import Session\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from snowflake.ml.modeling.tree import DecisionTreeClassifier\n",
    "    \n",
    "    connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": sf_pass\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "    }\n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "    \n",
    "    data = session.table(dataset)\n",
    "    data = data.to_pandas()\n",
    "    \n",
    "    # Data Preprocessing: Validating and encoding the data if required and imputing null values.\n",
    "    data = data.fillna(method='pad')  # Filling null values with the previous ones\n",
    "    data = data.fillna(method='bfill')  # Filling null value with the next ones\n",
    "    \n",
    "    def encoding(df, target_column):\n",
    "        \"\"\"\n",
    "        Checking whether encoding required in target and feature datasets.\n",
    "        If required, then encoding them with label and one hot encoding.\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        target_column: target column\n",
    "        :returns:\n",
    "        df_target: target dataframe\n",
    "        le_target: target label encoder object\n",
    "        df_feature: feature dataframe\n",
    "        le_dict_feature: dict of feature label encoder objects\n",
    "        oh_enc_feature: feature one hot encoder object\n",
    "        le_column_feature: list of feature label encoder columns\n",
    "        oh_column_feature: list of feature one hot encoder columns\n",
    "        \"\"\"\n",
    "        df_target = df[[target_column]]\n",
    "        le_target = None\n",
    "        # Target column validation and encoding\n",
    "        if df.dtypes[target_column].name in ['object', 'bool']:\n",
    "            print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "            le_target = LabelEncoder()\n",
    "            df_target[target_column] = pd.DataFrame(le_target.fit_transform(df_target[target_column].astype(str)))\n",
    "            print(f\"Target column label encoded {df_target[target_column]}, object: {le_target}\")\n",
    "\n",
    "        # Feature column validation and encoding\n",
    "        df_feature = df.drop(target_column, axis=1)\n",
    "        non_numeric_cols = df_feature.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "        le_dict_feature = {}\n",
    "        le_column_feature = []\n",
    "        oh_column_feature = []\n",
    "        oh_enc_feature = None\n",
    "        if len(non_numeric_cols) >= 1:\n",
    "            print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for col in non_numeric_cols:\n",
    "                if df_feature[col].nunique() >= 10:\n",
    "                    le_column_feature.append(col)\n",
    "                else:\n",
    "                    oh_column_feature.append(col)\n",
    "\n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "                  f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "\n",
    "            # columns to be label encoded\n",
    "            if len(le_column_feature) == 0:\n",
    "                df_feature = df_feature\n",
    "            else:\n",
    "                for col in le_column_feature:\n",
    "                    le_dict_feature[col] = LabelEncoder()\n",
    "                    df_feature[col] = le_dict_feature[col].fit_transform(df_feature[col].astype(str))\n",
    "                    print(f\"{col} column label encoded {df_feature[col]}, object: {le_dict_feature[col]}\")\n",
    "\n",
    "            # columns to be one hot encoded\n",
    "            if len(oh_column_feature) == 0:\n",
    "                df_feature = df_feature\n",
    "            else:\n",
    "                unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "                unique_combinations_list = unique_combinations.columns.tolist()\n",
    "                oh_enc_feature = OneHotEncoder()\n",
    "                oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "                df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "                df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "                df_feature = df_feature.join(df_oh_enc)\n",
    "                print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                      f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "            print(f\"final feature df created: {df_feature}\")\n",
    "        return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature\n",
    "    \n",
    "    df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature = encoding(data, target)\n",
    "    \n",
    "    features_pandas = pd.concat([df_feature, df_target], axis=1)\n",
    "    features_pandas.columns = map(str.upper, features_pandas.columns)\n",
    "    features_pandas.columns = features_pandas.columns.str.replace(' ', '_')\n",
    "    features_df = session.create_dataframe(features_pandas)\n",
    "    \n",
    "    FEATURE_COLUMNS=list(features_df.columns)\n",
    "    FEATURE_COLUMNS.remove('LEAVEORNOT')\n",
    "    LABEL_COLUMNS = [\"LEAVEORNOT\"]\n",
    "    OUTPUT_COLUMNS = [\"PREDICTION\"]\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        input_cols=FEATURE_COLUMNS,\n",
    "        label_cols=LABEL_COLUMNS,\n",
    "        output_cols=OUTPUT_COLUMNS\n",
    "    )\n",
    "    model.fit(features_df)\n",
    "\n",
    "    # Use the model to make predictions.\n",
    "    predictions = model.predict(features_df)\n",
    "    return predictions[OUTPUT_COLUMNS]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
