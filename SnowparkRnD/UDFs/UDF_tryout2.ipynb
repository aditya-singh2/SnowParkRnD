{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Python file for udf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a830f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(sf_pass, dataset, target):\n",
    "    import os\n",
    "    from snowflake.snowpark import Session\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from snowflake.ml.modeling.tree import DecisionTreeClassifier\n",
    "    \n",
    "    connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": sf_pass\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "    }\n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    session.sql_simplifier_enabled = True\n",
    "    \n",
    "    data = session.table(dataset)\n",
    "    data = data.to_pandas()\n",
    "    \n",
    "    # Data Preprocessing: Validating and encoding the data if required and imputing null values.\n",
    "    data = data.fillna(method='pad')  # Filling null values with the previous ones\n",
    "    data = data.fillna(method='bfill')  # Filling null value with the next ones\n",
    "    \n",
    "    def encoding(df, target_column):\n",
    "        \"\"\"\n",
    "        Checking whether encoding required in target and feature datasets.\n",
    "        If required, then encoding them with label and one hot encoding.\n",
    "        :param:\n",
    "        df: input dataframe\n",
    "        target_column: target column\n",
    "        :returns:\n",
    "        df_target: target dataframe\n",
    "        le_target: target label encoder object\n",
    "        df_feature: feature dataframe\n",
    "        le_dict_feature: dict of feature label encoder objects\n",
    "        oh_enc_feature: feature one hot encoder object\n",
    "        le_column_feature: list of feature label encoder columns\n",
    "        oh_column_feature: list of feature one hot encoder columns\n",
    "        \"\"\"\n",
    "        df_target = df[[target_column]]\n",
    "        le_target = None\n",
    "        # Target column validation and encoding\n",
    "        if df.dtypes[target_column].name in ['object', 'bool']:\n",
    "            print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "            le_target = LabelEncoder()\n",
    "            df_target[target_column] = pd.DataFrame(le_target.fit_transform(df_target[target_column].astype(str)))\n",
    "            print(f\"Target column label encoded {df_target[target_column]}, object: {le_target}\")\n",
    "\n",
    "        # Feature column validation and encoding\n",
    "        df_feature = df.drop(target_column, axis=1)\n",
    "        non_numeric_cols = df_feature.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "        le_dict_feature = {}\n",
    "        le_column_feature = []\n",
    "        oh_column_feature = []\n",
    "        oh_enc_feature = None\n",
    "        if len(non_numeric_cols) >= 1:\n",
    "            print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for col in non_numeric_cols:\n",
    "                if df_feature[col].nunique() >= 10:\n",
    "                    le_column_feature.append(col)\n",
    "                else:\n",
    "                    oh_column_feature.append(col)\n",
    "\n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "                  f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "\n",
    "            # columns to be label encoded\n",
    "            if len(le_column_feature) == 0:\n",
    "                df_feature = df_feature\n",
    "            else:\n",
    "                for col in le_column_feature:\n",
    "                    le_dict_feature[col] = LabelEncoder()\n",
    "                    df_feature[col] = le_dict_feature[col].fit_transform(df_feature[col].astype(str))\n",
    "                    print(f\"{col} column label encoded {df_feature[col]}, object: {le_dict_feature[col]}\")\n",
    "\n",
    "            # columns to be one hot encoded\n",
    "            if len(oh_column_feature) == 0:\n",
    "                df_feature = df_feature\n",
    "            else:\n",
    "                unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "                unique_combinations_list = unique_combinations.columns.tolist()\n",
    "                oh_enc_feature = OneHotEncoder()\n",
    "                oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "                df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "                df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "                df_feature = df_feature.join(df_oh_enc)\n",
    "                print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                      f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "            print(f\"final feature df created: {df_feature}\")\n",
    "        return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6496c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing: Validating and encoding the data if required and imputing null values.\n",
    "data = data.fillna(method='pad')  # Filling null values with the previous ones\n",
    "data = data.fillna(method='bfill')  # Filling null value with the next ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddedd64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df, target_column):\n",
    "    \"\"\"\n",
    "    Checking whether encoding required in target and feature datasets.\n",
    "    If required, then encoding them with label and one hot encoding.\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    target_column: target column\n",
    "    :returns:\n",
    "    df_target: target dataframe\n",
    "    le_target: target label encoder object\n",
    "    df_feature: feature dataframe\n",
    "    le_dict_feature: dict of feature label encoder objects\n",
    "    oh_enc_feature: feature one hot encoder object\n",
    "    le_column_feature: list of feature label encoder columns\n",
    "    oh_column_feature: list of feature one hot encoder columns\n",
    "    \"\"\"\n",
    "    df_target = df[[target_column]]\n",
    "    le_target = None\n",
    "    # Target column validation and encoding\n",
    "    if df.dtypes[target_column].name in ['object', 'bool']:\n",
    "        print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "        le_target = LabelEncoder()\n",
    "        df_target[target_column] = pd.DataFrame(le_target.fit_transform(df_target[target_column].astype(str)))\n",
    "        print(f\"Target column label encoded {df_target[target_column]}, object: {le_target}\")\n",
    "\n",
    "    # Feature column validation and encoding\n",
    "    df_feature = df.drop(target_column, axis=1)\n",
    "    non_numeric_cols = df_feature.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    le_dict_feature = {}\n",
    "    le_column_feature = []\n",
    "    oh_column_feature = []\n",
    "    oh_enc_feature = None\n",
    "    if len(non_numeric_cols) >= 1:\n",
    "        print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for col in non_numeric_cols:\n",
    "            if df_feature[col].nunique() >= 10:\n",
    "                le_column_feature.append(col)\n",
    "            else:\n",
    "                oh_column_feature.append(col)\n",
    "\n",
    "        print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "              f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "\n",
    "        # columns to be label encoded\n",
    "        if len(le_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            for col in le_column_feature:\n",
    "                le_dict_feature[col] = LabelEncoder()\n",
    "                df_feature[col] = le_dict_feature[col].fit_transform(df_feature[col].astype(str))\n",
    "                print(f\"{col} column label encoded {df_feature[col]}, object: {le_dict_feature[col]}\")\n",
    "\n",
    "        # columns to be one hot encoded\n",
    "        if len(oh_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "            unique_combinations_list = unique_combinations.columns.tolist()\n",
    "            oh_enc_feature = OneHotEncoder()\n",
    "            oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "            df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "            df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "            df_feature = df_feature.join(df_oh_enc)\n",
    "            print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                  f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "        print(f\"final feature df created: {df_feature}\")\n",
    "    return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a26534e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED'] columns are non numeric in feature dataset, encoding required.\n",
      "Columns identified to be encoded with label encoder: []\n",
      "Columns identified to be encoded with one hot encoder: ['EDUCATION', 'CITY', 'GENDER', 'EVERBENCHED']\n",
      "new one hot encoded df: [[1. 0. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]]\n",
      "one hot encoder object: OneHotEncoder()\n",
      "\n",
      "final feature df created:       JOININGYEAR  PAYMENTTIER  AGE  EXPERIENCEINCURRENTDOMAIN  \\\n",
      "0            2017            3   34                          0   \n",
      "1            2013            1   28                          3   \n",
      "2            2014            3   38                          2   \n",
      "3            2016            3   27                          5   \n",
      "4            2017            3   24                          2   \n",
      "...           ...          ...  ...                        ...   \n",
      "4648         2013            3   26                          4   \n",
      "4649         2013            2   37                          2   \n",
      "4650         2018            3   27                          5   \n",
      "4651         2012            3   30                          2   \n",
      "4652         2015            3   33                          4   \n",
      "\n",
      "      EDUCATION_Bachelors  EDUCATION_Masters  EDUCATION_PHD  CITY_Bangalore  \\\n",
      "0                     1.0                0.0            0.0             1.0   \n",
      "1                     1.0                0.0            0.0             0.0   \n",
      "2                     1.0                0.0            0.0             0.0   \n",
      "3                     0.0                1.0            0.0             1.0   \n",
      "4                     0.0                1.0            0.0             0.0   \n",
      "...                   ...                ...            ...             ...   \n",
      "4648                  1.0                0.0            0.0             1.0   \n",
      "4649                  0.0                1.0            0.0             0.0   \n",
      "4650                  0.0                1.0            0.0             0.0   \n",
      "4651                  1.0                0.0            0.0             1.0   \n",
      "4652                  1.0                0.0            0.0             1.0   \n",
      "\n",
      "      CITY_New Delhi  CITY_Pune  GENDER_Female  GENDER_Male  EVERBENCHED_No  \\\n",
      "0                0.0        0.0            0.0          1.0             1.0   \n",
      "1                0.0        1.0            1.0          0.0             1.0   \n",
      "2                1.0        0.0            1.0          0.0             1.0   \n",
      "3                0.0        0.0            0.0          1.0             1.0   \n",
      "4                0.0        1.0            0.0          1.0             0.0   \n",
      "...              ...        ...            ...          ...             ...   \n",
      "4648             0.0        0.0            1.0          0.0             1.0   \n",
      "4649             0.0        1.0            0.0          1.0             1.0   \n",
      "4650             1.0        0.0            0.0          1.0             1.0   \n",
      "4651             0.0        0.0            0.0          1.0             0.0   \n",
      "4652             0.0        0.0            0.0          1.0             0.0   \n",
      "\n",
      "      EVERBENCHED_Yes  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 1.0  \n",
      "...               ...  \n",
      "4648              0.0  \n",
      "4649              0.0  \n",
      "4650              0.0  \n",
      "4651              1.0  \n",
      "4652              1.0  \n",
      "\n",
      "[4653 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature = encoding(data,'LEAVEORNOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "588c95bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOININGYEAR</th>\n",
       "      <th>PAYMENTTIER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCEINCURRENTDOMAIN</th>\n",
       "      <th>EDUCATION_Bachelors</th>\n",
       "      <th>EDUCATION_Masters</th>\n",
       "      <th>EDUCATION_PHD</th>\n",
       "      <th>CITY_Bangalore</th>\n",
       "      <th>CITY_New Delhi</th>\n",
       "      <th>CITY_Pune</th>\n",
       "      <th>GENDER_Female</th>\n",
       "      <th>GENDER_Male</th>\n",
       "      <th>EVERBENCHED_No</th>\n",
       "      <th>EVERBENCHED_Yes</th>\n",
       "      <th>LEAVEORNOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JOININGYEAR  PAYMENTTIER  AGE  EXPERIENCEINCURRENTDOMAIN  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "\n",
       "   EDUCATION_Bachelors  EDUCATION_Masters  EDUCATION_PHD  CITY_Bangalore  \\\n",
       "0                  1.0                0.0            0.0             1.0   \n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   CITY_New Delhi  CITY_Pune  GENDER_Female  GENDER_Male  EVERBENCHED_No  \\\n",
       "0             0.0        0.0            0.0          1.0             1.0   \n",
       "1             0.0        1.0            1.0          0.0             1.0   \n",
       "2             1.0        0.0            1.0          0.0             1.0   \n",
       "3             0.0        0.0            0.0          1.0             1.0   \n",
       "4             0.0        1.0            0.0          1.0             0.0   \n",
       "\n",
       "   EVERBENCHED_Yes  LEAVEORNOT  \n",
       "0              0.0           0  \n",
       "1              0.0           1  \n",
       "2              0.0           0  \n",
       "3              0.0           1  \n",
       "4              1.0           1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pandas = pd.concat([df_feature, df_target], axis=1)\n",
    "# features_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae71aceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOININGYEAR</th>\n",
       "      <th>PAYMENTTIER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCEINCURRENTDOMAIN</th>\n",
       "      <th>EDUCATION_BACHELORS</th>\n",
       "      <th>EDUCATION_MASTERS</th>\n",
       "      <th>EDUCATION_PHD</th>\n",
       "      <th>CITY_BANGALORE</th>\n",
       "      <th>CITY_NEW_DELHI</th>\n",
       "      <th>CITY_PUNE</th>\n",
       "      <th>GENDER_FEMALE</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>EVERBENCHED_NO</th>\n",
       "      <th>EVERBENCHED_YES</th>\n",
       "      <th>LEAVEORNOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JOININGYEAR  PAYMENTTIER  AGE  EXPERIENCEINCURRENTDOMAIN  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "\n",
       "   EDUCATION_BACHELORS  EDUCATION_MASTERS  EDUCATION_PHD  CITY_BANGALORE  \\\n",
       "0                  1.0                0.0            0.0             1.0   \n",
       "1                  1.0                0.0            0.0             0.0   \n",
       "2                  1.0                0.0            0.0             0.0   \n",
       "3                  0.0                1.0            0.0             1.0   \n",
       "4                  0.0                1.0            0.0             0.0   \n",
       "\n",
       "   CITY_NEW_DELHI  CITY_PUNE  GENDER_FEMALE  GENDER_MALE  EVERBENCHED_NO  \\\n",
       "0             0.0        0.0            0.0          1.0             1.0   \n",
       "1             0.0        1.0            1.0          0.0             1.0   \n",
       "2             1.0        0.0            1.0          0.0             1.0   \n",
       "3             0.0        0.0            0.0          1.0             1.0   \n",
       "4             0.0        1.0            0.0          1.0             0.0   \n",
       "\n",
       "   EVERBENCHED_YES  LEAVEORNOT  \n",
       "0              0.0           0  \n",
       "1              0.0           1  \n",
       "2              0.0           0  \n",
       "3              0.0           1  \n",
       "4              1.0           1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_pandas=features_pandas.drop(\"Unnamed: 0\", axis=1)\n",
    "features_pandas.columns = map(str.upper, features_pandas.columns)\n",
    "features_pandas.columns = features_pandas.columns.str.replace(' ', '_')\n",
    "# features_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85205f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"JOININGYEAR\"  |\"PAYMENTTIER\"  |\"AGE\"  |\"EXPERIENCEINCURRENTDOMAIN\"  |\"EDUCATION_BACHELORS\"  |\"EDUCATION_MASTERS\"  |\"EDUCATION_PHD\"  |\"CITY_BANGALORE\"  |\"CITY_NEW_DELHI\"  |\"CITY_PUNE\"  |\"GENDER_FEMALE\"  |\"GENDER_MALE\"  |\"EVERBENCHED_NO\"  |\"EVERBENCHED_YES\"  |\"LEAVEORNOT\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2017           |3              |34     |0                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2013           |1              |28     |3                            |1.0                    |0.0                  |0.0              |0.0               |0.0               |1.0          |1.0              |0.0            |1.0               |0.0                |1             |\n",
      "|2014           |3              |38     |2                            |1.0                    |0.0                  |0.0              |0.0               |1.0               |0.0          |1.0              |0.0            |1.0               |0.0                |0             |\n",
      "|2016           |3              |27     |5                            |0.0                    |1.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |1             |\n",
      "|2017           |3              |24     |2                            |0.0                    |1.0                  |0.0              |0.0               |0.0               |1.0          |0.0              |1.0            |0.0               |1.0                |1             |\n",
      "|2016           |3              |22     |0                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2015           |3              |38     |0                            |1.0                    |0.0                  |0.0              |0.0               |1.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2016           |3              |34     |2                            |1.0                    |0.0                  |0.0              |1.0               |0.0               |0.0          |1.0              |0.0            |1.0               |0.0                |1             |\n",
      "|2016           |3              |23     |1                            |1.0                    |0.0                  |0.0              |0.0               |0.0               |1.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "|2017           |2              |37     |2                            |0.0                    |1.0                  |0.0              |0.0               |1.0               |0.0          |0.0              |1.0            |1.0               |0.0                |0             |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = session.create_dataframe(features_pandas)\n",
    "# features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0deaefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS=list(features_df.columns)\n",
    "FEATURE_COLUMNS.remove('LEAVEORNOT')\n",
    "# print(FEATURE_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f58a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = [\"LEAVEORNOT\"]\n",
    "OUTPUT_COLUMNS = [\"PREDICTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f89eae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.0 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "The version of package 'scikit-learn' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'scikit-learn==1.3.0'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(\n",
    "    input_cols=FEATURE_COLUMNS,\n",
    "    label_cols=LABEL_COLUMNS,\n",
    "    output_cols=OUTPUT_COLUMNS\n",
    ")\n",
    "model.fit(features_df)\n",
    "\n",
    "# Use the model to make predictions.\n",
    "predictions = model.predict(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18ccdb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "|\"PREDICTION\"  |\n",
      "----------------\n",
      "|0             |\n",
      "|1             |\n",
      "|0             |\n",
      "|1             |\n",
      "|1             |\n",
      "|0             |\n",
      "|0             |\n",
      "|1             |\n",
      "|0             |\n",
      "|0             |\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions[OUTPUT_COLUMNS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f11cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
