{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake['ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall cloudpickle -y \n",
    "!pip install cloudpickle==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy -y\n",
    "# !pip install numpy==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758813d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall snowflake-snowpark-python -y\n",
    "# !pip install snowflake-snowpark-python==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, DoubleType, StringType\n",
    "import snowflake.snowpark.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37d01210",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "#     \"authenticator\": \"externalbrowser\", # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4355a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : ADITYASINGH\n",
      "Role                        : \"ADITYASINGH\"\n",
      "Database                    : \"FIRST_DB\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"FOSFOR_INSIGHT_WH\"\n",
      "Snowflake version           : 8.20.10\n",
      "Snowpark for Python version : 1.17.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Edit the connection.json before creating the session object below\n",
    "# Create Snowflake Session object\n",
    "# connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d162d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc05df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/mlflow_sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abd88cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(df, target_column):\n",
    "    \"\"\"\n",
    "    Checking whether encoding required in target and feature datasets.\n",
    "    If required, then encoding them with label and one hot encoding.\n",
    "    :param:\n",
    "    df: input dataframe\n",
    "    target_column: target column\n",
    "    :returns:\n",
    "    df_target: target dataframe\n",
    "    le_target: target label encoder object\n",
    "    df_feature: feature dataframe\n",
    "    le_dict_feature: dict of feature label encoder objects\n",
    "    oh_enc_feature: feature one hot encoder object\n",
    "    le_column_feature: list of feature label encoder columns\n",
    "    oh_column_feature: list of feature one hot encoder columns\n",
    "    \"\"\"\n",
    "    df_target = df[[target_column]]\n",
    "    le_target = None\n",
    "    # Target column validation and encoding\n",
    "    if df.dtypes[target_column].name in ['object', 'bool']:\n",
    "        print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "        le_target = LabelEncoder()\n",
    "        df_target[target_column] = pd.DataFrame(le_target.fit_transform(df_target[target_column].astype(str)))\n",
    "        print(f\"Target column label encoded {df_target[target_column]}, object: {le_target}\")\n",
    "\n",
    "    # Feature column validation and encoding\n",
    "    df_feature = df.drop(target_column, axis=1)\n",
    "    non_numeric_cols = df_feature.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    le_dict_feature = {}\n",
    "    le_column_feature = []\n",
    "    oh_column_feature = []\n",
    "    oh_enc_feature = None\n",
    "    if len(non_numeric_cols) >= 1:\n",
    "        print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "        for col in non_numeric_cols:\n",
    "            if df_feature[col].nunique() >= 10:\n",
    "                le_column_feature.append(col)\n",
    "            else:\n",
    "                oh_column_feature.append(col)\n",
    "\n",
    "        print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "              f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "\n",
    "        # columns to be label encoded\n",
    "        if len(le_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            for col in le_column_feature:\n",
    "                le_dict_feature[col] = LabelEncoder()\n",
    "                df_feature[col] = le_dict_feature[col].fit_transform(df_feature[col].astype(str))\n",
    "                print(f\"{col} column label encoded {df_feature[col]}, object: {le_dict_feature[col]}\")\n",
    "\n",
    "        # columns to be one hot encoded\n",
    "        if len(oh_column_feature) == 0:\n",
    "            df_feature = df_feature\n",
    "        else:\n",
    "            unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "            unique_combinations_list = unique_combinations.columns.tolist()\n",
    "            oh_enc_feature = OneHotEncoder()\n",
    "            oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "            df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "            df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "            df_feature = df_feature.join(df_oh_enc)\n",
    "            print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                  f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "        print(f\"final feature df created: {df_feature}\")\n",
    "    return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f48c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature = encoding(data,'quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b1038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10e0f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487a863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24797b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import string\n",
    "\n",
    "# from sklearn.datasets import make_regression\n",
    "# from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "# from snowflake.ml.modeling.pipeline import Pipeline\n",
    "# from snowflake.snowpark import Session\n",
    "\n",
    "# # Create a session with your preferred method\n",
    "# # session =\n",
    "\n",
    "# NUMERICAL_COLS = [\"X1\", \"X2\", \"X3\"]\n",
    "# CATEGORICAL_COLS = [\"C1\", \"C2\", \"C3\"]\n",
    "# FEATURE_COLS = NUMERICAL_COLS + CATEGORICAL_COLS\n",
    "# CATEGORICAL_OUTPUT_COLS = [\"C1_OUT\", \"C2_OUT\", \"C3_OUT\"]\n",
    "# FEATURE_OUTPUT_COLS = [\"X1_FEAT_OUT\", \"X2_FEAT_OUT\", \"X3_FEAT_OUT\", \"C1_FEAT_OUT\", \"C2_FEAT_OUT\", \"C3_FEAT_OUT\"]\n",
    "\n",
    "# # Create a dataset with numerical and categorical features\n",
    "# X, _ = make_regression(\n",
    "#     n_samples=1000,\n",
    "#     n_features=3,\n",
    "#     noise=0.1,\n",
    "#     random_state=0,\n",
    "# )\n",
    "# X = pd.DataFrame(X, columns=NUMERICAL_COLS)\n",
    "\n",
    "# def generate_random_string(length):\n",
    "#     return \"\".join(random.choices(string.ascii_uppercase, k=length))\n",
    "\n",
    "# categorical_feature_length = 2\n",
    "# categorical_features = {}\n",
    "# for c in CATEGORICAL_COLS:\n",
    "#     categorical_column = [generate_random_string(categorical_feature_length) for _ in range(X.shape[0])]\n",
    "#     categorical_features[c] = categorical_column\n",
    "\n",
    "# X = X.assign(**categorical_features)\n",
    "\n",
    "# features_df = session.create_dataframe(X)\n",
    "\n",
    "# # Fit a pipeline with OrdinalEncoder and MinMaxScaler on Snowflake\n",
    "# pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\n",
    "#             \"OE\",\n",
    "#             OrdinalEncoder(\n",
    "#                 input_cols=CATEGORICAL_COLS,\n",
    "#                 output_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "#             )\n",
    "#         ),\n",
    "#         (\n",
    "#             \"MMS\",\n",
    "#             MinMaxScaler(\n",
    "#                 input_cols=NUMERICAL_COLS + CATEGORICAL_OUTPUT_COLS,\n",
    "#                 output_cols=FEATURE_OUTPUT_COLS,\n",
    "#             )\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# pipeline.fit(features_df)\n",
    "\n",
    "# # Use the pipeline to transform a dataset.\n",
    "# result = pipeline.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.ml.modeling.xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_model = XGBRegressor(\n",
    "#     input_cols=FEATURE_COLS,\n",
    "#     label_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "#     output_cols=FEATURE_OUTPUT_COLS\n",
    "# )\n",
    "\n",
    "# xgboost_model.fit(features_df)\n",
    "\n",
    "# # Use the model to make predictions.\n",
    "# predictions = xgboost_model.predict(features_df)\n",
    "# predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e852ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "# from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "# from snowflake.snowpark import Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "# LABEL_COLS = [\"Y\"]\n",
    "# OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# # Set up data.\n",
    "# X, y = make_classification(\n",
    "#     n_samples=40000,\n",
    "#     n_features=6,\n",
    "#     n_informative=4,\n",
    "#     n_redundant=1,\n",
    "#     random_state=0,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "# y = pd.DataFrame(y, columns=LABEL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06665933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "# from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "# from snowflake.snowpark import Session\n",
    "\n",
    "# # Create a session with your preferred method\n",
    "# # session =\n",
    "\n",
    "# FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "# LABEL_COLS = [\"Y\"]\n",
    "# OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# # Set up data.\n",
    "# X, y = make_classification(\n",
    "#     n_samples=40000,\n",
    "#     n_features=6,\n",
    "#     n_informative=4,\n",
    "#     n_redundant=1,\n",
    "#     random_state=0,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "# y = pd.DataFrame(y, columns=LABEL_COLS)\n",
    "\n",
    "# features_pandas = pd.concat([X, y], axis=1)\n",
    "# features_df = session.create_dataframe(features_pandas)\n",
    "\n",
    "# # Train an XGBoost model on snowflake.\n",
    "# xgboost_model = XGBRegressor(\n",
    "#     input_cols=FEATURE_COLS,\n",
    "#     label_cols=LABEL_COLS,\n",
    "#     output_cols=OUTPUT_COLS\n",
    "# )\n",
    "\n",
    "# xgboost_model.fit(features_df)\n",
    "\n",
    "# # Use the model to make predictions.\n",
    "# predictions = xgboost_model.predict(features_df)\n",
    "# predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep clou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d1d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
