{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake['ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall cloudpickle -y \n",
    "!pip install cloudpickle==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy -y\n",
    "# !pip install numpy==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758813d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall snowflake-snowpark-python -y\n",
    "# !pip install snowflake-snowpark-python==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fb33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, DoubleType, StringType\n",
    "import snowflake.snowpark.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37d01210",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\": \"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",  # optional\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",  # optional\n",
    "#     \"authenticator\": \"externalbrowser\", # optional\n",
    "    \"database\": \"FIRST_DB\",  # optional\n",
    "    \"schema\": \"PUBLIC\",  # optional\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4355a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection Established with the following parameters:\n",
      "User                        : ADITYASINGH\n",
      "Role                        : \"ADITYASINGH\"\n",
      "Database                    : \"FIRST_DB\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"FOSFOR_INSIGHT_WH\"\n",
      "Snowflake version           : 8.20.10\n",
      "Snowpark for Python version : 1.17.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Edit the connection.json before creating the session object below\n",
    "# Create Snowflake Session object\n",
    "# connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c25e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccf7b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-146539bc3247>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('/data/mlflow_sample_data.csv', sep='COLUMN_SEPARATOR', dtype=np.float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to convert column ,fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur dioxide,total sulfur dioxide,density,pH,sulphates,alcohol,quality to type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/base_parser.py:791\u001b[0m, in \u001b[0;36mParserBase._cast_types\u001b[0;34m(self, values, cast_type, column)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 791\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/core/dtypes/astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '0,7.4,0.7,0.0,1.9,0.076,11.0,34.0,0.9978,3.51,0.56,9.4,5'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/mlflow_sample_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCOLUMN_SEPARATOR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/python_parser.py:285\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    282\u001b[0m alldata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows_to_cols(content)\n\u001b[1;32m    283\u001b[0m data, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclude_implicit_index(alldata)\n\u001b[0;32m--> 285\u001b[0m conv_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m columns, conv_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_date_conversions(columns, conv_data)\n\u001b[1;32m    288\u001b[0m index, result_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_index(\n\u001b[1;32m    289\u001b[0m     conv_data, alldata, columns, indexnamerow\n\u001b[1;32m    290\u001b[0m )\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/python_parser.py:349\u001b[0m, in \u001b[0;36mPythonParser._convert_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    346\u001b[0m     clean_na_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_values\n\u001b[1;32m    347\u001b[0m     clean_na_fvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_fvalues\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_ndarrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_na_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_na_fvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/base_parser.py:605\u001b[0m, in \u001b[0;36mParserBase._convert_to_ndarrays\u001b[0;34m(self, dct, na_values, na_fvalues, verbose, converters, dtypes)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    604\u001b[0m         cast_type \u001b[38;5;241m=\u001b[39m pandas_dtype(cast_type)\n\u001b[0;32m--> 605\u001b[0m         cvals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cast_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m result[c] \u001b[38;5;241m=\u001b[39m cvals\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m na_count:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/io/parsers/base_parser.py:793\u001b[0m, in \u001b[0;36mParserBase._cast_types\u001b[0;34m(self, values, cast_type, column)\u001b[0m\n\u001b[1;32m    791\u001b[0m         values \u001b[38;5;241m=\u001b[39m astype_nansafe(values, cast_type, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 793\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    794\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to convert column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcast_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to convert column ,fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur dioxide,total sulfur dioxide,density,pH,sulphates,alcohol,quality to type float64"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/data/mlflow_sample_data.csv', sep='COLUMN_SEPARATOR', dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24797b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import string\n",
    "\n",
    "# from sklearn.datasets import make_regression\n",
    "# from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "# from snowflake.ml.modeling.pipeline import Pipeline\n",
    "# from snowflake.snowpark import Session\n",
    "\n",
    "# # Create a session with your preferred method\n",
    "# # session =\n",
    "\n",
    "# NUMERICAL_COLS = [\"X1\", \"X2\", \"X3\"]\n",
    "# CATEGORICAL_COLS = [\"C1\", \"C2\", \"C3\"]\n",
    "# FEATURE_COLS = NUMERICAL_COLS + CATEGORICAL_COLS\n",
    "# CATEGORICAL_OUTPUT_COLS = [\"C1_OUT\", \"C2_OUT\", \"C3_OUT\"]\n",
    "# FEATURE_OUTPUT_COLS = [\"X1_FEAT_OUT\", \"X2_FEAT_OUT\", \"X3_FEAT_OUT\", \"C1_FEAT_OUT\", \"C2_FEAT_OUT\", \"C3_FEAT_OUT\"]\n",
    "\n",
    "# # Create a dataset with numerical and categorical features\n",
    "# X, _ = make_regression(\n",
    "#     n_samples=1000,\n",
    "#     n_features=3,\n",
    "#     noise=0.1,\n",
    "#     random_state=0,\n",
    "# )\n",
    "# X = pd.DataFrame(X, columns=NUMERICAL_COLS)\n",
    "\n",
    "# def generate_random_string(length):\n",
    "#     return \"\".join(random.choices(string.ascii_uppercase, k=length))\n",
    "\n",
    "# categorical_feature_length = 2\n",
    "# categorical_features = {}\n",
    "# for c in CATEGORICAL_COLS:\n",
    "#     categorical_column = [generate_random_string(categorical_feature_length) for _ in range(X.shape[0])]\n",
    "#     categorical_features[c] = categorical_column\n",
    "\n",
    "# X = X.assign(**categorical_features)\n",
    "\n",
    "# features_df = session.create_dataframe(X)\n",
    "\n",
    "# # Fit a pipeline with OrdinalEncoder and MinMaxScaler on Snowflake\n",
    "# pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\n",
    "#             \"OE\",\n",
    "#             OrdinalEncoder(\n",
    "#                 input_cols=CATEGORICAL_COLS,\n",
    "#                 output_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "#             )\n",
    "#         ),\n",
    "#         (\n",
    "#             \"MMS\",\n",
    "#             MinMaxScaler(\n",
    "#                 input_cols=NUMERICAL_COLS + CATEGORICAL_OUTPUT_COLS,\n",
    "#                 output_cols=FEATURE_OUTPUT_COLS,\n",
    "#             )\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# pipeline.fit(features_df)\n",
    "\n",
    "# # Use the pipeline to transform a dataset.\n",
    "# result = pipeline.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.ml.modeling.xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa170b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_model = XGBRegressor(\n",
    "#     input_cols=FEATURE_COLS,\n",
    "#     label_cols=CATEGORICAL_OUTPUT_COLS,\n",
    "#     output_cols=FEATURE_OUTPUT_COLS\n",
    "# )\n",
    "\n",
    "# xgboost_model.fit(features_df)\n",
    "\n",
    "# # Use the model to make predictions.\n",
    "# predictions = xgboost_model.predict(features_df)\n",
    "# predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25592070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "# from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "# from snowflake.snowpark import Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "# LABEL_COLS = [\"Y\"]\n",
    "# OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# # Set up data.\n",
    "# X, y = make_classification(\n",
    "#     n_samples=40000,\n",
    "#     n_features=6,\n",
    "#     n_informative=4,\n",
    "#     n_redundant=1,\n",
    "#     random_state=0,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "# y = pd.DataFrame(y, columns=LABEL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06665933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "# from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "# from snowflake.snowpark import Session\n",
    "\n",
    "# # Create a session with your preferred method\n",
    "# # session =\n",
    "\n",
    "# FEATURE_COLS = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\"]\n",
    "# LABEL_COLS = [\"Y\"]\n",
    "# OUTPUT_COLS = [\"PREDICTIONS\"]\n",
    "\n",
    "# # Set up data.\n",
    "# X, y = make_classification(\n",
    "#     n_samples=40000,\n",
    "#     n_features=6,\n",
    "#     n_informative=4,\n",
    "#     n_redundant=1,\n",
    "#     random_state=0,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# X = pd.DataFrame(X, columns=FEATURE_COLS)\n",
    "# y = pd.DataFrame(y, columns=LABEL_COLS)\n",
    "\n",
    "# features_pandas = pd.concat([X, y], axis=1)\n",
    "# features_df = session.create_dataframe(features_pandas)\n",
    "\n",
    "# # Train an XGBoost model on snowflake.\n",
    "# xgboost_model = XGBRegressor(\n",
    "#     input_cols=FEATURE_COLS,\n",
    "#     label_cols=LABEL_COLS,\n",
    "#     output_cols=OUTPUT_COLS\n",
    "# )\n",
    "\n",
    "# xgboost_model.fit(features_df)\n",
    "\n",
    "# # Use the model to make predictions.\n",
    "# predictions = xgboost_model.predict(features_df)\n",
    "# predictions[OUTPUT_COLS].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep clou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be923f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
