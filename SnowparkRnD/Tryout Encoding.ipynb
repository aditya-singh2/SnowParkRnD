{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ddc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "exp_data = '{\"name\": \"moremetrices01\", \"algo_details\": {\"snowflake.ml.modeling.ensemble.GradientBoostingClassifier\": null}, \"id\": \"367\", \"dataset\": \"AIRLINE_DEP_DELAY_10K\", \"target_column\": \"DEP_DEL15\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511aba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, os\n",
    "from snowflake.snowpark.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf95e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {\n",
    "    \"account\": \"ug94937.us-east4.gcp\",\n",
    "    \"user\":\"ADITYASINGH\",\n",
    "    \"password\": os.environ.get('SF_Password'),\n",
    "    \"role\": \"ADITYASINGH\",\n",
    "    \"database\": \"FIRST_DB\",\n",
    "    \"warehouse\": \"FOSFOR_INSIGHT_WH\",\n",
    "    \"schema\": \"PUBLIC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e890cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(session, stage_name=\"demo\"):\n",
    "    try:\n",
    "        session.sql(f\"create or replace stage {stage_name}\").collect()\n",
    "        return f\"@{stage_name}\"\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "195e63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_models(session: Session, exp_data: str) -> list:\n",
    "    # variable for holding logs\n",
    "    logs = []\n",
    "    \n",
    "    # function for accumulating logs\n",
    "    def log_message(level: str, message: str):\n",
    "        logs.append(f\"{level}: {message}\")\n",
    "        \n",
    "    from snowflake.ml.modeling.pipeline import Pipeline\n",
    "    from snowflake.ml.modeling.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "         r2_score, accuracy_score, precision_score, roc_auc_score, f1_score, recall_score\n",
    "    from snowflake.snowpark.functions import col, last_value, row_number, first_value, when, lit\n",
    "    from snowflake.snowpark.window import Window\n",
    "    import importlib, sys, json\n",
    "    from snowflake.snowpark.types import StringType, BooleanType\n",
    "\n",
    "    log_message(\"INFO\",\"Starting Experiment Recipe Execution\")\n",
    "    \n",
    "#     def oh_encode(df, column):\n",
    "#         unique values = df.select(column).distinct().to_pandas()\n",
    "#         unique_values =  unique_values.values.tolist()\n",
    "#         for value in unique_values:\n",
    "#             df = df.with_column\n",
    "    \n",
    "    def encoding(df, target_column):\n",
    "        df_target = df[[target_column]]\n",
    "        le_target = None\n",
    "        # Target column validation and encoding\n",
    "        for item in df.dtypes:\n",
    "            if item[0] == target_column and item[1] in ['object', 'bool']:\n",
    "                print(f\"target_column is of {df.dtypes[target_column].name} datatype, encoding required.\")\n",
    "                le_target = LabelEncoder()\n",
    "                target_list = df.select(target_column).collect()\n",
    "                target_values = [row[target_column] for row in target_list]\n",
    "                encoded_values = le_target.fit_transform(target_values)\n",
    "                df_target = session.create_dataframe([(val,) for val in encoded_values.tolist()], schema=[target_column])\n",
    "                print(f\"Target column label encoded {df_target.show()}, object: {le_target}\")\n",
    "    \n",
    "        # Feature column validation and encoding\n",
    "        df_feature = df.drop(target_column)\n",
    "        non_numeric_cols = [field.name for field in df_feature.schema.fields if isinstance(field.datatype, (StringType, BooleanType))]\n",
    "        le_dict_feature = {}\n",
    "        le_column_feature = []\n",
    "        oh_column_feature = []\n",
    "        oh_enc_feature = None\n",
    "        if len(non_numeric_cols) >= 1:\n",
    "            print(f\"{non_numeric_cols} columns are non numeric in feature dataset, encoding required.\")\n",
    "            for column in non_numeric_cols:\n",
    "                if df_feature.select(df_feature[column]).distinct().count() >= 10:\n",
    "                    le_column_feature.append(column)\n",
    "                else:\n",
    "                    oh_column_feature.append(column)\n",
    "    \n",
    "            print(f\"Columns identified to be encoded with label encoder: {le_column_feature}\\n\"\n",
    "                  f\"Columns identified to be encoded with one hot encoder: {oh_column_feature}\")\n",
    "    \n",
    "            # columns to be label encoded\n",
    "            if len(le_column_feature) == 0:\n",
    "                df_feature = df_feature\n",
    "            else:\n",
    "                for column in le_column_feature:\n",
    "                    le_dict_feature[column] = LabelEncoder()\n",
    "                    df_feature[column] = le_dict_feature[col].fit_transform(df_feature[column].astype(str))\n",
    "                    print(f\"{column} column label encoded {df_feature.show(column)}, object: {le_dict_feature[column]}\")\n",
    "    \n",
    "            # columns to be one hot encoded\n",
    "            if len(oh_column_feature) == 0:\n",
    "                df_feature = df_feature\n",
    "            else:\n",
    "                unique_combinations = df_feature.select(*oh_column_feature).distinct().collect()\n",
    "                for combination in unique_combinations:\n",
    "                    condition = lit(True)\n",
    "                    for column in oh_column_feature:\n",
    "                        condition = condition & (col(column) == combination[column])\n",
    "                    column_name =  \"_\".join([f\"{column}_{combination[column]}\" for column in oh_column_feature])\n",
    "                unique_combinations = df_feature.with_column(\n",
    "                    column_name,\n",
    "                    when(condition, 1).otherwise(0)\n",
    "                )\n",
    "                unique_combinations.show()\n",
    "#                 unique_combinations = pd.get_dummies(df_feature[oh_column_feature])\n",
    "                unique_combinations_list = [field.name for field in unique_combinations.schema]\n",
    "                oh_enc_feature = OneHotEncoder()\n",
    "                oh_encoded_array = oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray() if len(\n",
    "                    oh_column_feature) > 1 else oh_enc_feature.fit_transform(df_feature[oh_column_feature]).toarray()\n",
    "                df_oh_enc = pd.DataFrame(oh_encoded_array, columns=unique_combinations_list)\n",
    "                df_feature = df_feature.drop(columns=oh_column_feature)\n",
    "                df_feature = df_feature.join(df_oh_enc)\n",
    "                print(f\"new one hot encoded df: {oh_encoded_array}\\n\"\n",
    "                      f\"one hot encoder object: {oh_enc_feature}\\n\")\n",
    "            print(f\"final feature df created: {df_feature}\")\n",
    "        return df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature\n",
    "           \n",
    "    \n",
    "    # Experiment details\n",
    "    exp_details=json.loads(exp_data)\n",
    "    \n",
    "    # Read dataset, Random split\n",
    "    log_message(\"INFO\",\"Reading and Identifing dataset features\")\n",
    "    data = session.table(exp_details.get(\"dataset\"))\n",
    "    \n",
    "    # Data Preprocessing: Validating and encoding the data if required and imputing null values.\n",
    "    window_spec = Window.order_by(exp_details.get(\"target_column\"))\n",
    "    data_row_num = data.with_column('ROW_NUM', row_number().over(window_spec))\n",
    "    columns = data_row_num.columns\n",
    "    columns.remove('ROW_NUM')\n",
    "    # forward fillna\n",
    "    data_ff = data_row_num.select(\n",
    "            [data_row_num['ROW_NUM']] + [\n",
    "                last_value(col(column), ignore_nulls=True).over(Window.order_by('ROW_NUM')).alias(column)\n",
    "                for column in columns\n",
    "            ]\n",
    "        )\n",
    "    # backward fillna\n",
    "    data_bf = data_row_num.select(\n",
    "            [data_row_num['ROW_NUM']] + [\n",
    "                first_value(col(column), ignore_nulls=True).over(Window.order_by(data_ff['ROW_NUM'].desc())).alias(column)\n",
    "                for column in columns\n",
    "            ]\n",
    "        )\n",
    "    data = data_bf.drop('ROW_NUM')\n",
    "\n",
    "    df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature = encoding(\n",
    "        data, exp_details.get(\"target_column\"))\n",
    "    \n",
    "    \n",
    "    df_train, df_test = session.table(exp_details.get(\"dataset\")).drop('ROW').random_split(weights=[0.9, 0.1], seed=0)\n",
    "    features = df_train.columns\n",
    "    features.remove(exp_details.get(\"target_column\"))\n",
    "    \n",
    "    # get features\n",
    "    data_schema = session.sql(f\"DESCRIBE TABLE {exp_details.get('dataset')}\").collect()\n",
    "    categorical_types = ['VARCHAR','CHAR','STRING','TEXT','BOOL']\n",
    "    categorical_features = []\n",
    "    \n",
    "    for row in data_schema:\n",
    "        for typ in categorical_types:\n",
    "            if typ in row['type'] and row['name']!=exp_details.get(\"target_column\"):\n",
    "                categorical_features.append(row['name'])\n",
    "                break\n",
    "    numerical_features = list(set(features) - set(categorical_features))\n",
    "    log_message(\"INFO\",f\"numerical_features:  {numerical_features}\")\n",
    "    log_message(\"INFO\",f\"categorical_features_oe: {categorical_features}\")\n",
    "    \n",
    "    \n",
    "    #pipeline steps \n",
    "    log_message(\"INFO\",\"Setting up preprocessing pipeline based on dataset\")\n",
    "    categorical_pp = {\n",
    "        'ohe': OneHotEncoder(input_cols=categorical_features, output_cols=categorical_features)\n",
    "    }\n",
    "    numerical_pp = {\n",
    "        'scaler': MinMaxScaler(input_cols=numerical_features, output_cols=numerical_features)\n",
    "    }\n",
    "    steps = [(key, categorical_pp[key]) for key in categorical_pp if categorical_features!=[]] + \\\n",
    "    [(key, numerical_pp[key]) for key in numerical_pp if numerical_features!=[]]\n",
    "    \n",
    "    \n",
    "    # Define a pipeline that does the preprocessing and training of \n",
    "    # dynamically import selected algorithms\n",
    "    for algorithm, hyperparam in exp_details.get(\"algo_details\").items():\n",
    "        algorithm = algorithm.rsplit('.', 1)\n",
    "        module = importlib.import_module(algorithm[0])\n",
    "        log_message(\"INFO\",f\"Running Algorithm {algorithm[1]}\")\n",
    "        attr = getattr(module, algorithm[1])\n",
    "        \n",
    "        pipe = Pipeline(steps=steps+[(\"algorithm\", attr(input_cols=categorical_features+numerical_features\n",
    "                                              , label_cols=[exp_details.get(\"target_column\")]\n",
    "                                              , output_cols=[f'PREDICTIONS_{algorithm[1]}'.upper()]))]\n",
    "               )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        log_message(\"INFO\",f\"Running model pipeline {algorithm[1]}\")\n",
    "        model = pipe.fit(df_train)\n",
    "        \n",
    "#         log_message(\"INFO\",f\"final model size {model.size()} bytes\")\n",
    "        \n",
    "        # Test the model\n",
    "        log_message(\"INFO\",\"Running prediction on model with test dataset\")\n",
    "        df_test_pred = model.predict(df_test)\n",
    "        \n",
    "        # metrices\n",
    "        log_message(\"INFO\",\"Generating Metrices\")\n",
    "        accuracy = accuracy_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        f1_score = f1_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        recall_score = recall_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        precision_score = precision_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_pred_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        roc_auc_score = roc_auc_score(df=df_test_pred, y_true_col_names=exp_details.get(\"target_column\"), y_score_col_names=f'PREDICTIONS_{algorithm[1]}'.upper())\n",
    "        print(\"Execution Completed\")\n",
    "        print(f'{algorithm[1]} MSE: {accuracy}')\n",
    "\n",
    "        print(f'{algorithm[1]} R2: {precision_score}')\n",
    "        print(f'{algorithm[1]} R2: {roc_auc_score}')\n",
    "        \n",
    "\n",
    "        # LOG MODEL INTO SNOWFLAKE REGISTRY\n",
    "        from snowflake.ml.registry.registry import Registry\n",
    "        reg = Registry(session=session)\n",
    "        # Log the model\n",
    "        log_message(\"INFO\",\"Started: Registering model on snowflake\")\n",
    "        try:\n",
    "            mv = reg.log_model(model=model,\n",
    "                               model_name=exp_details.get(\"name\", \"sample_experiment\")+\"_\"+algorithm[1],\n",
    "                               comment=\"test\",\n",
    "                               version_name=\"run1\",\n",
    "                               python_version=\"3.9.19\",\n",
    "                               conda_dependencies=[\"scikit-learn==1.3.2\"],\n",
    "                               metrics=[{\"model_metrics\": {\"roc_auc_score\": roc_auc_score, \"precision_score\": precision_score, \"f1_score\": f1_score, \"recall_score\": recall_score, \"accuracy_score\": accuracy}, \"project_id\": \"0001\", \"type\": \"EXP\"}])\n",
    "            log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "        except Exception as ex:\n",
    "            key = 'Processing aborted due to error 370001' \n",
    "            if key in str(ex):\n",
    "                log_message(\"INFO\",\"Registeration of model completed!!!\")\n",
    "                pass\n",
    "            else:\n",
    "                log_message(\"ERROR\",\"Exception Occured while registering model\")\n",
    "                return str(ex).split('?')\n",
    "    return [{\"Execution Logs:\": \"\\n\".join(logs),\n",
    "             \"EXP_NAME\":exp_details.get(\"name\", \"sample_experiment\"),\n",
    "             \"Version\":\"Run1\",\n",
    "             \"matrices\":{\"model_metrics\": {\"roc_auc_score\": roc_auc_score, \"precision_score\": precision_score, \"f1_score\": f1_score, \"recall_score\": recall_score, \"accuracy_score\": accuracy}, \"project_id\": \"0001\", \"type\": \"EXP\"},\n",
    "             \"Alogirthm_Type\":\"Regression\",\n",
    "             \"Alogithms\": list(exp_details.get(\"algo_details\").keys()),\n",
    "             \"RUN_STATUS\":\"SUCCESS\",\n",
    "             \"registry_exp_name\":\"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b696bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Snowflake Session object...\n",
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.10.1, Python Version: 3.9.18, Platform: Linux-6.1.58+-x86_64-with-glibc2.34\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:snowflake.snowpark.session:Snowpark Session information: \n",
      "\"version\" : 1.17.0,\n",
      "\"python.version\" : 3.9.18,\n",
      "\"python.connector.version\" : 3.10.1,\n",
      "\"python.connector.session.id\" : 96125691279638,\n",
      "\"os.name\" : Linux\n",
      "\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Session has been created !\n",
      "Creating stored procedure...\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 2\n",
      "WARNING:snowflake.snowpark.session:The version of package 'snowflake-snowpark-python' in the local environment is 1.17.0, which does not fit the criteria for the requirement 'snowflake-snowpark-python'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Stored procedure has been created successfully!\n",
      "Executing Procedure\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT'] columns are non numeric in feature dataset, encoding required.\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "Columns identified to be encoded with label encoder: []\n",
      "Columns identified to be encoded with one hot encoder: ['DEP_TIME_BLK', 'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT']\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 10\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"MONTH\"  |\"DAY_OF_WEEK\"  |\"DEP_TIME_BLK\"  |\"DISTANCE_GROUP\"  |\"SEGMENT_NUMBER\"  |\"CONCURRENT_FLIGHTS\"  |\"NUMBER_OF_SEATS\"  |\"CARRIER_NAME\"  |\"AIRPORT_FLIGHTS_MONTH\"  |\"AIRLINE_FLIGHTS_MONTH\"  |\"AIRLINE_AIRPORT_FLIGHTS_MONTH\"  |\"AVG_MONTHLY_PASS_AIRPORT\"  |\"AVG_MONTHLY_PASS_AIRLINE\"  |\"FLT_ATTENDANTS_PER_PASS\"  |\"GROUND_SERV_PER_PASS\"  |\"PLANE_AGE\"  |\"DEPARTING_AIRPORT\"                |\"LATITUDE\"  |\"LONGITUDE\"  |\"PREVIOUS_AIRPORT\"  |\"PRCP\"  |\"SNOW\"  |\"SNWD\"  |\"TMAX\"  |\"AWND\"  |\"CARRIER_HISTORICAL\"  |\"DEP_AIRPORT_HIST\"  |\"DAY_HISTORICAL\"    |\"DEP_BLOCK_HIST\"    |\"DEP_TIME_BLK_1500-1559_CARRIER_NAME_American A...  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "|6        |1              |2000-2059       |2                 |1                 |21                    |50                 |Comair Inc.     |11017                    |24179                    |2351                             |955406                      |1245396                     |0.0                        |8.999810569042966e-05   |15           |Ronald Reagan Washington National  |38.852      |-77.037      |NONE                |0.06    |0.0     |0.0     |90.0    |4.7     |0.2171979243884358    |0.1878828898345793  |0.2535681805527199  |0.3717355758000467  |0                                                   |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "(2101) input_cols is not set. To read more about Snowpark ML general API differences, please refer to: https://docs.snowflake.com/en/developer-guide/snowpark-ml/snowpark-ml-modeling#general-api-differences.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowflakeMLException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/snowflake/ml/_internal/telemetry.py:367\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:291\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_cols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_check_dataset_type(dataset)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/snowflake/ml/modeling/framework/base.py:165\u001b[0m, in \u001b[0;36mBase._check_input_cols\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_cols:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mSnowflakeMLException(\n\u001b[1;32m    166\u001b[0m         error_code\u001b[38;5;241m=\u001b[39merror_codes\u001b[38;5;241m.\u001b[39mNOT_FOUND,\n\u001b[1;32m    167\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mRuntimeError\u001b[39;00m(modeling_error_messages\u001b[38;5;241m.\u001b[39mATTRIBUTE_NOT_SET\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_cols\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    168\u001b[0m     )\n",
      "\u001b[0;31mSnowflakeMLException\u001b[0m: RuntimeError('(2101) input_cols is not set. To read more about Snowpark ML general API differences, please refer to: https://docs.snowflake.com/en/developer-guide/snowpark-ml/snowpark-ml-modeling#general-api-differences.')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting Procedure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# procedure_response = session.call(\"train_ml_models\", exp_data)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m procedure_response \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ml_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStored Procedure Executed Successfully !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(procedure_response)\n",
      "Cell \u001b[0;32mIn[21], line 124\u001b[0m, in \u001b[0;36mtrain_ml_models\u001b[0;34m(session, exp_data)\u001b[0m\n\u001b[1;32m    116\u001b[0m data_bf \u001b[38;5;241m=\u001b[39m data_row_num\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m    117\u001b[0m         [data_row_num[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROW_NUM\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m    118\u001b[0m             first_value(col(column), ignore_nulls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mover(Window\u001b[38;5;241m.\u001b[39morder_by(data_ff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROW_NUM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdesc()))\u001b[38;5;241m.\u001b[39malias(column)\n\u001b[1;32m    119\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns\n\u001b[1;32m    120\u001b[0m         ]\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m data \u001b[38;5;241m=\u001b[39m data_bf\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROW_NUM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m df_target, le_target, df_feature, le_dict_feature, oh_enc_feature, le_column_feature, oh_column_feature \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_column\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m df_train, df_test \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mtable(exp_details\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROW\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrandom_split(weights\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.1\u001b[39m], seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    129\u001b[0m features \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mcolumns\n",
      "Cell \u001b[0;32mIn[21], line 85\u001b[0m, in \u001b[0;36mtrain_ml_models.<locals>.encoding\u001b[0;34m(df, target_column)\u001b[0m\n\u001b[1;32m     83\u001b[0m unique_combinations_list \u001b[38;5;241m=\u001b[39m [field\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m unique_combinations\u001b[38;5;241m.\u001b[39mschema]\n\u001b[1;32m     84\u001b[0m oh_enc_feature \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n\u001b[0;32m---> 85\u001b[0m oh_encoded_array \u001b[38;5;241m=\u001b[39m \u001b[43moh_enc_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_feature\u001b[49m\u001b[43m[\u001b[49m\u001b[43moh_column_feature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m     86\u001b[0m     oh_column_feature) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m oh_enc_feature\u001b[38;5;241m.\u001b[39mfit(df_feature[oh_column_feature])\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     87\u001b[0m df_oh_enc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(oh_encoded_array, columns\u001b[38;5;241m=\u001b[39munique_combinations_list)\n\u001b[1;32m     88\u001b[0m df_feature \u001b[38;5;241m=\u001b[39m df_feature\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39moh_column_feature)\n",
      "File \u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/snowflake/ml/_internal/telemetry.py:389\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m update_stmt_params_if_snowpark_df(res, statement_params)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: (2101) input_cols is not set. To read more about Snowpark ML general API differences, please refer to: https://docs.snowflake.com/en/developer-guide/snowpark-ml/snowpark-ml-modeling#general-api-differences."
     ]
    }
   ],
   "source": [
    "# Initilization\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "print(\"Creating Snowflake Session object...\")\n",
    "session = get_session()\n",
    "stage = create_stage(session)\n",
    "print(\"Session has been created !\")\n",
    "\n",
    "print(\"Creating stored procedure...\")\n",
    "session.sproc.register(func=train_ml_models,\n",
    "                       name=\"train_ml_models\",\n",
    "                       packages=[\"snowflake-snowpark-python\", \"snowflake-ml-python\"],\n",
    "                       isPermanant=False,\n",
    "                       stage_location=stage,\n",
    "                       replace=True)\n",
    "print(\"Stored procedure has been created successfully!\")\n",
    "\n",
    "print(\"Executing Procedure\")\n",
    "# procedure_response = session.call(\"train_ml_models\", exp_data)\n",
    "procedure_response = train_ml_models(session, exp_data)\n",
    "print(\"Stored Procedure Executed Successfully !\")\n",
    "print(procedure_response)\n",
    "\n",
    "#Log in mlflow\n",
    "print(\"Logging in mlflow completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc573c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
