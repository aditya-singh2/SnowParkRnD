{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a615090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 µs, sys: 0 ns, total: 38 µs\n",
      "Wall time: 44.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fosforio.manager import get_conn_details_from_ds_name\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.registry import Registry\n",
    "import pandas as pd, re, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5960d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(dataset, project_id):\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_conn_details_from_ds_name(dataset, project_id)\n",
    "        region=conn[\"params\"][\"READER\"][\"region\"] if conn[\"params\"][\"READER\"][\"cloudPlatform\"] is None \\\n",
    "                    else conn[\"params\"][\"READER\"][\"region\"]+\".\"+conn[\"params\"][\"READER\"][\"cloudPlatform\"]\n",
    "        account = conn['params']['READER']['accountId'] if region is None \\\n",
    "                    else conn['params']['READER']['accountId']+\".\"+region\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": account,\n",
    "            \"user\":conn['params']['READER']['user'],\n",
    "            \"password\": conn['params']['READER']['password'],\n",
    "            \"role\": conn['params']['READER']['role'],\n",
    "            \"database\": conn['params']['READER']['database'],\n",
    "            \"warehouse\": conn['params']['READER']['wareHouse'],\n",
    "            \"schema\": conn['params']['READER']['schema']\n",
    "        }\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4af188",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session('DIAMONDS',\"fd0cf79c-8118-43a7-8f0b-059e8f78227a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4864c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "exp_id=\"600b9f90-f431-4590-83c7-f38fe138dedc\"#\"600b9f90-f431-4590-83c7-f38fe138dedc\"\n",
    "project_id=\"68bce134-6d7a-4e24-9591-86266438acf9\"\n",
    "executions_url = f\"http://monitor-backend-service/monitor/api/v4/executions/search?objectId={exp_id}&projectId={project_id}&jobType=EXPERIMENT&profile=DETAILED\"\n",
    "\n",
    "temp_head = {\n",
    "    \"X-Auth-Userid\": \"aditya1.singh2@fosfor.com\",\n",
    "    \"X-Auth-Username\": \"aditya1.singh2@fosfor.com\",\n",
    "    \"X-Auth-Email\": \"aditya1.singh2@fosfor.com\",\n",
    "    \"X-Project-Id\": \"68bce134-6d7a-4e24-9591-86266438acf9\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2d9789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totalRecordCount': 1, 'data': [{'jobinstanceId': 110003, 'objectId': '600b9f90-f431-4590-83c7-f38fe138dedc', 'projectId': '68bce134-6d7a-4e24-9591-86266438acf9', 'projectName': None, 'jobObjectName': 'New_Experiment_01', 'jobScheduleId': None, 'jobInstanceInputParameter': '{\"input_params\":\"{\\\\\"currentTime\\\\\":\\\\\"2024-07-10T14:10:56Z\\\\\",\\\\\"objectName\\\\\":\\\\\"New_Experiment_01\\\\\",\\\\\"lastRunDate\\\\\":\\\\\"2024-07-10T13:45:54Z\\\\\",\\\\\"instanceId\\\\\":\\\\\"110003\\\\\",\\\\\"lastSuccessfulRunDate\\\\\":\\\\\"\\\\\",\\\\\"userId\\\\\":\\\\\"aditya1.singh2@fosfor.com\\\\\"}\"}', 'jobType': 'EXPERIMENT', 'jobStatus': 'SUCCESSFUL', 'finalStatus': 'SUCCESSFUL', 'jobCreatedby': 'aditya1.singh2@fosfor.com', 'jobCreatedts': '2024-07-10T14:10:56.270+00:00', 'jobUpdatedby': 'aditya1.singh2@fosfor.com', 'jobUpdatedts': '2024-07-10T14:11:41.460+00:00', 'applicationId': '01b59392-0000-72c9-0000-576d074ae99a', 'executionId': None, 'runID': '110003', 'versionNumber': None, 'runEngine': 'SNOWFLAKE', 'attemptId': 110107, 'workflowId': None, 'jobConfig': '{\"snowflake_query\": \"CALL RUN_EXPERIMENT({\\'algorithm_category\\': \\'Snowparkml\\', \\'algorithm_type\\': \\'Classification\\', \\'algorithms\\': [{\\'algorithm_name\\': \\'snowflake.ml.modeling.xgboost.XGBClassifier\\'}], \\'dataset_name\\': \\'DIAMONDS\\', \\'experiment_id\\': \\'600b9f90-f431-4590-83c7-f38fe138dedc\\', \\'experiment_name\\': \\'New_Experiment_01\\', \\'monitor_run_id\\': \\'MONITORRUNID\\', \\'project_id\\': \\'68bce134-6d7a-4e24-9591-86266438acf9\\', \\'stored_procedure\\': \\'run_experiment\\', \\'target_column\\': \\'PRICE\\'});\", \"algorithm\": \"snowflake.ml.modeling.xgboost.XGBClassifier\"}'}], 'jobTypesList': None, 'executedByList': None, 'projectList': None}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(executions_url, headers=temp_head)\n",
    "print(response.json())\n",
    "res = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb20180",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res_format = {\n",
    "            \"run_id\": \"\",\n",
    "            \"algorithm_used\": \"\",\n",
    "            \"run_status\": \"\",\n",
    "        }\n",
    "monitor_resp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b51e787",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type set is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m _res_format\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: {data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunID\u001b[39m\u001b[38;5;124m'\u001b[39m)},\n\u001b[1;32m      8\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_status\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobStatus\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      9\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm_used\u001b[39m\u001b[38;5;124m\"\u001b[39m: algorithm_used[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m})\n\u001b[1;32m     10\u001b[0m res_data \u001b[38;5;241m=\u001b[39m _res_format\n\u001b[0;32m---> 11\u001b[0m monitor_resp\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_data\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type set is not JSON serializable"
     ]
    }
   ],
   "source": [
    "for data in res.get('data'):\n",
    "    jobConfig=data.get('jobConfig')\n",
    "    pattern = r\"snowflake\\.ml[^']*\"\n",
    "    match = re.search(pattern, jobConfig)\n",
    "    if match:\n",
    "        algorithm_used = match.group().rsplit('.', 1)\n",
    "    _res_format.update({\"run_id\": {data.get('runID')},\n",
    "                        \"run_status\": data.get('jobStatus'),\n",
    "                        \"algorithm_used\": algorithm_used[1] if match else None})\n",
    "    res_data = _res_format\n",
    "    monitor_resp.append(json.dumps(res_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e96644",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT \" \\\n",
    "        \"METADATA:metrics:model_metrics as model_metrics,\" \\\n",
    "        \"METADATA:metrics:run_id as run_id, \" \\\n",
    "        \"METADATA:metrics:status as status, \" \\\n",
    "        \"MODEL_NAME as sf_model_name \" \\\n",
    "        f\"FROM INFORMATION_SCHEMA.MODEL_VERSIONS where METADATA:metrics:experiment_id='{exp_id}';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e1a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT METADATA:metrics:model_metrics as model_metrics,METADATA:metrics:run_id as run_id, METADATA:metrics:status as status, MODEL_NAME as sf_model_name FROM INFORMATION_SCHEMA.MODEL_VERSIONS where METADATA:metrics:experiment_id='600b9f90-f431-4590-83c7-f38fe138dedc';\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e175b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  {\"run_id\": \"110003\", \"algorithm_used\": \"XGBCla...\n",
      "                                       model_metrics    run_id     status  \\\n",
      "0  {\\n  \"accuracy_score\": 0.840549,\\n  \"f1_score\"...  \"110003\"  \"Trained\"   \n",
      "\n",
      "                               experiment_model_name  \n",
      "0  EXPERIMENT_68BCE134_6D7A_4E24_9591_86266438ACF...  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'run_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fe9adbfbf18e>\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mregistry_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmonitor_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m registry_resp.rename(columns={'MODEL_METRICS': 'model_metrics',\n",
      "\u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 110\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    699\u001b[0m         (\n\u001b[1;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/packages/Python-3.9-Snowpark/c4ae710c-7618-477a-97d0-5337fbf62a9a/3.9/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m             )\n\u001b[1;32m   1849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'run_id'"
     ]
    }
   ],
   "source": [
    "registry_resp = session.sql(query).to_pandas()\n",
    "monitor_resp = pd.DataFrame(monitor_resp)\n",
    "print(monitor_resp)\n",
    "registry_resp.rename(columns={'MODEL_METRICS': 'model_metrics',\n",
    "                              'RUN_ID': 'run_id',\n",
    "                              'STATUS': 'status',\n",
    "                              'SF_MODEL_NAME': 'experiment_model_name'}, inplace=True)  \n",
    "print(registry_resp)\n",
    "final_resp = pd.merge(monitor_resp, registry_resp, on='run_id')\n",
    "# final_resp = monitor_resp.join(registry_resp, how='left')\n",
    "a = {'data': final_resp.to_dict(orient='records')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(monitor_resp)\n",
    "print(registry_resp)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ab096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "res=response.json()\n",
    "for data in res.get('data'):\n",
    "    jobConfig=data.get('jobConfig')\n",
    "    print(jobConfig)\n",
    "#     data = json.loads(data)\n",
    "#     print(jobConfig)\n",
    "    pattern = r'snowflake\\.ml[^\"]*'\n",
    "    x = re.search(pattern, jobConfig)\n",
    "    print(x.group(0))\n",
    "    print(type(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monitor_resp = [\n",
    "    {\n",
    "        \"run_id\": \"RUN_0001\",\n",
    "        \"algorithm_used\": \"XGBClassifier\",\n",
    "        \"status\": \"Successful\"\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"RUN_0001_11\",\n",
    "        \"algorithm_used\": \"DecisionTreeClassifier\",\n",
    "        \"status\": \"Successful\"\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"ef47a0a5\",\n",
    "        \"algorithm_used\": \"GradientBoostingClassifier\",\n",
    "        \"status\": \"Running\"\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"26a15f9c\",\n",
    "        \"algorithm_used\": \"RandomForestClassifier\",\n",
    "        \"status\": \"Running\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# monitor_resp = []\n",
    "def get_session(dataset, project_id):\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_conn_details_from_ds_name(dataset, project_id)\n",
    "        region=conn[\"params\"][\"READER\"][\"region\"] if conn[\"params\"][\"READER\"][\"cloudPlatform\"] is None \\\n",
    "                    else conn[\"params\"][\"READER\"][\"region\"]+\".\"+conn[\"params\"][\"READER\"][\"cloudPlatform\"]\n",
    "        account = conn['params']['READER']['accountId'] if region is None \\\n",
    "                    else conn['params']['READER']['accountId']+\".\"+region\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": account,\n",
    "            \"user\":conn['params']['READER']['user'],\n",
    "            \"password\": conn['params']['READER']['password'],\n",
    "            \"role\": conn['params']['READER']['role'],\n",
    "            \"database\": conn['params']['READER']['database'],\n",
    "            \"warehouse\": conn['params']['READER']['wareHouse'],\n",
    "            \"schema\": conn['params']['READER']['schema']\n",
    "        }\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "        \n",
    "session = get_session(\"EMPLOYEE_10L\",\"fd0cf79c-8118-43a7-8f0b-059e8f78227a\") #,\"\")0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\n",
    "query =\"SELECT METADATA:metrics as model_metrics, COMMENT as run_id FROM INFORMATION_SCHEMA.MODEL_VERSIONS where MODEL_NAME like '%EXP_001%';\"\n",
    "registry_resp = session.sql(query).to_pandas()\n",
    "registry_resp.rename(columns={'RUN_ID': 'run_id', \n",
    "                              'MODEL_METRICS': 'model_metrics'}, inplace=True)\n",
    "monitor_resp = pd.DataFrame(monitor_resp)\n",
    "final_resp = pd.merge(monitor_resp, registry_resp, on='run_id', how='left')\n",
    "print({'data': final_resp.to_dict(orient='records')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bedb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_resp=[]\n",
    "if monitor_resp:\n",
    "    print(\"TRUE\")\n",
    "else:\n",
    "    print(\"NOT TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9dddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monitor_resp = [\n",
    "    {\n",
    "        \"run_id\": \"8042932c-101a-4ddc-a808-00c092797960\",\n",
    "        \"algorithm_used\": \"XGBClassifier\",\n",
    "        \"status\": \"Successful\",\n",
    "        \"model_metrics\": {}\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"16e3f179-bb70-4632-9a39-9a6fac4a5581\",\n",
    "        \"algorithm_used\": \"DecisionTreeClassifier\",\n",
    "        \"status\": \"Successful\",\n",
    "        \"model_metrics\": {}\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"ef47a0a5-1a74-4a14-b0fd-8dbbd322057f\",\n",
    "        \"algorithm_used\": \"GradientBoostingClassifier\",\n",
    "        \"status\": \"Running\",\n",
    "        \"model_metrics\": {}\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"26a15f9c-29fd-4d55-82fb-3d38cc18e4b8\",\n",
    "        \"algorithm_used\": \"RandomForestClassifier\",\n",
    "        \"status\": \"Running\",\n",
    "        \"model_metrics\": {}\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_session(dataset, project_id):\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_conn_details_from_ds_name(dataset, project_id)\n",
    "        region=conn[\"params\"][\"READER\"][\"region\"] if conn[\"params\"][\"READER\"][\"cloudPlatform\"] is None \\\n",
    "                    else conn[\"params\"][\"READER\"][\"region\"]+\".\"+conn[\"params\"][\"READER\"][\"cloudPlatform\"]\n",
    "        account = conn['params']['READER']['accountId'] if region is None \\\n",
    "                    else conn['params']['READER']['accountId']+\".\"+region\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": account,\n",
    "            \"user\":conn['params']['READER']['user'],\n",
    "            \"password\": conn['params']['READER']['password'],\n",
    "            \"role\": conn['params']['READER']['role'],\n",
    "            \"database\": conn['params']['READER']['database'],\n",
    "            \"warehouse\": conn['params']['READER']['wareHouse'],\n",
    "            \"schema\": conn['params']['READER']['schema']\n",
    "        }\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "        \n",
    "session = get_session(\"EMPLOYEE_10L\",\"fd0cf79c-8118-43a7-8f0b-059e8f78227a\")\n",
    "reg = Registry(session=session)\n",
    "\n",
    "model_list = session.sql(\"show models like '%exp6789%'\").collect()\n",
    "for model in model_list:\n",
    "    model_name = model[\"name\"]\n",
    "    model_run_id = model_name[-36:].replace('_','-').lower()\n",
    "    model_obj = reg.get_model(model_name)\n",
    "    metrics = {\n",
    "        \"model_metrics\" : model_obj.default.get_metric('model_metrics')\n",
    "    }\n",
    "    for run in monitor_resp:\n",
    "        if run.get('run_id') == model_run_id:\n",
    "            run.update(metrics)\n",
    "print(monitor_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "####Approach 2####\n",
    "monitor_resp = [\n",
    "    {\n",
    "        \"run_id\": \"8042932c-101a-4ddc-a808-00c092797960\",\n",
    "        \"algorithm_used\": \"XGBClassifier\",\n",
    "        \"status\": \"Successful\",\n",
    "        \"model_metrics\": {}\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"16e3f179-bb70-4632-9a39-9a6fac4a5581\",\n",
    "        \"algorithm_used\": \"DecisionTreeClassifier\",\n",
    "        \"status\": \"Successful\",\n",
    "        \"model_metrics\": {}\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"ef47a0a5-1a74-4a14-b0fd-8dbbd322057f\",\n",
    "        \"algorithm_used\": \"GradientBoostingClassifier\",\n",
    "        \"status\": \"Running\",\n",
    "        \"model_metrics\": {}\n",
    "    },\n",
    "    {\n",
    "        \"run_id\": \"26a15f9c-29fd-4d55-82fb-3d38cc18e4b8\",\n",
    "        \"algorithm_used\": \"RandomForestClassifier\",\n",
    "        \"status\": \"Running\",\n",
    "        \"model_metrics\": {}\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_session(dataset, project_id):\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_conn_details_from_ds_name(dataset, project_id)\n",
    "        region=conn[\"params\"][\"READER\"][\"region\"] if conn[\"params\"][\"READER\"][\"cloudPlatform\"] is None \\\n",
    "                    else conn[\"params\"][\"READER\"][\"region\"]+\".\"+conn[\"params\"][\"READER\"][\"cloudPlatform\"]\n",
    "        account = conn['params']['READER']['accountId'] if region is None \\\n",
    "                    else conn['params']['READER']['accountId']+\".\"+region\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": account,\n",
    "            \"user\":conn['params']['READER']['user'],\n",
    "            \"password\": conn['params']['READER']['password'],\n",
    "            \"role\": conn['params']['READER']['role'],\n",
    "            \"database\": conn['params']['READER']['database'],\n",
    "            \"warehouse\": conn['params']['READER']['wareHouse'],\n",
    "            \"schema\": conn['params']['READER']['schema']\n",
    "        }\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "        \n",
    "session = get_session(\"EMPLOYEE_10L\",\"fd0cf79c-8118-43a7-8f0b-059e8f78227a\")\n",
    "reg = Registry(session=session)\n",
    "resp_df = pd.DataFrame(monitor_resp)\n",
    "model_list = session.sql(\"show models like '%exp6789%'\").collect()\n",
    "for model in model_list:\n",
    "    model_name = model[\"name\"]\n",
    "    model_run_id = model_name[-36:].replace('_','-').lower()\n",
    "    model_obj = reg.get_model(model_name)\n",
    "    metrics = {\n",
    "        \"model_metrics\" : model_obj.default.get_metric('model_metrics')\n",
    "    }\n",
    "    select_row = resp_df.loc[resp_df['run_id']==model_run_id]\n",
    "    resp_df.loc[resp_df['run_id']==model_run_id, 'model_metrics'] = str(metrics.get('model_metrics'))   \n",
    "print(resp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f27efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed905fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d626a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_url = \"http://monitor-backend-service/monitor/api/v5/executions/search?objectId=f40619bc-16a1-4d6b-8f74-6b95c1d7c76a_bWFpbg==_U25vd3BhcmtSbkQvQnVpbGRfRGF0YXNldC5pcHluYg==&projectId=0e0fb803-22db-4d88-9f2f-f6f75b6abcf0&jobType=NOTEBOOK\"\n",
    "temp_head = {\n",
    "    \"X-Auth-Userid\": \"aditya1.singh2@fosfor.com\",\n",
    "    \"X-Auth-Username\": \"aditya1.singh2@fosfor.com\",\n",
    "    \"X-Auth-Email\": \"aditya1.singh2@fosfor.com\",\n",
    "    \"X-Project-Id\": \"0e0fb803-22db-4d88-9f2f-f6f75b6abcf0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4992261",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(monitor_url, headers=temp_head)\n",
    "res = json.loads(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b597925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormats:\n",
    "    LIST_RUNS = {\n",
    "            \"run_id\": \"\",\n",
    "            \"algorithm_used\": \"\",\n",
    "            \"status\": \"\",\n",
    "            \"model_metrics\": {}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res_format = ResponseFormats.LIST_RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bddf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_res_format['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29952bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resp = []\n",
    "for data in res.get('data'):\n",
    "    _res_format.update({\"run_id\": data.get('runID'), \"status\": data.get('jobStatus')})\n",
    "    res_data = _res_format\n",
    "    final_resp.append(res_data)\n",
    "\n",
    "print(final_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a74b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(dataset, project_id):\n",
    "    \"\"\"\n",
    "    Method creates snowflake session object.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_conn_details_from_ds_name(dataset, project_id)\n",
    "        region=conn[\"params\"][\"READER\"][\"region\"] if conn[\"params\"][\"READER\"][\"cloudPlatform\"] is None \\\n",
    "                    else conn[\"params\"][\"READER\"][\"region\"]+\".\"+conn[\"params\"][\"READER\"][\"cloudPlatform\"]\n",
    "        account = conn['params']['READER']['accountId'] if region is None \\\n",
    "                    else conn['params']['READER']['accountId']+\".\"+region\n",
    "        CONNECTION_PARAMETERS = {\n",
    "            \"account\": account,\n",
    "            \"user\":conn['params']['READER']['user'],\n",
    "            \"password\": conn['params']['READER']['password'],\n",
    "            \"role\": conn['params']['READER']['role'],\n",
    "            \"database\": conn['params']['READER']['database'],\n",
    "            \"warehouse\": conn['params']['READER']['wareHouse'],\n",
    "            \"schema\": conn['params']['READER']['schema']\n",
    "        }\n",
    "        return Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "    except Exception as ex:\n",
    "        print(\"Error while creating snowflake session\", ex)\n",
    "        raise ex\n",
    "        \n",
    "session = get_session(\"EMPLOYEE_10L\",\"fd0cf79c-8118-43a7-8f0b-059e8f78227a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Registry(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'FD0CF79C_8118_43A7_8F0B_059E8F78227A_EXP_001_RUN_0001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = reg.get_model(model_name)\n",
    "metrics = model_obj.default.show_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = model_obj.default.get_metric('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1472fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d489035",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze | grep -i snowf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1f4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
